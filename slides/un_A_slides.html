<!DOCTYPE html>
<html lang="en"><head>
<script src="un_A_files/libs/clipboard/clipboard.min.js"></script>
<script src="un_A_files/libs/quarto-html/tabby.min.js"></script>
<script src="un_A_files/libs/quarto-html/popper.min.js"></script>
<script src="un_A_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="un_A_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="un_A_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="un_A_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="un_A_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.56">

  <meta name="author" content="Tommaso Rigon">
  <title>Point estimation</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="un_A_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="un_A_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="un_A_files/libs/revealjs/dist/theme/quarto.css">
  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
  <link href="un_A_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="un_A_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="un_A_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="un_A_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Point estimation</h1>
  <p class="subtitle">Statistical Inference - PhD EcoStatData</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<span class="orange">Tommaso Rigon</span> 
</div>
        <p class="quarto-title-affiliation">
            <em>Universit√† degli Studi di Milano-Bicocca</em>
          </p>
    </div>
</div>

</section>
<section id="homepage" class="slide level2 center">
<h2><a href="../index.html">Homepage</a></h2>
<div class="columns">
<div class="column" style="width:20%;">
<p><img data-src="img/target.png"></p>
<!-- *"Pluralitas non est ponenda sine necessitate."* -->
<!-- [William of Ockham]{.grey} -->
</div><div class="column" style="width:80%;">
<ul>
<li><p>This unit will cover the following <span class="orange">topics</span>:</p>
<ul>
<li>Methods of finding estimators</li>
<li>Methods of evaluating estimators</li>
<li>Unbiasedness</li>
<li>Asymptotic evaluations</li>
<li>Robustness and model misspecification</li>
</ul></li>
</ul>
</div><ul>
<li><p>The rationale behind <span class="blue">point estimation</span> is quite simple:</p></li>
<li><p>When sampling is from a <span class="orange">population</span> described by a pdf or a pmf <span class="math inline">f(\cdot ; \theta)</span>, knowledge of <span class="math inline">\theta</span> yields knowledge of the entire population.</p></li>
<li><p>Hence, it is natural to seek a method of finding a good <span class="blue">estimator</span> of the unknown point <span class="math inline">\theta</span>.</p></li>
</ul>
</div>
</section>
<section>
<section id="methods-of-finding-estimators" class="title-slide slide level1 center">
<h1>Methods of finding estimators</h1>

</section>
<section id="estimator" class="slide level2 center">
<h2>Estimator</h2>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>A <span class="blue">point estimator</span> <span class="math inline">\hat{\theta}</span> is any function of the random sample <span class="math inline">Y_1,\dots,Y_n</span>, namely <span class="math display">
\hat{\theta}(\bm{Y}) = \hat{\theta}(Y_1,\dots,Y_n).
</span> That is, any <span class="orange">statistic</span> is a point estimator.</p>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li><p>To streamline the presentation, we consider estimators that target the <span class="orange">unknown parameter</span> <span class="math inline">\theta</span> rather than an arbitrary (non-one-to-one) <span class="blue">transformation</span> <span class="math inline">g(\theta)</span>.</p></li>
<li><p>Most theoretical results <span class="orange">extend naturally</span> to the general case <span class="math inline">g(\theta)</span>.</p></li>
</ul>
<!-- - In principle, the range of the estimator coincides with that of the parameter, i.e. $\hat{\theta} : \mathcal{Y} \rightarrow \Theta$, but there are exceptions. -->
</div>
</div>
</div>
<ul>
<li><p>An <span class="blue">estimator</span> <span class="math inline">\hat{\theta}(Y_1,\dots,Y_n)</span> is a function of the sample <span class="math inline">Y_1,\dots,Y_n</span> and is a <span class="blue">random variable</span>.</p></li>
<li><p>An <span class="orange">estimate</span> <span class="math inline">\hat{\theta}(y_1,\dots,y_n)</span> is a function of the realized values <span class="math inline">y_1,\dots,y_n</span> and is a <span class="orange">number</span>.</p></li>
<li><p>We will write <span class="math inline">\hat{\theta}</span> to denote both estimators and estimates whenever its meaning is clear from the context.</p></li>
</ul>
</section>
<section id="method-of-moments" class="slide level2 center">
<h2>Method of moments</h2>
<ul>
<li><p>The <span class="blue">method of moments</span> is, perhaps, the oldest method of finding point estimators, dating back at least to Karl Pearson in the late 1800s.</p></li>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid sample from <span class="math inline">f(\cdot; \theta)</span>, <span class="math inline">\theta = (\theta_1,\dots,\theta_p)</span>, and <span class="math inline">\Theta \subseteq \mathbb{R}^p</span>. Moreover, define <span class="math display">
  m_r = \frac{1}{n}\sum_{i=1}^n Y_i^r, \qquad \mu_r(\theta) = \mu_r(\theta_1,\dots,\theta_p) = \mathbb{E}_\theta(Y^r), \qquad r=1,\dots,p.
  </span> corresponding to the <span class="blue">population moment</span> <span class="math inline">\mu_r(\theta_1,\dots,\theta_p)</span> and the <span class="orange">sample moment</span> <span class="math inline">m_r</span>.</p></li>
<li><p>The method of moments estimator <span class="math inline">\hat{\theta}</span> is obtained by solving the following system of equations for <span class="math inline">(\theta_1,\dots,\theta_p)</span>: <span class="math display">
  \begin{aligned}
  \mu_1(\theta_1,\dots,\theta_p) &amp;= m_1, \\
  \mu_2(\theta_1,\dots,\theta_p) &amp;= m_2, \\
  &amp;\vdots \\
  \mu_p(\theta_1,\dots,\theta_p) &amp;= m_p. \\
  \end{aligned}
  </span></p></li>
<li><p>In general, it is <span class="orange">not guaranteed</span> that a <span class="blue">solution exists</span> nor its <span class="blue">uniqueness</span>.</p></li>
</ul>
</section>
<section id="asymptotic-evaluation-of-the-mm" class="slide level2 center">
<h2>Asymptotic evaluation of the MM</h2>
<ul>
<li><p>Moments estimators are not necessarily the best estimators, but <span class="blue">under reasonable conditions</span> they are <span class="orange">consistent</span>, they have converge rate <span class="math inline">\sqrt{n}</span>, and they are <span class="orange">asymptotically normal</span>.</p></li>
<li><p>Suppose <span class="math inline">(Y,Y^2,\dots,Y^p)</span> has <span class="blue">covariance</span> <span class="math inline">\Sigma</span>, then the multivariate <span class="orange">central limit theorem</span> implies that as <span class="math inline">n\rightarrow \infty</span> <span class="math display">
\sqrt{n}\{m - \mu(\theta)\} \overset{\text{d}}{\longrightarrow} Z, \qquad Z\sim N_p(0, \Sigma),
</span> where <span class="math inline">m = (m_1,\dots,m_p)</span> and <span class="math inline">\mu(\theta) = (\mu_1(\theta),\dots,\mu_p(\theta))</span>.</p></li>
<li><p>Suppose also that <span class="math inline">\mu(\theta)</span> is a <span class="blue">one-to-one</span> mapping and let <span class="math inline">g(\mu)</span> be the inverse of <span class="math inline">\mu(\theta)</span>, that is <span class="math inline">g = \mu^{-1}</span>. We assume that <span class="math inline">g</span> has <span class="blue">differentiable</span> components <span class="math inline">g_r(\cdot)</span> for <span class="math inline">r = 1,\dots,p</span>.</p></li>
<li><p>The moments estimator can be written as <span class="math inline">\hat{\theta} = g(m)</span> and <span class="math inline">\theta = g(\mu(\theta))</span>. Then, as a consequence of the <span class="orange">delta method</span>, the following general result holds: <span class="math display">
\sqrt{n}(\hat{\theta} - \theta) \overset{\text{d}}{\longrightarrow} Z, \qquad Z\sim N_p\left(0, D \Sigma D^T\right),
</span> where <span class="math inline">D = [d_{rr'}]</span> is a <span class="math inline">p \times p</span> matrix whose entries are the derivatives <span class="math inline">d_{rr'} = \partial g_r(\mu)/\partial \mu_{r'}</span>.</p></li>
</ul>

<aside><div>
<p>Refer to <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 4.1, pag. 35-36.</p>
</div></aside></section>
<section id="example-beta-distribution" class="slide level2 center">
<h2>Example: beta distribution üìñ</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid random sample from a beta distribution of parameters <span class="math inline">\alpha,\beta &gt; 0</span> with density <span class="math display">
f(y; \alpha, \beta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} y^{\alpha-1}(1 - y)^{\beta-1}, \qquad 0 &lt; y &lt; 1.
</span></p></li>
<li><p>The <span class="blue">moment estimator</span> for <span class="math inline">(\alpha, \beta)</span> is the (<span class="orange">explicitly available</span>) solution of the system of equations <span class="math display">
m_1 = \frac{\alpha}{\alpha + \beta}, \qquad m_2 = \frac{\alpha (\alpha+1)}{(\alpha + \beta) (\alpha + \beta + 1)}.
</span></p></li>
<li><p>After some algebra we obtain the following relationship, which is a <span class="orange">smooth</span> and <span class="orange">regular</span> function of <span class="math inline">(m_1,m_2)</span>: <span class="math display">
\hat{\alpha} = m_1 \frac{m_1 - m_2}{m_2 - m_1^2}, \qquad \hat{\beta} = (1 - m_1) \frac{m_1 - m_2}{m_2 - m_1^2}.
</span> where <span class="math inline">\hat{\sigma}^2 = m_2 - m_1^2</span> is the <span class="blue">sample variance</span>. <span class="orange">Remark</span>: is it possible that <span class="math inline">m_1 &lt; m_2</span>?</p></li>
</ul>
</section>
<section id="example-beta-distribution-food-expenditure" class="slide level2 center">
<h2>Example: beta distribution (food expenditure)</h2>
<ul>
<li>We consider data on <span class="orange">proportion of income</span> spent on <span class="blue">food</span> for a random sample of <span class="math inline">38</span> households in a large US city.</li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p><span class="blue">Low</span> income level (<span class="math inline">n</span> = 17)</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0.07431 0.13548 0.08825 0.13728 0.09629 0.09160 0.13882 0.09670 0.10866
[10] 0.11629 0.18067 0.14539 0.15869 0.14910 0.09550 0.23066 0.14751</code></pre>
</div>
</div>
<p>Here <span class="math inline">m_1</span> = 0.129 and <span class="math inline">m_2</span> = 0.018, giving the <span class="orange">MM estimates</span>: <span class="math inline">\hat{\alpha}</span> = 9.7 and <span class="math inline">\hat{\beta}</span> = 65.7.</p>
</div>
</div>
</div>
<div class="callout callout-warning no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p><span class="orange">High</span> income level (<span class="math inline">n</span> = 21)</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> [1] 0.15998 0.16652 0.21741 0.10481 0.23256 0.17976 0.14161 0.14184 0.19604
[10] 0.21141 0.17446 0.14005 0.18831 0.07641 0.21604 0.28980 0.10882 0.18561
[19] 0.19192 0.25918 0.28833</code></pre>
</div>
</div>
<p>Here <span class="math inline">m_1</span> = 0.184 and <span class="math inline">m_2</span> = 0.037, giving the <span class="orange">MM estimates</span>: <span class="math inline">\hat{\alpha}</span> = 9 and <span class="math inline">\hat{\beta}</span> = 39.9.</p>
</div>
</div>
</div>
</section>
<section id="example-beta-distribution-food-expenditure-1" class="slide level2 center">
<h2>Example: beta distribution (food expenditure)</h2>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-5-1.png" width="1800" class="r-stretch"><ul>
<li><span class="orange">Estimated densities</span> <span class="math inline">f(y; \hat{\alpha}, \hat{\beta})</span> for each income level, showing a reasonable fit in both cases.</li>
</ul>
</section>
<section id="example-binomial-with-unknown-trials-mm" class="slide level2 center">
<h2>Example: binomial with unknown trials MM üìñ</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be iid <span class="math inline">\textup{Bin}(N, p)</span> and we assume that <span class="orange">both</span> <span class="math inline">N</span> and <span class="math inline">p</span> are unknown.</p></li>
<li><p>This is a somewhat unusual application of the binomial model, which can be used e.g.&nbsp;to estimate crime rates for crimes that are known to have many unreported occurrences.</p></li>
<li><p>Equating the first two moments yields the system of equations <span class="math display">
m_1 = N p, \qquad m_2 = N p(1-p) + N^2p^2.
</span></p></li>
<li><p>After some algebra we obtain the <span class="blue">moment estimator</span> for <span class="math inline">(N, p)</span>, which is <span class="orange">smooth</span> and <span class="orange">regular</span> function of <span class="math inline">(m_1,m_2)</span>: <span class="math display">
\hat{p} = \frac{m_1}{\hat{N}}, \qquad \hat{N} = \frac{m_1^2}{m_1 - \hat{\sigma}^2},
</span> where <span class="math inline">\hat{\sigma}^2 = m_2 - m_1^2</span> is the sample variance.</p></li>
<li><p><span class="orange">Remark</span>: what if <span class="math inline">m_1 &lt; \hat{\sigma}^2</span>?</p></li>
</ul>

<aside><div>
<p>This problem is described in Example 7.2.2 <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>, pag. 313.</p>
</div></aside></section>
<section id="maximum-likelihood-estimator" class="slide level2 center">
<h2>Maximum likelihood estimator</h2>
<ul>
<li><p>The method of <span class="orange">maximum likelihood</span> is, by far, the most popular technique for deriving estimators, developed by <span class="blue">Ronald A. Fisher</span> in Fisher (1922; 1925).</p></li>
<li><p>Recall that <span class="math inline">L(\theta) = L(\theta; \bm{y})</span> is the likelihood function and <span class="math inline">\ell(\theta) = \log{L(\theta)}</span> is the log-likelihood.</p></li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Given a likelihood function <span class="math inline">L(\theta)</span> of <span class="math inline">\theta \in \Theta</span>, a <span class="orange">maximum likelihood estimate</span> of <span class="math inline">\theta</span> is an element <span class="math inline">\hat{\theta} \in \Theta</span> which attains the maximum value of <span class="math inline">L(\theta)</span> in <span class="math inline">\Theta</span>, i.e.&nbsp;such that <span class="math inline">L(\hat{\theta}) \ge L(\theta)</span> or equivalently <span class="math display">
L(\hat{\theta}) = \max_{\theta \in \Theta} L(\theta).
</span></p>
<p>The <span class="blue">maximum likelihood estimator</span> (MLE) of the parameter <span class="math inline">\theta</span> based on a sample <span class="math inline">\bm{Y}</span> is <span class="math inline">\hat{\theta}(\bm{Y})</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>Intuitively, the MLE is a reasonable choice: it is the parameter point for which the observed sample is <span class="blue">most likely</span>.</p></li>
<li><p>Clearly, the MLE is also the maximizer of the log-likelihood: <span class="math inline">\ell(\hat{\theta}) = \max_{\theta \in \Theta} \ell(\theta)</span>.</p></li>
</ul>
</section>
<section id="properties-and-remarks-about-the-mle" class="slide level2 center">
<h2>Properties and remarks about the MLE üìñ</h2>
<ul>
<li><span class="blue">Remark I</span>: the MLE may <span class="orange">not exists</span> and is <span class="orange">not</span> necessarily <span class="orange">unique</span>. On the other hand, if <span class="math inline">\Theta \subseteq \mathbb{R}^p</span> and <span class="math inline">l(\theta)</span> is differentiable, then it can be found as the solution of the <span class="blue">score equations</span>: <span class="math display">
\ell^*(\theta) = \frac{\partial}{\partial \theta}\ell(\theta) = 0.
</span></li>
</ul>
<!-- - If $s(y)$ is a [sufficient statistic]{.blue}, then the MLE is a function of it. -->
<ul>
<li><p><span class="blue">Remark II</span>: often <span class="math inline">\hat{\theta}</span> cannot be written explicitly as a function of the sample values, i.e.&nbsp;in general the MLE has <span class="orange">no closed-form expression</span> but it must be found using <span class="orange">numerical procedures</span>.</p></li>
<li><p><span class="blue">Remark III</span>: the likelihood function has to be maximized in the set space <span class="math inline">\Theta</span> specified by the statistical model, not over the set of the mathematically admissible values of <span class="math inline">\theta</span>.</p></li>
</ul>
<!-- - [Remark IV]{.blue}: it is not necessary for $\Theta$ to be a numeric set, i.e. we need [not]{.orange} be dealing with a [parametric]{.orange} model, although we shall restrict ourself to this case. -->
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem <span class="citation" data-cites="Casella2002">(Invariance, <a href="#/references" role="doc-biblioref" onclick="">Casella and Berger 2002</a>, Theorem 7.2.10)</span></strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\psi(\cdot)</span> be <span class="orange">one-to-one</span><sup>1</sup>, that is, a <span class="blue">reparametrization</span>, from the set <span class="math inline">\Theta</span> onto the set <span class="math inline">\Psi</span>. Then the MLE of <span class="math inline">\psi = \psi(\theta)</span> is <span class="math inline">\hat{\psi} = \psi(\hat{\theta})</span> where <span class="math inline">\hat{\theta}</span> denotes the MLE of <span class="math inline">\theta</span>.</p>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn1"><p>It generalizes to any <span class="math inline">g(\cdot)</span>. If <span class="math inline">\hat{\theta}</span> is the MLE, then <span class="math inline">g(\hat{\theta})</span> is the ‚ÄúMLE‚Äù of an ‚Äúinduced likelihood‚Äù.</p></li></ol></aside></section>
<section id="example-poisson-with-unknown-mean" class="slide level2 center">
<h2>Example: Poisson with unknown mean üìñ</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a iid random sample from a Poisson distribution of mean parameter <span class="math inline">\lambda &gt; 0</span>, with <span class="orange">likelihood function</span> <span class="math display">
L(\lambda) = \prod_{i=1}^n \frac{e^{-\lambda} \lambda^{y_i}}{y_i!}.
</span></p></li>
<li><p>Therefore the <span class="blue">log-likelihood</span>, up to an additive constant <span class="math inline">c</span> not depending on <span class="math inline">\lambda</span>, is <span class="math display">
\ell(\lambda) = \sum_{i=1}^ny_i\log{\lambda} - n\lambda + c.
</span></p></li>
<li><p>The <span class="orange">maximum likelihood estimator</span> <span class="math inline">\hat{\lambda}</span> is found by maximizing <span class="math inline">\ell(\lambda)</span>. In this regular problem, this can be done by studying the first derivative: <span class="math display">
\ell^*(\lambda) = \frac{1}{\lambda}\sum_{i=1}^ny_i - n.
</span></p></li>
<li><p>We solve <span class="math inline">\ell^*(\lambda) = 0</span>, obtaining <span class="math inline">\hat{\lambda} = \bar{y}</span>. This is indeed a maximizer of <span class="math inline">\ell(\lambda)</span> (<span class="orange">why</span>?).</p></li>
</ul>
</section>
<section id="example-binomial-with-unknown-trials-mle" class="slide level2 center">
<h2>Example: binomial with unknown trials MLE</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be iid <span class="math inline">\textup{Bin}(N, p)</span>, and suppose <span class="math inline">N</span> is <span class="orange">unknown</span>, while <span class="math inline">p</span> is considered <span class="blue">known</span>. This constitutes a non-regular problem because <span class="math inline">N</span> is <span class="blue">discrete</span>.</p></li>
<li><p>The likelihood function is <span class="math display">
L(N) = \prod_{i=1}^n\binom{N}{y_i} p^{y_i}(1 - p)^{N - y_i},
</span> where the maximum <span class="orange">cannot</span> be obtained through <span class="orange">differentiation</span>, as <span class="math inline">N \in \mathbb{N}</span>.</p></li>
<li><p>Naturally, we require that <span class="math inline">\hat{N} \ge \max_i y_i</span>, since <span class="math inline">L(N) = 0</span> for any <span class="math inline">N &lt; \max_i y_i</span>. The ML is therefore an integer <span class="math inline">\hat{N} \ge \max_i y_i</span> such that <span class="math display">
L(\hat{N}) \ge L(\hat{N} - 1), \qquad L(\hat{N} + 1) &lt; L(\hat{N}).
</span></p></li>
<li><p>This value must be found <span class="orange">numerically</span>. However, it can be shown<sup>1</sup> that there exists exactly one such <span class="math inline">\hat{N}</span>, meaning the MLE is <span class="blue">unique</span>.</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn2"><p>This problem is described in Example 7.2.9 of <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>, pag. 318. See also Example 7.2.13: such estimate has a large variance in practice.</p></li></ol></aside></section>
<section id="example-binomial-with-unknown-trials-mle-1" class="slide level2 center">
<h2>Example: binomial with unknown trials MLE</h2>
<ul>
<li>Let us consider the following data, in which both <span class="math inline">N</span> and <span class="math inline">p</span> are unknown. These are <span class="blue">simulated data</span> and the <span class="grey">true values</span> were <span class="math inline">N = 75</span> and <span class="math inline">p = 0.32</span>.</li>
</ul>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 16 18 22 25 27</code></pre>
</div>
</div>
<ul>
<li>The <span class="orange">method of moments</span> estimator gives <span class="math inline">\hat{N}_\text{MM}</span> = 102 (rounded to the closest integer) and <span class="math inline">\hat{p}_\text{MM}</span> = 0.21. The <span class="blue">maximum likelihood</span>, instead, gives <span class="math inline">\hat{N}_\text{ML}</span> = 99 and <span class="math inline">\hat{p}_\text{ML}</span> = 0.22.</li>
</ul>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-7-1.png" class="quarto-figure quarto-figure-center r-stretch" width="1800"><ul>
<li>If we replace <span class="math inline">27</span> with a <span class="math inline">28</span>, we obtain drastically different estimates, namely <span class="math inline">\hat{N}_\text{MM} =  195</span> and <span class="math inline">\hat{N}_\text{ML} = 191</span>, demonstrating a <span class="orange">large</span> amount of <span class="orange">variability</span>.</li>
</ul>
</section>
<section id="m-estimators" class="slide level2 center">
<h2>M-estimators</h2>
<ul>
<li>M- and Z- estimators are broad class of estimators that encompass the maximum likelihood (iid observations) and other popular methods as special cases. <sup>1</sup></li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>An <span class="blue">M-estimator</span> is the <span class="orange">maximizer</span> over <span class="math inline">\Theta</span> of a function <span class="math inline">M(\theta) : \Theta \rightarrow \mathbb{R}</span> of the type: <span class="math display">
M(\theta) = \sum_{i=1}^n m(\theta; Y_i),
</span> where <span class="math inline">m(\theta; Y_i)</span> are known real-valued functions.</p>
</div>
</div>
</div>
<ul>
<li><span class="orange">Remark</span>: when <span class="math inline">m(\theta; y) = \log{f(Y_i; \theta)}</span> this coincides with the MLE of a model with iid observations.</li>
</ul>
<!-- -   The term $1/n$ is included here to facilitate the description of the -->
<!--     subsequent asymptotic theory, but it is obviously non influential. -->
<aside><ol class="aside-footnotes"><li id="fn3"><p>A detailed discussion is offered in <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Chap. 5.</p></li></ol></aside></section>
<section id="z-estimators" class="slide level2 center">
<h2>Z-estimators</h2>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>A <span class="blue">Z-estimator</span> is the <span class="orange">solution</span> over <span class="math inline">\Theta</span> of a system of equations function <span class="math inline">Q(\theta) = \bm{0}</span> of the type: <span class="math display">
Q(\theta) = Q(\theta; Y) = \sum_{i=1}^n q(\theta; Y_i) = \bm{0},
</span> where <span class="math inline">q(\theta) = q(\theta; y)</span> are known vector-valued maps. These are called <span class="blue">estimating equations</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>When <span class="math inline">\theta = (\theta_1,\dots,\theta_p)</span>, <span class="math inline">Q</span> and <span class="math inline">q</span> typically have <span class="math inline">p</span> coordinate functions, namely we consider: <span class="math display">
Q_r(\theta) = \sum_{i=1}^n q_r(\theta; Y_i)= 0, \qquad r = 1,\dots,p.
</span></p></li>
<li><p>In many examples <span class="math inline">q_r(y; \theta)</span> are the partial derivatives of a function <span class="math inline">m(\theta; y)</span>, that is <span class="math display">
Q(\theta) = \frac{\partial}{\partial \theta} M(\theta).</span> An example is the <span class="blue">score function</span> <span class="math inline">\ell^*(\theta)</span>. However, this is <span class="orange">not always the case</span>.</p></li>
</ul>
<!-- ## Plug-in estimators -->
</section>
<section id="huber-estimators-i" class="slide level2 center">
<h2>Huber estimators I</h2>
<ul>
<li><p>The <span class="orange">location</span> of a r.v. <span class="math inline">Y</span> is a vague term that can be made precise by defining it as the expectation <span class="math inline">\mathbb{E}(Y)</span>, a quantile, or the center of symmetry, as in the following example.</p></li>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a iid sample of real-valued random variables belonging to family of distributions <span class="math inline">\mathcal{F}</span> defined as <span class="math display">
\mathcal{F} = \{f(y - \theta) : \theta \in \Theta \subseteq \mathbb{R} \},
</span> for some unknown density <span class="math inline">f(y)</span> <span class="blue">symmetric</span> around <span class="math inline">0</span>. The parameter <span class="math inline">\theta</span> is the <span class="orange">location</span>.</p></li>
<li><p>Classical M- estimators for <span class="math inline">\theta</span> are the <span class="blue">mean</span> and the <span class="orange">median</span>, maximizing: <span class="math display">
-\sum_{i=1}^n (Y_i - \theta)^2, \quad (\text{Mean}) \qquad \qquad - \sum_{i=1}^n |Y_i - \theta|, \quad (\text{Median})
</span> or alternatively (Z- estimator forms) solving the equations <span class="math display">
\sum_{i=1}^n (Y_i - \theta) = 0, \quad (\text{Mean}) \qquad \qquad \sum_{i=1}^n \text{sign}(Y_i - \theta) = 0, \quad (\text{Median}).
</span></p></li>
</ul>
<!-- ## Location estimators II -->
<!-- - Both estimating equations involve functions of the form $q(\theta; Y) = q(Y - \theta)$ that are [monotone]{.blue} and [odd]{.orange} around zero.  -->
<!-- - It is hence reasonable to study estimating equations of the type:$$ -->
<!-- Q(\theta) = \frac{1}{n}\sum_{i=1}^n q(Y_i - \theta)= 0. -->
<!-- $$ -->
<!-- - This class of estimators has an appealing [equivariance]{.orange} property. If the observations $Y_i$ are shifted by a fixed amount $\alpha$, then so is the estimate: -->
<!-- $$ -->
<!-- \hat{\theta} + \alpha \quad \text{ solves } \quad Q(\theta) = \frac{1}{n}\sum_{i=1}^n q(Y_i + \alpha - \theta)= 0, -->
<!-- $$ -->
<!-- if $\hat{\theta}$ solves the original equation. -->
</section>
<section id="huber-estimators-ii" class="slide level2 center">
<h2>Huber estimators II</h2>
<ul>
<li><p><span class="blue">Huber estimators</span> can be regarded as a compromise between the mean and the median, maximizing the following function: <span class="math display">
M(\theta) = -\sum_{i=1}^n m(Y_i - \theta), \qquad m(y) = \begin{cases}\frac{1}{2}y^2 \quad &amp;\text{ if } |y| \le k\\
k |y| - \frac{1}{2}k^2 \quad &amp;\text{ if } |y| \ge k
\end{cases}
</span> where <span class="math inline">k &gt; 0</span> is a <span class="orange">tuning</span> parameter. The function <span class="math inline">m(y)</span> is continuous and differentiable<sup>1</sup>. The choice <span class="math inline">k \rightarrow 0</span> leads to the median, whereas for <span class="math inline">k \rightarrow \infty</span> we get the mean.</p></li>
<li><p>Equivalently, we can consider the solution of the following estimating equation: <span class="math display">
Q(\theta) = \sum_{i=1}^n q(Y_i - \theta)= 0, \qquad q(y) = \begin{cases} -k \quad &amp;\text{ if }\: y \le -k\\
y \quad &amp;\text{ if  }\: |y| \le k \\
k \quad &amp;\text{ if }\: y \ge k\end{cases}
</span></p></li>
<li><p>Unfortunately, there is no closed-form expression and the equation must be solved numerically.</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn4"><p>See Exercise 10.28 of <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>.</p></li></ol></aside></section>
<section id="example-newcombs-speed-of-light" class="slide level2 center">
<h2>Example: Newcomb‚Äôs speed of light</h2>
<ul>
<li>Data <span class="math inline">y_1, \dots, y_{66}</span> represent Simon Newcomb‚Äôs measurements (1882) of the <span class="orange">speed of light</span>. The data are recordes as <span class="blue">deviations</span> from 24,800 nanoseconds.</li>
</ul>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> [1]  28  26  33  24  34 -44  27  16  40  -2  29  22  24  21  25  30  23  29  31
[20]  19  24  20  36  32  36  28  25  21  28  29  37  25  28  26  30  32  36  26
[39]  30  22  36  23  27  27  28  27  31  27  26  33  26  32  32  24  39  28  24
[58]  25  32  25  29  27  28  29  16  23</code></pre>
</div>
</div>
<ul>
<li><p>There are <span class="orange">two outliers</span> (-44 and -2) which could influence the analysis.</p></li>
<li><p>We see that as <span class="math inline">k</span> increases, the <span class="blue">Huber estimate</span> varies between the median (27) and the mean (26.21), so we interpret increasing <span class="math inline">k</span> as decreasing <span class="orange">robustness</span> to outliers.</p></li>
<li><p>The suggested <span class="blue">default</span> for <span class="math inline">k</span> is roughly <span class="math inline">k \approx 4.5</span>, that is <span class="math inline">k = 1.5 \times \text{MAD}</span>.</p></li>
</ul>
<table class="caption-top">
<colgroup>
<col style="width: 4%">
<col style="width: 4%">
<col style="width: 9%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">k</span></th>
<th style="text-align: right;">0</th>
<th style="text-align: right;">5</th>
<th style="text-align: right;">10</th>
<th style="text-align: right;">20</th>
<th style="text-align: right;">30</th>
<th style="text-align: right;">40</th>
<th style="text-align: right;">50</th>
<th style="text-align: right;">60</th>
<th style="text-align: right;">70</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Est.</td>
<td style="text-align: right;">27</td>
<td style="text-align: right;">27.37</td>
<td style="text-align: right;">27.417</td>
<td style="text-align: right;">27.125</td>
<td style="text-align: right;">26.831</td>
<td style="text-align: right;">26.677</td>
<td style="text-align: right;">26.523</td>
<td style="text-align: right;">26.369</td>
<td style="text-align: right;">26.215</td>
</tr>
</tbody>
</table>
<ul>
<li>Based on recent measurements, the <span class="orange">true value</span> of the speed of light, expressed in this scale, is 33. <span class="blue">Huber estimate</span> for reasonable values of <span class="math inline">k</span> is <span class="blue">closer</span> than both median and mean.</li>
</ul>
</section>
<section id="bayesian-estimators" class="slide level2 center">
<h2>Bayesian estimators</h2>
<ul>
<li><p>Bayesian estimators are obtained following a <span class="orange">different inferential paradigm</span> than the one considered here, but they also exhibit <span class="blue">appealing frequentist properties</span>.</p></li>
<li><p>Let <span class="math inline">L(\theta; \bm{y})</span> denote the likelihood function, and let <span class="math inline">\pi(\theta)</span> represent the <span class="orange">prior</span> distribution. Bayesian inference is based on the <span class="blue">posterior</span> distribution, defined as: <span class="math display">
\pi(\theta \mid \bm{y}) = \frac{\pi(\theta) L(\theta; \bm{y})}{\int_\Theta \pi(\theta) L(\theta; \bm{y}) \mathrm{d}\theta}.
</span></p></li>
<li><p>Under certain hypotheses, which will be clarified later, the <span class="blue">posterior mean</span> serves as an <span class="orange">optimal Bayesian estimator</span>: <span class="math display">
\hat{\theta}_\text{Bayes} = \mathbb{E}(\theta \mid \bm{Y}) = \frac{\int_\Theta \theta \: \pi(\theta) L(\theta; \bm{Y}) \mathrm{d}\theta}{\int_\Theta \pi(\theta) L(\theta; \bm{Y}) \mathrm{d}\theta}.
</span> However, this estimator is not always available in closed form.</p></li>
<li><p>Other ‚Äúoptimal‚Äù Bayesian estimators include, for instance, the posterior median.</p></li>
</ul>
</section>
<section id="example-binomial-bayes-estimator" class="slide level2 center">
<h2>Example: binomial Bayes estimator</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be iid Bernoulli random variables with probability <span class="math inline">p</span>, and let the prior <span class="math inline">p \sim \text{Beta}(a, b)</span>. Moreover, let <span class="math inline">n_1 = \sum_{i=1}^n y_i</span> be the <span class="blue">number of successes</span> out of <span class="math inline">n</span> trials.</p></li>
<li><p>Standard calculations in Bayesian statistics yield the (<span class="orange">conjugate</span>) posterior <span class="math inline">(p \mid Y_1,\dots,Y_n) \sim \text{Beta}(a + n_1, b + n - n_1)</span>. Hence, the <span class="blue">posterior mean</span> is <span class="math display">
\hat{p} = \mathbb{E}(p \mid Y_1,\dots,Y_n) = \frac{a + n_1}{a + b + n}.
</span></p></li>
<li><p>Note that we can rewrite <span class="math inline">\hat{p}</span> in the following way: <span class="math display">
\hat{p} = \left(\frac{n}{a + b + n}\right)\bar{y} + \left(\frac{a + b}{a + b + n}\right) \left(\frac{a}{a + b}\right),
</span> that is, as a <span class="orange">linear combination</span> of the prior mean and the sample mean, with weights determined by <span class="math inline">a, b</span>, and <span class="math inline">n</span>.<sup>1</sup></p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn5"><p>This is not a coincidence, and it essentially holds for general exponential families; see the elegant paper by <span class="citation" data-cites="Diaconis1979">Diaconis and Ylvisaker (<a href="#/references" role="doc-biblioref" onclick="">1979</a>)</span>.</p></li></ol></aside></section></section>
<section>
<section id="methods-of-evaluating-estimators" class="title-slide slide level1 center">
<h1>Methods of evaluating estimators</h1>

</section>
<section id="comparing-estimators" class="slide level2 center">
<h2>Comparing estimators</h2>
<ul>
<li><p>We study the performance of estimators, aiming to determine when an estimator <span class="math inline">\hat{\theta}</span> can be considered <span class="orange">good</span> or <span class="blue">optimal</span>.</p></li>
<li><p>This requires <span class="orange">criteria</span> for evaluation, often provided by <span class="blue">decision theory</span>, which relies on a <span class="orange">loss function</span> <span class="math inline">\mathscr{L}</span>. The function <span class="math inline">\mathscr{L}(\theta, \hat{\theta})</span> quantifies the loss incurred when estimating <span class="math inline">\theta</span> by <span class="math inline">\hat{\theta}</span>.</p></li>
<li><p>Typically, we assume <span class="math display">
\mathscr{L}(\theta, \theta) = 0 \text{ (no loss for the correct estimate)}, \qquad \mathscr{L}(\theta, \hat{\theta}) \geq 0,
</span> for all <span class="math inline">\theta</span> and <span class="math inline">\hat{\theta}</span>.</p></li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Since <span class="math inline">\hat{\theta}(\bm{Y})</span> is random, we need a way to summarize the loss. A common criterion is the (frequentist) <span class="orange">risk function</span>, namely the <span class="blue">average loss</span>, defined as the expectation <span class="math display">
R(\theta; \hat{\theta}) = \mathbb{E}_\theta\{\mathscr{L}(\theta, \hat{\theta}(\bm{Y}))\}.
</span></p>
</div>
</div>
</div>
</section>
<section id="optimal-estimators" class="slide level2 center">
<h2>Optimal estimators</h2>
<ul>
<li><p>An <span class="blue">oracle estimator</span> <span class="math inline">\hat{\theta}_\text{oracle}</span>, which never makes errors, satisfies <span class="math display">
R(\theta; \hat{\theta}_\text{oracle}) = 0,
</span> for all <span class="math inline">\theta \in \Theta</span>. Clearly, such an estimator <span class="orange">does not exist</span>.</p></li>
<li><p>An <span class="blue">optimal estimator</span> <span class="math inline">\hat{\theta}_\text{opt}</span> <span class="blue">uniformly</span> minimizes the risk, meaning <span class="math display">
R(\theta; \hat{\theta}_\text{opt}) \leq R(\theta; \tilde{\theta}),
</span> for all <span class="math inline">\theta \in \Theta</span> and estimators <span class="math inline">\tilde{\theta}</span>. Except for trivial cases, such an estimator <span class="orange">does not exist</span> unless one <span class="blue">restricts</span> the class of estimators considered <sup>1</sup>.</p></li>
<li><p>In fact, the constant estimator <span class="math inline">\hat{\theta}_\text{const}(\bm{Y}) = \theta_1</span> has zero risk when <span class="math inline">\theta = \theta_1</span> but positive risk otherwise. Thus, <span class="math inline">\hat{\theta}_\text{opt}</span> would need <span class="math inline">R(\theta; \hat{\theta}_\text{opt}) = 0</span> for all <span class="math inline">\theta \in \Theta</span>, making it identical to the oracle.</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn6"><p>A common restriction is unbiasedness, namely the requirement <span class="math inline">\mathbb{E}_\theta(\hat{\theta}) = \theta</span>. An alternative restriction is equivariance.</p></li></ol></aside></section>
<section id="admissible-estimators" class="slide level2 center">
<h2>Admissible estimators</h2>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>An estimator <span class="math inline">\hat{\theta}</span> is <span class="orange">admissible</span> if no other estimator <span class="math inline">\tilde{\theta}</span> exists such that<br>
<span class="math display">
R(\theta; \tilde{\theta}) \le R(\theta; \hat{\theta}), \qquad \text { for all } \theta \in \Theta,
</span> with strict inequality for at least one value of <span class="math inline">\theta</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>Broadly speaking, an <span class="blue">admissible</span> estimator <span class="math inline">\hat{\theta}</span> will perform better than an alternative <span class="math inline">\tilde{\theta}</span> for some values of <span class="math inline">\theta</span> and worse for others.</p></li>
<li><p>In principle, disregarding any practical implications, an <span class="orange">inadmissible</span> estimator should not be used, as it is <span class="orange">dominated</span> by a better alternative.</p></li>
<li><p>The admissibility criterion is interesting due to its <span class="blue">selective</span> nature, eliminating dominated estimators.</p></li>
<li><p>However, <span class="blue">admissibility</span> alone is <span class="orange">not enough</span>: for instance, the constant estimator <span class="math inline">\hat{\theta}_\text{const} = \theta_1</span> is admissible but clearly unsatisfactory.</p></li>
</ul>
</section>
<section id="the-choice-of-the-loss-function" class="slide level2 center">
<h2>The choice of the loss function</h2>
<ul>
<li><p>The choice of the loss function has its roots in <span class="blue">decision theory</span>. The loss function <span class="math inline">\mathscr{L}</span> is a nonnegative function that generally increases as the distance between <span class="math inline">\hat{\theta}</span> and <span class="math inline">\theta</span> increases.</p></li>
<li><p>Let <span class="math inline">\theta \in \mathbb{R}^p</span>. Two <span class="orange">commonly used</span> loss functions are <span class="math display">
\mathscr{L}(\theta, \hat{\theta}) = ||\hat{\theta} - \theta||_1, \qquad \text{(Absolute error loss)},
</span> and<br>
<span class="math display">
\mathscr{L}(\theta, \hat{\theta}) = ||\hat{\theta} - \theta||_2^2, \qquad \text{(Quadratic loss)}.
</span></p></li>
<li><p>The quadratic loss is the de facto standard in many contexts, leading to the <span class="orange">mean squared error</span> and the well-known <span class="blue">bias-variance</span> decomposition. Let <span class="math inline">\Theta \subseteq \mathbb{R}</span>, then<br>
<span class="math display">
R(\theta; \hat{\theta}) = \mathbb{E}_\theta\{(\hat{\theta} - \theta)^2\} = \text{bias}_\theta(\hat{\theta})^2 + \text{var}_\theta(\hat{\theta}), \qquad \text{(Mean squared error)}.
</span></p></li>
<li><p>Both these losses are <span class="blue">convex</span>, and the quadratic loss is <span class="orange">strictly convex</span>. Convexity will be crucial in the subsequent theoretical developments.</p></li>
</ul>
</section>
<section id="other-loss-functions" class="slide level2 center">
<h2>Other loss functions</h2>
<ul>
<li><p>In principle, the choice of the loss should be based on its properties rather than mathematical convenience. Here we present some less common <span class="orange">examples</span>.</p></li>
<li><p><span class="blue">Weighted quadratic loss</span>, a variant of the quadratic loss, accounting for weights. Let <span class="math inline">\theta \in \mathbb{R}^p</span> <span class="math display">
\mathscr{L}(\theta, \hat{\theta}) = (\theta - \hat{\theta})^T A (\theta - \hat{\theta}),
</span> where <span class="math inline">A \in \mathbb{R}^{p \times p}</span> is a positive definite matrix. This loss is <span class="orange">strictly convex</span>.</p></li>
<li><p><span class="blue">Stein Loss</span> <sup>1</sup>. Let <span class="math inline">\theta &gt; 0</span>, such as the <span class="orange">population variance</span> of a model. Stein loss is defined as: <span class="math display">
\mathscr{L}(\theta,\hat{\theta}) = \frac{\hat{\theta}}{\theta} - 1 - \log\frac{\hat{\theta}}{\theta}.
</span> A criticism of quadratic loss for variance estimation is that underestimation has finite penalty, while overestimation as infinite penalty. Instead, Stein loss <span class="math inline">\mathscr{L}(\theta,\hat{\theta}) \rightarrow \infty</span> as <span class="math inline">\hat{\theta}\rightarrow 0</span> and <span class="math inline">\hat{\theta}\rightarrow \infty</span>.</p></li>
<li><p>Other examples are <span class="blue">Huber losses</span> <span class="citation" data-cites="Lehmann1998">(see <a href="#/references" role="doc-biblioref" onclick="">Lehmann and Casella 1998,pp. 51‚Äì52</a>)</span> and <span class="blue">intrinsic losses</span> <span class="citation" data-cites="Robert1994">(see <a href="#/references" role="doc-biblioref" onclick="">Robert 1994,p. 2.5.4</a>)</span>, such as the <span class="orange">entropy distance</span>.</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn7"><p>See Examples 7.3.26 and 7.3.27 in <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span> for a comparison in the estimation of the population variance <span class="math inline">\sigma^2</span> under the quadratic loss and the Stein loss.</p></li></ol></aside></section>
<section id="example-mse-of-binomial-estimators-i" class="slide level2 center">
<h2>Example: MSE of binomial estimators I üìñ</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be iid Bernoulli random variables with probability <span class="math inline">p</span>. Moreover, let <span class="math inline">n_1 = \sum_{i=1}^n y_i</span> be the <span class="blue">number of successes</span> out of <span class="math inline">n</span> trials.</p></li>
<li><p>The <span class="orange">proportion</span> <span class="math inline">\hat{p} = \bar{y} = n_1/n</span> is the <span class="orange">maximum likelihood</span> (and method of moments) estimator. Simple calculations yield <span class="math display">
R(p; \hat{p}) = \mathbb{E}_p\{(\hat{p} - p)^2\} = \text{var}_p(\hat{p}) = \frac{p(1-p)}{n}.
</span></p></li>
<li><p>Let us consider a <span class="blue">Bayesian estimator</span> for <span class="math inline">p</span> under a beta prior with parameters <span class="math inline">a = b = 0.5\sqrt{n}</span>, yielding <span class="math display">
\hat{p}_\text{minimax} = \frac{n_1 + 0.5\sqrt{n}}{n + \sqrt{n}}, \qquad R(p; \hat{p}_\text{minimax}) = \mathbb{E}_p\{(\hat{p}_\text{minimax} - p)^2\} = \frac{n}{4 ( n + \sqrt{n})^2}.
</span> This Bayesian estimator has <span class="orange">constant risk</span>, that is, <span class="math inline">R(p; \hat{p}_\text{minimax})</span> does not depend on <span class="math inline">p</span>.<sup>1</sup></p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn8"><p>Some subjective Bayesians may criticize this estimator for not being ‚Äútruly Bayesian‚Äù as the hyperparameters depend on the sample size <span class="math inline">n</span>, making the prior data-dependent. However, here we are evaluating <span class="math inline">\hat{p}_\text{Bayes}</span> from a frequentist perspective.</p></li></ol></aside></section>
<section id="example-mse-of-binomial-estimators-ii" class="slide level2 center">
<h2>Example: MSE of binomial estimators II</h2>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-11-1.png" width="1800" class="r-stretch"></section>
<section id="example-mse-of-binomial-estimators-iii" class="slide level2 center">
<h2>Example: MSE of binomial estimators III</h2>
<ul>
<li><p>Neither <span class="math inline">\hat{p}</span> dominates <span class="math inline">\hat{p}_\text{minimax}</span> nor vice versa. In fact, both estimators are <span class="blue">admissible</span>.</p></li>
<li><p>For small values of <span class="math inline">n</span>, <span class="math inline">\hat{p}_\text{minimax}</span> is the <span class="orange">better choice</span> unless one believes that <span class="math inline">p</span> is very close to one of the extremes <span class="math inline">0</span> or <span class="math inline">1</span>.</p></li>
<li><p>Conversely, for large values of <span class="math inline">n</span>, the maximum likelihood estimator <span class="math inline">\hat{p}</span> is the better choice unless one strongly believes that <span class="math inline">p</span> is very close to <span class="math inline">0.5</span>.</p></li>
<li><p>This information, <span class="blue">combined</span> with the <span class="blue">knowledge of the problem</span> at hand, can lead to choosing the better estimator for the situation.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li><p>We will get back to this example, as both <span class="math inline">\hat{p}</span> and <span class="math inline">\hat{p}_\text{minimax}</span> are <span class="blue">optimal</span> in some sense.</p></li>
<li><p>In fact, <span class="math inline">\hat{p}</span> is the <span class="orange">UMVU estimator</span> (uniform minimum variance unbiased estimator), and <span class="math inline">\hat{p}_\text{minimax}</span> is the <span class="orange">minimax</span> estimator.<br>
</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="james-stein-estimator-i" class="slide level2 center">
<h2>James-Stein estimator I</h2>
<ul>
<li><p>Let <span class="math inline">\bm{Y} = (Y_1,\dots,Y_p)</span> be a <span class="blue">Gaussian random vector</span>, <span class="math inline">\bm{Y} \sim \text{N}_p(\mu, I_p)</span>, with unknown means <span class="math inline">\mu = (\mu_1,\dots,\mu_p)</span> and fixed variance. That is, <span class="math display">
Y_j \overset{\text{ind}}{\sim} \text{N}(\mu_j, 1), \qquad j=1,\dots,p.
</span></p></li>
<li><p>We are interested in <span class="orange">estimating</span> the <span class="orange">means</span> <span class="math inline">\mu</span>.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li>Intuitively, the most ‚Äúnatural‚Äù approach is the maximum likelihood / method of moments estimator, which in this case with <span class="math inline">n = 1</span> is simply <span class="math display">
\hat{\mu}_j = Y_j, \qquad j=1,\dots,p.
</span></li>
<li>This estimator is ‚Äúoptimal‚Äù in the sense that it is the UMVUE, as we shall see in the next sections. Moreover, its <span class="orange">frequentist risk</span> under a squared loss is <span class="math display">
R(\mu; \hat{\mu}) = \mathbb{E}_\mu(||\hat{\mu} - \mu||_2^2) = p,
</span> because <span class="math inline">||\hat{\mu} - \mu||_2^2 = ||\bm{Y} - \mu||_2^2 \sim \chi^2_p</span>.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="james-stein-estimator-ii" class="slide level2 center">
<h2>James-Stein estimator II</h2>
<ul>
<li><p>By the early 1950s, three proofs had emerged to show that <span class="math inline">\hat{\mu}</span> is <span class="blue">admissible</span> for squared error loss <span class="orange">when</span> <span class="math inline">p = 1</span>.</p></li>
<li><p>Nevertheless, <span class="citation" data-cites="Stein1956">Stein (<a href="#/references" role="doc-biblioref" onclick="">1956</a>)</span><sup>1</sup> <span class="blue">stunned the statistical world</span> when he proved that although <span class="math inline">\hat{\mu}</span> is admissible for squared error loss when <span class="math inline">p = 2</span>, it is <span class="orange">inadmissible</span> <span class="orange">when</span> <span class="math inline">p \geq 3</span>.</p></li>
<li><p>In fact, <span class="citation" data-cites="James1961">James and Stein (<a href="#/references" role="doc-biblioref" onclick="">1961</a>)</span><sup>2</sup> showed that the estimator<br>
<span class="math display">
\hat{\mu}_\text{JS} = \left(1 - \frac{p-2}{||\bm{Y}||_2^2}\right)\bm{Y}
</span> strictly <span class="orange">dominates</span> <span class="math inline">\hat{\mu}</span>.</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn9"><p><span class="citation" data-cites="Stein1956">Stein (<a href="#/references" role="doc-biblioref" onclick="">1956</a>)</span>, Inadmissibility of the usual estimator of the mean of a multivariate normal distribution, <em>Proc. Third Berkeley Symposium</em>, 1, 197‚Äì206, Univ. California Press.</p></li><li id="fn10"><p><span class="citation" data-cites="James1961">James and Stein (<a href="#/references" role="doc-biblioref" onclick="">1961</a>)</span>, Estimation with quadratic loss, <em>Proc. Fourth Berkeley Symposium</em>, 1, 361‚Äì380, Univ. California Press.</p></li></ol></aside></section>
<section id="james-stein-estimator-iii" class="slide level2 center">
<h2>James-Stein estimator III üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (James-Stein, 1961)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\bm{Y} \sim \text{N}_p(\mu, I_p)</span>. The frequentist risk of the James-Stein estimator <span class="math inline">\hat{\mu}_\text{JS}</span> under quadratic loss is <span class="math display">
R(\mu; \hat{\mu}_\text{JS}) = \mathbb{E}_\mu(||\hat{\mu}_\text{JS} - \mu||_2^2) = p - (p -2)^2\mathbb{E}_\mu\left(\frac{1}{||\bm{Y}||_2^2}\right).
</span> Thus, <span class="math inline">\hat{\mu}_\text{JS}</span> <span class="blue">strictly dominates</span> <span class="math inline">\hat{\mu}</span>, meaning that <span class="math inline">R(\mu; \hat{\mu}_\text{JS}) &lt; R(\mu; \hat{\mu}) = p</span>. Moreover, <span class="math display">
R(\mu; \hat{\mu}_\text{JS}) \le p - \frac{(p-2)^2}{p - 2 + ||\mu||_2^2}.
</span></p>
</div>
</div>
</div>
<ul>
<li><p>Geometrically, the James-Stein estimator <span class="orange">shrinks</span> each component of <span class="math inline">\bm{Y}</span> towards the origin.</p></li>
<li><p>The biggest <span class="blue">improvement</span> occurs when <span class="math inline">\mu</span> is close to zero. For <span class="math inline">\mu = 0</span>, we have <span class="math inline">R(0; \hat{\mu}_\text{JS}) = 2</span> for all <span class="math inline">p \geq 2</span>. As <span class="math inline">||\mu||_2^2 \rightarrow \infty</span>, the risk approaches <span class="math inline">R(\mu; \hat{\mu}_\text{JS}) \rightarrow p</span>.</p></li>
</ul>
</section>
<section id="james-stein-estimator-iv" class="slide level2 center">
<h2>James-Stein estimator IV</h2>
<!-- - The James-Stein estimator is also [inadmissible]{.orange}. Note that $(1 - (p-2)/||\bm{Y}||_2^2)$ can be negative. Using its positive part, $(1 - (p-2)/||\bm{Y}||_2^2)_+$, gives a [uniformly better]{.blue} (inadmissible!) estimator.   -->
<ul>
<li><p>A useful <span class="orange">generalization</span> of the <span class="blue">James-Stein estimator</span> consists in <span class="orange">shrinking</span> the mean towards a <span class="blue">common value</span> <span class="math inline">m \in \mathbb{R}</span> rather than <span class="math inline">0</span>, giving <span class="math display">
\hat{\mu}_\text{JS}(m) = m + \left(1 - \frac{p-2}{||\bm{Y} - m||_2^2}\right)(\bm{Y} - m).
</span> It holds that <span class="math inline">R(\mu; \hat{\mu}_\text{JS}(m)) \le p - (p-2)^2/ (p - 2 + ||\mu - m||_2^2)</span>, therefore <span class="math inline">\hat{\mu}_\text{JS}(m)</span> <span class="blue">dominates</span> <span class="math inline">\hat{\mu}</span>.</p></li>
<li><p>Even better, if we <span class="orange">estimate</span> <span class="math inline">m</span> with the <span class="blue">arithmetic mean</span> of <span class="math inline">\bm{Y}</span>, that is <span class="math inline">\bar{Y} = (1/p) \sum_{j=1}^p Y_j</span>, we can obtain the following <span class="orange">shrinkage estimator</span>: <span class="math display">
\hat{\mu}_\text{shrink} = \bar{Y} + \left(1 - \frac{p-3}{||\bm{Y} - \bar{Y}||_2^2}\right)(\bm{Y} - \bar{Y}).
</span> Intuitively, <span class="math inline">p-3</span> is the appropriate constant as an additional parameter is estimated. Moreover, in <span class="citation" data-cites="Efron1975">Efron and Morris (<a href="#/references" role="doc-biblioref" onclick="">1975</a>)</span> it is proved that <span class="math display">
R(\mu; \hat{\mu}_\text{shrink}) \le p - \frac{(p-3)^2}{p - 3 + ||\mu - \bar{\mu}||_2^2},
</span> with <span class="math inline">\bar{\mu} = (1/p)\sum_{j=1}^p\mu_j</span>, again <span class="blue">dominating</span> the maximum likelihood <span class="math inline">\hat{\mu}</span>.</p></li>
</ul>
</section>
<section id="james-stein-estimator-v" class="slide level2 center">
<h2>James-Stein estimator V</h2>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>The James-Stein estimator is an empirical <span class="blue">Bayes estimator</span> in disguise. Let <span class="math inline">\bm{Y} \sim \text{N}_p(\mu, I_p)</span> and consider the <span class="orange">prior</span> <span class="math inline">\bm{\mu} \sim N_p(m, \tau^2 I_p)</span>. Then the <span class="orange">posterior mean</span> is <span class="math display">
\hat{\mu}_\text{Bayes} = m + \left(1 - \frac{1}{1 + \tau^2}\right)(\bm{Y} - m).
</span> James-Stein is an <span class="blue">empirical Bayes</span> approach: the quantity <span class="math inline">1/(1 + \tau^2)</span> is <span class="orange">estimated</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>In particular, under the Bayesian model <span class="math display">
||\bm{Y} - m||_2^2 = \sum_{j=1}^p(Y_j - m)^2 \sim (1 + \tau^2)\chi^2_p
</span> and therefore <span class="math inline">(p - 2)/(||\bm{Y} - m||_2^2)</span> is an an <span class="orange">unbiased estimate</span> for <span class="math inline">1 / (1 + \tau^2)</span>. In fact: <span class="math display">
\mathbb{E}\left(\frac{p - 2}{||\bm{Y} - m||_2^2}\right) = \frac{1}{1 + \tau^2}.
</span></p></li>
<li><p>Alternative estimates for <span class="math inline">1/(1 + \tau^2)</span> leads to <span class="blue">refined</span> James-Stein estimators.</p></li>
</ul>
</section>
<section id="efron-and-morris-1975" class="slide level2 center">
<h2>Efron and Morris (1975)</h2>
<div class="columns">
<div class="column" style="width:35%;">
<p><img data-src="img/efron.png"></p>
</div><div class="column" style="width:65%;">
<ul>
<li><p><span class="citation" data-cites="Efron1975">Efron and Morris (<a href="#/references" role="doc-biblioref" onclick="">1975</a>, JASA)</span> is a <span class="blue">classical paper</span> on the <span class="orange">practical relevance</span> of James-Stein‚Äôs estimator.</p></li>
<li><p>This approach was used in <span class="orange">sports analytics</span> to predict the batting averages of 18 major league players in 1970.</p></li>
<li><p>As expected, <span class="blue">shrinkage estimators</span> significantly improve upon the maximum likelihood estimator.</p></li>
<li><p>Stein‚Äôs estimator was <span class="math inline">3.50</span> times <span class="orange">more efficient</span> than the MLE in this case.</p></li>
<li><p>It also showcases a useful practical demonstration of <span class="orange">variance-stabilizing</span> transformations:</p>
<ul>
<li>The original data are proportions, i.e.&nbsp;arguably not Gaussians.</li>
<li>After a suitable transformations they can be approximately regarded as normal.</li>
</ul></li>
</ul>
</div></div>
</section>
<section id="efron-and-morris-1975-1" class="slide level2 center">
<h2>Efron and Morris (1975)</h2>
<div class="smaller">
<table class="caption-top">
<colgroup>
<col style="width: 4%">
<col style="width: 18%">
<col style="width: 16%">
<col style="width: 21%">
<col style="width: 20%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Name</th>
<th style="text-align: right;">At Bats <span class="math inline">n_i</span></th>
<th style="text-align: right;">Hits <span class="math inline">x_i</span></th>
<th style="text-align: right;">Mean <span class="math inline">\hat{p_i}</span></th>
<th style="text-align: right;">James-Stein</th>
<th style="text-align: right;">Rem. mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Clemente</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">0.400</td>
<td style="text-align: right;">0.290</td>
<td style="text-align: right;">0.346</td>
</tr>
<tr class="even">
<td style="text-align: left;">Robinson</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0.378</td>
<td style="text-align: right;">0.286</td>
<td style="text-align: right;">0.298</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Howard</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">0.356</td>
<td style="text-align: right;">0.282</td>
<td style="text-align: right;">0.276</td>
</tr>
<tr class="even">
<td style="text-align: left;">Johnstone</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">0.333</td>
<td style="text-align: right;">0.277</td>
<td style="text-align: right;">0.222</td>
</tr>
<tr class="odd">
<td style="text-align: left;">‚Ä¶</td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Williams</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">0.222</td>
<td style="text-align: right;">0.254</td>
<td style="text-align: right;">0.330</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Campaneris</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0.200</td>
<td style="text-align: right;">0.249</td>
<td style="text-align: right;">0.285</td>
</tr>
<tr class="even">
<td style="text-align: left;">Munson</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">0.178</td>
<td style="text-align: right;">0.244</td>
<td style="text-align: right;">0.316</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Alvis</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0.156</td>
<td style="text-align: right;">0.239</td>
<td style="text-align: right;">0.200</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><p>The batting averages <span class="math inline">\hat{p}_i</span> out of <span class="math inline">n_i</span> trials for <span class="math inline">n = 18</span> players have been <span class="orange">transformed</span> via <span class="math inline">y_i = \sqrt{n_i} \arcsin(2 p_i - 1)</span>. The <span class="blue">James-Stein estimator</span> is applied to <span class="math inline">y_i</span> and then transformed back.</p></li>
<li><p>The <span class="orange">shrinkage effect</span> is evident and provides a better estimate of the <span class="blue">remaining batting average</span> for the season.</p></li>
</ul>
</section>
<section id="james-stein-estimator-vi" class="slide level2 center">
<h2>James-Stein estimator VI</h2>
<ul>
<li><p>James-Stein estimators were initially seen with suspicion:</p>
<ul>
<li>How come that deliberately introducing <span class="orange">bias</span> improves the estimates?<br>
</li>
<li>How come that <span class="orange">learning from the experience of other</span> points can modify and even improve the individual estimates?</li>
</ul></li>
<li><p>These ideas are nowadays well established:</p>
<ul>
<li>Modern <span class="blue">shrinkage estimators</span> such as <span class="orange">ridge regression</span> and <span class="orange">lasso</span> are widely used.<br>
</li>
<li>The notion of <span class="blue">borrowing of information</span> is at the heart of <span class="blue">random effects models</span>.</li>
</ul></li>
<li><p>The James-Stein theorem rigorously confirms the theoretical relevance of <span class="blue">indirect information</span>. Remarkably, this is based on <span class="orange">frequentist criteria</span> rather than Bayesian ones.</p></li>
<li><p>A <span class="blue">simple proof</span> of the James-Stein theorem can be found in <span class="citation" data-cites="Efron2010">Efron (<a href="#/references" role="doc-biblioref" onclick="">2010</a>)</span>; see also <span class="citation" data-cites="Efron2016">Efron and Hastie (<a href="#/references" role="doc-biblioref" onclick="">2016</a>)</span> for a modern and accessible perspective or <a href="https://www.statslab.cam.ac.uk/~rjs57/SteinParadox.pdf">this divulgative article</a>.</p></li>
</ul>
</section>
<section id="criticism-to-the-risk-function-approach" class="slide level2 center">
<h2>Criticism to the risk function approach</h2>
<ul>
<li>Some authors, such as <span class="citation" data-cites="Robert1994">Robert (<a href="#/references" role="doc-biblioref" onclick="">1994</a>)</span>, have <span class="orange">criticized</span> the risk function approach for comparing estimators. The main arguments are the following:</li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li><p>The frequentist paradigm evaluates estimators based on their <span class="blue">long-run performance</span>, without accounting for the given observations <span class="math inline">\bm{Y}</span>. A client may wish for <span class="blue">optimal results</span> for the observed data, and <span class="orange">not someone else‚Äôs data</span>.</p></li>
<li><p>The risk function approach implicitly assumes the <span class="blue">repeatability</span> of the <span class="blue">experiment</span>, which has sparked controversy, especially among Bayesian statisticians.</p></li>
<li><p>For instance, if new observations come to the statistician, she should make use of them, potentially modifying the way the experiment is conducted, as in medical trials.</p></li>
<li><p>The risk function depends on <span class="math inline">\theta</span>, preventing a <span class="blue">total ordering</span> of the estimators. Comparisons are difficult unless a <span class="blue">uniformly optimal</span> procedure exists, which is <span class="orange">rare</span>.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="integrated-risk" class="slide level2 center">
<h2>Integrated risk</h2>
<ul>
<li>Let us begin by finding a criterion that induces <span class="orange">total ordering</span> among estimators. A potential solution is taking the <span class="blue">average</span> risk function over values of <span class="math inline">\theta</span>.</li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Let <span class="math inline">R(\theta, \hat{\theta}) = \mathbb{E}_\theta\{\mathscr{L}(\theta,\hat{\theta})\}</span> be the <span class="orange">risk function</span>, and let <span class="math inline">\pi(\mathrm{d}\theta)</span> be a probability measure <span class="orange">weighting</span> the relevance of each <span class="math inline">\theta</span>. Then<br>
<span class="math display">
r(\pi, \hat{\theta}) = \int_\Theta R(\theta; \hat{\theta}) \pi(\mathrm{d}\theta),
</span> is called <span class="blue">integrated risk</span> or <span class="orange">Bayes risk</span>.</p>
</div>
</div>
</div>
<ul>
<li>Thus, an estimator <span class="math inline">\hat{\theta}</span> is <span class="blue">preferable</span> over another <span class="math inline">\tilde{\theta}</span> if <span class="math inline">r(\pi, \hat{\theta}) &lt; r(\pi, \tilde{\theta})</span>. Moreover, if <span class="math inline">\hat{\theta}</span> <span class="orange">dominates</span> <span class="math inline">\tilde{\theta}</span>, that is if <span class="math inline">\tilde{\theta}</span> is <span class="orange">inadmissible</span>, then <span class="math inline">r(\pi, \hat{\theta}) &lt; r(\pi, \tilde{\theta})</span> for any choice of weights.</li>
</ul>
</section>
<section id="example-integrated-risk-of-binomial-estimators" class="slide level2 center">
<h2>Example: integrated risk of binomial estimators üìñ</h2>
<ul>
<li><p>Let us consider the estimation of the <span class="blue">probability</span> <span class="math inline">p</span> from a <span class="binomial">binomial experiment</span> using the maximum likelihood <span class="math inline">\hat{p} = n_1/n</span> and the Bayesian <span class="math inline">\hat{p}_\text{minimax} = (n_1 + 0.5\sqrt{n})/(n + \sqrt{n})</span> estimators.</p></li>
<li><p>We previously computed the <span class="orange">mean squared error</span> for both estimators. Let us now compute the integrated risk, assuming <span class="blue">uniform weights</span> <span class="math inline">\pi(\mathrm{d}p) = \mathrm{d}p</span>, i.e., a <span class="orange">simple average</span> of the MSE.</p></li>
<li><p>The <span class="blue">integrated risk</span> of the <span class="orange">maximum likelihood</span> estimator is<br>
<span class="math display">
r(\pi, \hat{p}) = \int_0^1 \mathbb{E}_p\{(\hat{p} - p)^2\}\mathrm{d}p = \frac{1}{n}\int_0^1 p(1-p)\mathrm{d}p= \frac{1}{6n}.
</span></p></li>
<li><p>The <span class="blue">integrated risk</span> of the <span class="orange">Bayes estimator</span> coincides with the risk function, the latter being <span class="orange">constant</span> over <span class="math inline">p</span>:<br>
<span class="math display">
r(\pi, \hat{p}_\text{minimax}) = \int_0^1 \mathbb{E}_p\{(\hat{p}_\text{minimax} - p)^2\}\mathrm{d}p = \int_0^1\frac{n}{4 ( n + \sqrt{n})^2}\mathrm{d}p= \frac{n}{4 ( n + \sqrt{n})^2}.
</span></p></li>
<li><p>Depending on the sample size <span class="math inline">n</span>, one estimator may be preferable over the other.</p></li>
</ul>
</section>
<section id="example-integrated-risk-of-binomial-estimators-1" class="slide level2 center">
<h2>Example: integrated risk of binomial estimators</h2>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-13-1.png" class="quarto-figure quarto-figure-center r-stretch" width="1800"><ul>
<li>According to the integrated risk and using constant weights <span class="math inline">\pi(\mathrm{d}p) = \mathrm{d}p</span> one should <span class="orange">prefer</span> <span class="math inline">\hat{p}</span> over <span class="math inline">\hat{p}_\text{minimax}</span> when <span class="math inline">n \ge 20</span> and viceversa.</li>
</ul>
</section>
<section id="bayesian-estimators-minimize-the-integrated-risk" class="slide level2 center">
<h2>Bayesian estimators minimize the integrated risk üìñ</h2>
<ul>
<li><p>The integrated risk is a sensible criterion for comparing estimators, provided a suitable set of weights <span class="math inline">\pi</span> is selected. Hence, we may wish to find its <span class="orange">minimizer</span>.</p></li>
<li><p>There is a surprisingly simple and elegant answer to this apparently difficult question.</p></li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 1.1 in Chap. 4)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\pi(\mathrm{d}\theta)</span> be the <span class="orange">prior distribution</span> for <span class="math inline">\theta</span>. The <span class="orange">minimizer</span> of the <span class="blue">posterior expected loss</span>, if a unique solution exists, is called <span class="blue">Bayes estimator</span>. Moreover: <span class="math display">
\hat{\theta}_\text{Bayes}(\bm{Y}) = \arg\min_{\tilde{\theta} \in \Theta} \int_\Theta \mathscr{L}(\theta, \tilde{\theta}(\bm{Y}))\pi(\mathrm{d}\theta \mid \bm{Y}) = \arg\min_{\tilde{\theta} \in \Theta} r(\pi, \tilde{\theta}(\bm{Y})),
</span> which means <span class="math inline">\hat{\theta}_\text{Bayes}</span> coincides with minimizer of the <span class="orange">integrated risk</span>, provided <span class="math inline">r(\pi, \hat{\theta}_\text{Bayes}) &lt; \infty</span>.</p>
</div>
</div>
</div>
<ul>
<li>This fundamental theorem provides a <span class="blue">decision-theoretic justification</span> to Bayesian estimators as well as a practical recipe for finding them.</li>
</ul>
</section>
<section id="decision-theoretic-justification-of-the-posterior-mean" class="slide level2 center">
<h2>Decision-theoretic justification of the posterior mean üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Corollary (<span class="citation" data-cites="Robert1994">Robert (<a href="#/references" role="doc-biblioref" onclick="">1994</a>)</span>, Proposition 2.5.1)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}^p</span>, then the <span class="blue">Bayes estimator</span> associated with prior distribution <span class="math inline">\pi</span> and <span class="blue">quadratic loss</span> <span class="math inline">\mathscr{L}(\theta, \hat{\theta}) = ||\hat{\theta} -\theta||_2^2</span> is the <span class="orange">posterior mean</span>: <span class="math display">
\hat{\theta}_\text{Bayes}(\bm{Y}) = \arg\min_{\tilde{\theta} \in \Theta} \int_\Theta ||\tilde{\theta}(\bm{Y}) - \theta||_2^2\pi(\mathrm{d}\theta \mid \bm{Y}) = \mathbb{E}(\theta \mid \bm{Y}).
</span> If the posterior mean exists, the Bayes estimator is <span class="blue">unique</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>Hence, the <span class="orange">posterior mean</span> is <span class="blue">optimal</span> in the sense that minimizes the posterior expected loss and therefore also the integrated risk.</p></li>
<li><p>This theorem extends to various loss functions. For instance if <span class="math inline">\mathscr{L}(\theta, \hat{\theta}) = ||\hat{\theta} - \theta||_1</span> then the <span class="blue">Bayes estimator</span> is the <span class="orange">posterior median</span>.</p></li>
</ul>
</section>
<section id="example-integrated-risk-of-binomial-estimators-2" class="slide level2 center">
<h2>Example: integrated risk of binomial estimators üìñ</h2>
<ul>
<li><p>We previously considered the estimators <span class="math inline">\hat{p} = n_1/n</span> and <span class="math inline">\hat{p}_\text{minimax} = (n_1 + 0.5\sqrt{n})/(n + \sqrt{n})</span>. Assuming <span class="blue">uniform weights</span>, neither <span class="math inline">\hat{p}</span> nor <span class="math inline">\hat{p}_\text{minimax}</span> minimizes the integrated risk.</p></li>
<li><p>In fact, theoretical results indicate that the <span class="blue">unique minimizer</span> is the <span class="orange">posterior mean</span> of <span class="math inline">p</span> for a binomial model under a <span class="orange">uniform prior</span> <span class="math inline">\pi(\mathrm{d}p) = \mathrm{d}p</span>. The optimal estimator is: <span class="math display">
p \mid \bm{Y} \sim \text{Beta}(n_1 + 1, n - n_1 + 1) \implies \hat{p}_\text{Bayes} = \mathbb{E}(p \mid \bm{Y}) = \frac{n_1 + 1}{n + 2}.
</span></p></li>
<li><p>After some simple but tedious calculations, we obtain the associated <span class="orange">mean squared error</span>:<br>
<span class="math display">
R(p; \hat{p}_\text{Bayes}) = \left(\frac{2}{n+2}\right)^2(1/2 - p)^2 + \left(\frac{n}{n+2}\right)^2 \frac{p(1-p)}{n}.
</span></p></li>
<li><p>Integrating with respect to the <span class="blue">uniform prior</span> distribution, we obtain the <span class="orange">integrated risk</span>: <span class="math display">
r(\pi, \hat{p}_\text{Bayes}) = \int_0^1 R(p; \hat{p}_\text{Bayes})\mathrm{d}p = \frac{1}{6 (n+2)},
</span> which is indeed <span class="orange">smaller</span> than <span class="math inline">r(\pi, \hat{p})</span> and <span class="math inline">r(\pi, \hat{p}_\text{minimax})</span>.</p></li>
</ul>
</section>
<section id="example-integrated-risk-of-binomial-estimators-3" class="slide level2 center">
<h2>Example: integrated risk of binomial estimators</h2>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-14-1.png" class="quarto-figure quarto-figure-center r-stretch" width="1800"></section>
<section id="admissibility-of-bayesian-estimators" class="slide level2 center">
<h2>Admissibility of Bayesian estimators üìñ</h2>
<ul>
<li>The next theorem provides a strong <span class="orange">frequentist justification</span> for <span class="blue">Bayesian estimators</span>.</li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 2.4 in Chap. 5)</strong></p>
</div>
<div class="callout-content">
<p>Any unique Bayesian estimator is <span class="blue">admissible</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>The uniqueness assumption is a technical condition often satisfied in practice. Under <span class="blue">squared loss</span>, or any other strictly convex loss, this holds automatically, provided the <span class="orange">estimator exists</span>.</p></li>
<li><p>If the loss is strictly convex, such as the squared error loss, and the integrated risk is finite, this theorem remains valid even when using <span class="orange">improper priors</span> (<span class="citation" data-cites="Robert1994">Robert (<a href="#/references" role="doc-biblioref" onclick="">1994</a>)</span>, Proposition 2.4.25).</p></li>
<li><p><span class="blue">Admissibility</span> is a <span class="orange">minimum requirement</span>: even constant estimators are admissible.</p></li>
<li><p>Nonetheless, the risk function approach dictates that inadmissible estimators should be discarded. This is non-trivial in practice, as evidenced by the James-Stein saga.</p></li>
</ul>
</section>
<section id="minimax-estimators" class="slide level2 center">
<h2>Minimax estimators</h2>
<ul>
<li><p>The <span class="blue">minimax</span> criterion is an alternative to the integrated risk for <span class="orange">discriminating</span> among (admissible) <span class="blue">estimators</span>. It comes from game theory, where two adversaries are competing.</p></li>
<li><p>Instead of considering the ‚Äúaverage‚Äù risk over <span class="math inline">\theta</span> (integrated risk), the minimax criterion evaluates the <span class="blue">risk function</span> of estimators in the <span class="orange">worst-case scenario</span>.</p></li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>An estimator <span class="math inline">\hat{\theta}_\text{minimax}</span> which <span class="blue">minimizes</span> the <span class="orange">maximum</span> risk, that is, which satisfies <span class="math display">
\sup_{\theta \in \Theta} R(\theta; \hat{\theta}_\text{minimax}) =\inf_{\hat{\theta}} \sup_{\theta \in \Theta} R(\theta; \hat{\theta}),
</span> is called <span class="orange">minimax estimator</span>. The quantity <span class="math inline">\sup_\theta R(\theta; \hat{\theta}_\text{minimax})</span> is called <span class="blue">minimax risk</span>.</p>
</div>
</div>
</div>
<ul>
<li>In general, <span class="orange">finding minimax</span> estimators is <span class="orange">difficult</span>. Moreover, the resulting estimators are not necessarily very appealing in practice.</li>
</ul>
</section>
<section id="example-mse-of-binomial-estimators-minimax" class="slide level2 center">
<h2>Example: MSE of binomial estimators (minimax)</h2>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-15-1.png" class="quarto-figure quarto-figure-center r-stretch" width="1800"><ul>
<li><p>We will show that <span class="math inline">\hat{p}_\text{minimax} = (n_1 + 0.5\sqrt{n})/(n + \sqrt{n})</span> is indeed the <span class="orange">minimax estimator</span>. However, this is a very <span class="blue">conservative</span> choice.</p></li>
<li><p>One could argue that the maximum likelihood <span class="math inline">\hat{p} = n_1/n</span> is the preferred choice in practice, especially when <span class="math inline">n</span> is large enough, even though it has slightly higher risk when <span class="math inline">p \approx 1/2</span>.</p></li>
</ul>
<!-- ## Minimax and Bayesian estimators -->
<!-- :::callout-note -->
<!-- #### Least favorable prior -->
<!-- Let $\hat{\theta}_\text{Bayes}$ and $\tilde{\theta}_\text{Bayes}$ be [optimal Bayes estimators]{.orange} for a given model under [prior]{.orange} distributions $\pi(\mathrm{d}\theta)$ and $\tilde{\pi}(\mathrm{d}\theta)$, respectively. We will say  $\pi(\mathrm{d}\theta)$ is [least favorable]{.blue} if its itegrated risk -->
<!-- $$ -->
<!-- r(\pi, \hat{\theta}_\text{Bayes}) = \int_\Theta R(\theta; \hat{\theta}_\text{Bayes})\pi(\mathrm{d}\theta) \ge \int_\Theta R(\theta; \tilde{\theta}_\text{Bayes})\tilde{\pi}(\mathrm{d}\theta) = r(\tilde{\pi}, \tilde{\theta}_\text{Bayes}). -->
<!-- $$ -->
<!-- for any other prior distribution $\tilde{\pi}(\mathrm{d}\theta)$.  -->
<!-- ::: -->
<!-- ::: callout-warning -->
<!-- #### Lemma (@Robert1994, Lemma 2.4.10) -->
<!-- Let $\pi(\mathrm{d}\theta)$ be the [least favorable]{.blue}  prior. Then the integrated risk is smaller than the minimax risk: -->
<!-- $$ -->
<!-- r(\pi, \hat{\theta}_\text{Bayes}) \le \inf_{\hat{\theta}} \sup_{\theta \in \Theta} R(\theta; \hat{\theta}) \le \sup_{\theta \in \Theta} R(\theta; \hat{\theta}_\text{Bayes}). -->
<!-- $$ -->
<!-- Clearly, the same hold for any other prior choice $\tilde{\pi}$.  -->
<!-- ::: -->
</section>
<section id="minimax-and-bayesian-estimators" class="slide level2 center">
<h2>Minimax and Bayesian estimators üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 1.4, Chap. 5)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\pi(\mathrm{d}\theta)</span> be a prior distribution and <span class="math inline">\hat{\theta}_\text{Bayes}</span> be the <span class="blue">unique Bayes</span> estimator. If it holds <span class="math display">
r(\pi, \hat{\theta}_\text{Bayes}) = \sup_\theta R(\theta; \hat{\theta}_\text{Bayes}),
</span> then:</p>
<ul>
<li><p>the Bayes estimator <span class="math inline">\hat{\theta}_\text{Bayes}</span> is also the <span class="orange">unique minimax</span> estimator.</p></li>
<li><p>the prior <span class="math inline">\pi(\mathrm{d}\theta)</span> is <span class="blue">least favorable</span>, meaning that <span class="math inline">r(\pi, \hat{\theta}_\text{Bayes})\ge r(\tilde{\pi}, \tilde{\theta}_\text{Bayes})</span> for any other prior <span class="math inline">\tilde{\pi}(\mathrm{d}\theta)</span> and Bayes estimator <span class="math inline">\tilde{\theta}_\text{Bayes}</span>.</p></li>
</ul>
</div>
</div>
</div>
<ul>
<li><p><span class="orange">Remark</span>. The above condition states the average of <span class="math inline">R(\theta; \hat{\theta}_\text{Bayes})</span> is equal to its maximum. This will be the case when the risk function <span class="orange">constant</span> over <span class="math inline">\theta</span>.</p></li>
<li><p>More generally, if an <span class="blue">admissible estimator</span> has <span class="orange">constant risk</span>, is the unique <span class="orange">minimax</span> estimator (<span class="citation" data-cites="Robert1994">Robert (<a href="#/references" role="doc-biblioref" onclick="">1994</a>)</span>, Proposition 2.4.21).</p></li>
</ul>
</section></section>
<section>
<section id="unbiasedness" class="title-slide slide level1 center">
<h1>Unbiasedness</h1>

</section>
<section id="unbiased-estimators" class="slide level2 center">
<h2>Unbiased estimators</h2>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>An estimator <span class="math inline">\hat{\theta}</span> is <span class="blue">unbiased</span> for <span class="math inline">\theta</span> if <span class="math inline">\mathbb{E}_\theta(\hat{\theta}) = \theta</span>, that is, if <span class="math inline">\text{bias}_\theta(\hat{\theta}) = \mathbb{E}_\theta(\hat{\theta} - \theta) = 0</span> for all <span class="math inline">\theta \in \Theta</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>We often teach that <span class="orange">unbiasedness</span> is a natural and appealing property of an estimator. If <span class="math inline">\Theta \subseteq \mathbb{R}</span> and under <span class="blue">squared error loss</span>, unbiasedness implies that<br>
<span class="math display">R(\theta;\hat{\theta}) = \mathbb{E}_\theta\{(\hat{\theta} - \theta)^2\} = \text{var}_\theta(\hat{\theta}).</span></p></li>
<li><p>There are two main reasons for emphasizing unbiasedness:</p>
<ul>
<li>It is often possible to find the uniformly ‚Äúbest‚Äù unbiased estimator, e.g., the one with the lowest variance (<span class="orange">UMVU estimator</span>).</li>
<li>For an estimator to be <span class="grey">consistent</span>, it must be at least <span class="blue">asymptotically unbiased</span>.</li>
</ul></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Unbiasedness is not a negative property per se. However, one may overlook better estimators by focusing too narrowly on this special class. Indeed, the <span class="blue">UMVUE</span> can even be <span class="orange">inadmissible</span>.</p>
</div>
</div>
</div>
</section>
<section id="nonexistence-of-unbiased-estimators" class="slide level2 center">
<h2>Nonexistence of unbiased estimators</h2>
<ul>
<li><p>Certain quantities <span class="orange">do not admit unbiased</span> estimators, even though they can be accurately estimated using <span class="blue">slightly biased</span> estimators.</p></li>
<li><p>Let <span class="math inline">Y \sim \text{Bin}(n, p)</span> and suppose we wish to find an estimator <span class="math inline">\hat{\psi}(Y)</span> for the reparametrization <span class="math inline">\psi = 1 / p</span>. Then unbiasedness of an estimator <span class="math inline">\hat{\psi}(Y)</span> would require <span class="math display">
\sum_{k=0}^n \hat{\psi}(k)\binom{n}{k}p^k(1-p)^{n -k} = \frac{1}{p}, \qquad p \in (0, 1).
</span> Such an estimator <span class="orange">does not exist</span>!</p></li>
<li><p>Indeed, the left hand side of this equation is a <span class="blue">polynomial</span> <span class="math inline">p</span> with degree at most <span class="math inline">n</span>. However, <span class="math inline">1/p</span> cannot be written as a polynomial.</p></li>
<li><p>Nonetheless, the <span class="blue">slightly biased</span> estimator <span class="math inline">\hat{\psi} = n / n_1</span> will be close to <span class="math inline">1/p</span> with high probability as <span class="math inline">n</span> increases.</p></li>
</ul>
</section>
<section id="bayesian-estimators-and-unbiasedness" class="slide level2 center">
<h2>Bayesian estimators and unbiasedness üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 2.3, Chap. 4)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}^p</span> and <span class="math inline">\hat{\theta}_\text{Bayes}(\bm{Y})</span> be the unique Bayes estimator with prior <span class="math inline">\pi</span> under a <span class="orange">squared error loss</span>. If <span class="math inline">\hat{\theta}_\text{Bayes}</span> is <span class="blue">unbiased</span> then its integrated risk is <span class="math display">
r(\pi, \hat{\theta}_\text{Bayes}) = 0.
</span></p>
</div>
</div>
</div>
<ul>
<li><p>The above theorem is a formal way of saying that, apart from trivial cases, posterior means are <span class="orange">never unbiased</span> estimators.</p></li>
<li><p>However, the <span class="orange">bias</span> comes with a <span class="blue">reduced variance</span>, therefore the trade-off could be favorable. This is guaranteed to occur because Bayesian estimators are admissible.</p></li>
<li><p>Moreover, under mild regularity conditions, Bayesian estimators are <span class="blue">asymptotically unbiased</span>.</p></li>
</ul>
</section>
<section id="example-poisson-unbiased-estimation" class="slide level2 center">
<h2>Example: Poisson unbiased estimation</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be i.i.d. <span class="math inline">\text{Poisson}(\lambda)</span>, and let <span class="math inline">\bar{Y} = n^{-1} \sum_{i=1}^n Y_i</span> and <span class="math inline">S^2 = (n-1)^{-1} \sum_{i=1}^n (Y_i - \bar{Y})^2</span> be the <span class="blue">sample mean</span> and <span class="orange">sample variance</span>, respectively.</p></li>
<li><p>It can be shown<sup>1</sup> that both estimators are <span class="orange">unbiased</span>, meaning <span class="math display">
\mathbb{E}(\bar{Y}) = \mathbb{E}(S^2) = \lambda, \quad \text{for all } \lambda.
</span></p></li>
<li><p>To determine which estimator, <span class="math inline">\bar{Y}</span> or <span class="math inline">S^2</span>, is preferable, we should <span class="blue">compare their variances</span>. It is also well known that <span class="math inline">\text{var}_\lambda(\bar{Y}) = \lambda / n</span>, whereas computing <span class="math inline">\text{var}_\lambda(S^2)</span> can be <span class="orange">lengthy</span>.</p></li>
<li><p>It holds that <span class="math inline">\text{var}_\lambda(\bar{Y}) &lt; \text{var}_\lambda(S^2)</span> for all <span class="math inline">\lambda</span>. This implies that <span class="math inline">S^2</span> is <span class="orange">inadmissible</span>.</p></li>
<li><p>However, we can construct <span class="blue">infinitely</span> many <span class="blue">unbiased estimators</span> of <span class="math inline">\lambda</span>: <span class="math display">
\hat{\lambda}_a = a \bar{Y} + (1 - a) S^2, \quad 0 &lt; a &lt; 1.
</span> Is there a value of <span class="math inline">a</span> such that <span class="math inline">\text{var}_\lambda(\hat{\lambda}_a) \leq \text{var}_\lambda(\bar{Y})</span>? What about other unbiased estimators?</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn11"><p>These are basic and well-known results: see Theorem 5.2.6 in <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>.</p></li></ol></aside></section>
<section id="umvu-estimators" class="slide level2 center">
<h2>UMVU estimators</h2>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>In this subsection on <span class="orange">unbiasedness</span>, we will often assume that <span class="math inline">\Theta \subseteq \mathbb{R}</span>. All the results presented here extend to the <span class="blue">vector case</span>, though at the cost of heavier notation.</p>
</div>
</div>
</div>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}</span>. An estimator <span class="math inline">\hat{\theta}</span> is a <span class="blue">best unbiased estimator</span> of <span class="math inline">\theta</span> if it satisfies <span class="math inline">\mathbb{E}_\theta(\hat{\theta}) = \theta</span> for all <span class="math inline">\theta</span> (unbiasdness) and, for any <span class="orange">other unbiased</span> estimator <span class="math inline">\tilde{\theta}</span>, we have <span class="math display">
\text{var}_\theta(\hat{\theta}) \le \text{var}_\theta(\tilde{\theta}), \qquad \text {for all } \theta \in \Theta.
</span> The estimator <span class="math inline">\hat{\theta}</span> is also called <span class="orange">uniform minimum variance unbiased estimator</span> (UMVUE) of <span class="math inline">\theta</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>The UMVUE <span class="orange">does not necessarily exist</span>. If it does, <span class="blue">finding it</span> is not easy. And even if a unique UMVUE exists, it could still be <span class="orange">inadmissible</span>‚Äìrecall the James-Stein saga.</p></li>
<li><p>The success of UMVUE estimators is tied to two illuminating and elegant theorems: <span class="blue">Cram√©r-Rao</span> and <span class="orange">Rao-Blackwell</span>, which connect likelihood theory, sufficiency, and unbiasedness.</p></li>
</ul>
</section>
<section id="cram√©r-rao-inequality" class="slide level2 center">
<h2>Cram√©r-Rao inequality üìñ</h2>
<ul>
<li>The Cram√©r-Rao theorem establishes a <span class="blue">lower bound</span> for the variance of an estimator. Thus, if the variance of an unbiased estimator <span class="math inline">\hat{\theta}</span> attains the lower bound for all <span class="math inline">\theta</span>, then <span class="math inline">\hat{\theta}</span> is <span class="orange">UMVUE</span>.</li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (Cram√©r-Rao, Theorem 7.3.9 in <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a sample from a joint probability measure <span class="math inline">f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y})</span> and let <span class="math inline">\Theta \subseteq \mathbb{R}</span>. Moreover, let <span class="math inline">\hat{\theta}(\bm{Y})</span> be an estimator of <span class="math inline">\theta</span> satisfying <span class="math display">
1 + b^*(\theta) := \frac{\partial}{\partial \theta}\int \hat{\theta}(\bm{y})f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y}) = \int \frac{\partial}{\partial \theta} \hat{\theta}(\bm{y})f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y}),
</span> and with finite variance <span class="math inline">\text{var}_\theta(\hat{\theta}(\bm{Y})) &lt; \infty</span>. Then <span class="math display">
\text{var}_\theta(\hat{\theta}(\bm{Y})) \ge \frac{[1 + b^*(\theta)]^2}{\mathbb{E}_\theta(\ell^*(\theta)^2)}.
</span> Moreover, if <span class="math inline">\hat{\theta}</span> is an <span class="orange">unbiased</span> estimator for <span class="math inline">\theta</span>, then <span class="math inline">b^*(\theta) = 0</span> and <span class="math inline">\text{var}(\hat{\theta}(\bm{Y})) \ge 1/\mathbb{E}_\theta(l^*(\theta)^2)</span> .</p>
</div>
</div>
</div>
</section>
<section id="cram√©r-rao-considerations" class="slide level2 center">
<h2>Cram√©r-Rao: considerations</h2>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li><p>The interchange of the derivative under the integral sign is an important <span class="orange">condition</span>, not merely a technical artifact of the proof.</p></li>
<li><p>For example, if the <span class="blue">sample space</span> of i.i.d. random variables <span class="math inline">Y_i</span> <span class="blue">depends on <span class="math inline">\theta</span></span>, such condition is violated, and the Cram√©r-Rao lower bound may not hold.<sup>1</sup></p></li>
</ul>
</div>
</div>
</div>
<ul>
<li>The Cram√©r-Rao inequality is sometimes called <span class="orange">information inequality</span>. In fact <span class="math inline">I(\theta)</span> defined as: <span class="math display">
I(\theta) := \mathbb{E}_\theta(\ell^*(\theta)^2),
</span> is called <span class="blue">Fisher information</span> or information number. This reflects the fact that as more information become available, the bound on the variance gets smaller.</li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>If <span class="math inline">W(\bm{Y})</span> is an unbiased estimator of a <span class="blue">transformation</span> <span class="math inline">g(\theta)</span>, then the Cram√©r-Rao theorem holds as stated, but the term <span class="math inline">\frac{\partial}{\partial \theta}\mathbb{E}_\theta(W(\bm{Y})) = 1 + b^*(\theta)</span> is not related to the ‚Äúbias‚Äù.</p>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn12"><p>See Example 7.3.13 in <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>, for a simple and illuminating example.</p></li></ol></aside></section>
<section id="bartlett-identities-i" class="slide level2 center">
<h2>Bartlett identities I üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>First Bartlett identity</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a sample from a joint probability measure <span class="math inline">f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y})</span> and let <span class="math inline">\Theta \subseteq \mathbb{R}</span>. If we can interchange derivation and integration, namely <span class="math display">\frac{\partial}{\partial \theta}\int f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y}) = \int \frac{\partial}{\partial \theta} f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y}), \tag{C.1}
</span> then <span class="math display">
\mathbb{E}_\theta(\ell^*(\theta)) = 0,\qquad \text{implying}\qquad  I(\theta) = \mathbb{E}_\theta(\ell^*(\theta)^2) = \text{var}_\theta(\ell^*(\theta)).
</span></p>
</div>
</div>
</div>
<ul>
<li>Thus, the regularity condition of Cram√©r-Rao implies that the score function <span class="math inline">\ell^*(\theta)</span> is un <span class="blue">unbiased estimating equation</span>.</li>
</ul>
</section>
<section id="bartlett-identities-ii" class="slide level2 center">
<h2>Bartlett identities II üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Second Bartlett identity</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a sample from a joint probability measure <span class="math inline">f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y})</span> and let <span class="math inline">\Theta \subseteq \mathbb{R}</span>. If we can interchange <span class="orange">twice</span> derivation and integration, namely <span class="math display">
\frac{\partial}{\partial \theta}\int f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y}) = \int \frac{\partial}{\partial \theta} f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y}), \tag{C.1}
</span> <span class="math display">
\frac{\partial^2}{\partial^2 \theta}\int f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y}) = \int \frac{\partial^2}{\partial^2 \theta}f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y}), \tag{C.2}
</span> then <span class="math display">
I(\theta) = \mathbb{E}_\theta(\ell^*(\theta)^2) =\text{var}_\theta(\ell^*(\theta))= \mathbb{E}_\theta\left(-\frac{\partial^2}{\partial^2 \theta}\ell(\theta)\right).
</span></p>
</div>
</div>
</div>
<ul>
<li>Both conditions are true in <span class="orange">regular exponential</span> families. This also clarifies that, in regular models, Fisher information relates to the <span class="blue">curvature</span> of the log-likelihood.</li>
</ul>
</section>
<section id="cram√©r-rao-iid-and-regular-case" class="slide level2 center">
<h2>Cram√©r-Rao: iid and regular case</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (Cram√©r-Rao, simplified)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid sample from <span class="math inline">f(y \mid \theta)\mathrm{d}y</span> satisfying conditions <span class="blue">C.1</span> and <span class="blue">C.2</span>, and let <span class="math inline">\Theta \subseteq \mathbb{R}</span>. Moreover, let <span class="math inline">\hat{\theta}(\bm{Y})</span> be an <span class="orange">unbiased</span> estimator of <span class="math inline">\theta</span> with finite variance <span class="math inline">\text{var}(\hat{\theta}(\bm{Y})) &lt; \infty</span>. Then <span class="math display">
\text{var}_\theta(\hat{\theta}(\bm{Y})) \ge \frac{1}{n i(\theta)}, \qquad i(\theta) = -\int \left[\frac{\partial^2}{\partial^2 \theta}\log{f(y \mid \theta)}\right]f(y\mid\theta)\mathrm{d}y.
</span></p>
</div>
</div>
</div>
<ul>
<li><p>The Fisher information is the <span class="blue">sum</span> of <span class="blue">individual contributions</span> <span class="math inline">I(\theta) = i(\theta) + \cdots + i(\theta) = n i(\theta)</span>.</p></li>
<li><p>It can be shown<sup>1</sup> that <span class="blue">attainment</span>, that is the equality <span class="math inline">\text{var}(\hat{\theta}(\bm{Y})) = 1/ni(\theta)</span>, occurs if and only if <span class="math inline">f(y \mid \theta)</span> is the density of an <span class="orange">exponential family</span>.</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn13"><p>See Theorem 5.12, Chap.2, <span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>.</p></li></ol></aside></section>
<section id="example-poisson-unbiased-estimation-1" class="slide level2 center">
<h2>Example: Poisson unbiased estimation üìñ</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be i.i.d. <span class="math inline">\text{Poisson}(\lambda)</span>. The sample mean <span class="math inline">\bar{Y}</span> is <span class="orange">unbiased</span> for <span class="math inline">\lambda</span> and <span class="math inline">\text{var}_\lambda(\bar{Y}) = \lambda / n</span>.</p></li>
<li><p>We can use Cram√©r-Rao to show this estimator is a <span class="blue">UMVUE</span>. The regularity conditions are satisfied and therefore, after some calculus <span class="math display">
i(\lambda) = -\mathbb{E}_\lambda\left(\frac{\partial}{\partial \lambda^2}\log{f(y \mid \lambda)}\right) = \mathbb{E}_\lambda\left(\frac{Y}{\lambda^2}\right) = \frac{1}{\lambda}.
</span></p></li>
<li><p>Hence, <span class="orange">Cram√©r-Rao</span> theorem states that for any unbiased estimator <span class="math inline">\hat{\lambda}(\bm{Y})</span> <span class="math display">
\text{var}_\lambda(\hat{\lambda}) \ge \frac{\lambda}{n},
</span> implying that <span class="math inline">\bar{Y}</span> is a <span class="blue">UMVUE</span> because <span class="math inline">\text{var}_\lambda(\bar{Y}) = \lambda/n</span>.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li><p>Cram√©r-Rao theorem does not imply that <span class="math inline">\bar{Y}</span> is the <span class="orange">unique</span> UMVUE.</p></li>
<li><p>However, this is guaranteed by Theorem 7.3.19 in <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>: if a <span class="blue">UMVUE</span> exists, it is <span class="orange">unique</span>.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="cram√©r-rao-multiparameter-case" class="slide level2 center">
<h2>Cram√©r-Rao, multiparameter case</h2>
<ul>
<li><p>The Cram√©r-Rao theorem naturally extends to the <span class="orange">vector case</span>, that is, when <span class="math inline">\Theta \subseteq \mathbb{R}^p</span>.</p></li>
<li><p>The <span class="orange">regularity conditions</span> <span class="blue">C.1</span> and <span class="blue">C.2</span> extend to the vector case, leading to the multiparameter <span class="blue">Bartlett identities</span>: <span class="math display">
\mathbb{E}_\theta(\ell^*(\theta)) = \bm{0}, \qquad I(\theta) = \mathbb{E}_\theta(\ell^*(\theta)\ell^*(\theta)^T) = \mathbb{E}_\theta\left(- \frac{\partial^2}{\partial \theta \partial \theta^T} \ell(\theta)\right),
</span> where <span class="math inline">I(\theta)</span> is called the <span class="blue">Fisher information matrix</span>, which is <span class="orange">positive definite</span>.</p></li>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid sample from <span class="math inline">f(y \mid \theta)\mathrm{d}y</span> satisfying the above regularity conditions. Moreover, let <span class="math inline">\hat{\theta}(\bm{Y})</span> be an <span class="orange">unbiased</span> estimator of <span class="math inline">\theta</span> with a finite covariance matrix. Then, <span class="math display">
\text{var}_\theta(\hat{\theta}(\bm{Y})) \ge I(\theta)^{-1}, \quad I(\theta) = n i(\theta), \quad i(\theta) = - \int\frac{\partial^2}{\partial \theta \partial \theta^T} \log f(y \mid \theta)\mathrm{d}y,
</span> corresponding to the multiparameter Cram√©r-Rao theorem.</p></li>
<li><p>Refer to Theorem 6.6, Chap. 2 in <span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span> for a proof.</p></li>
</ul>
</section>
<section id="rao-blackwell" class="slide level2 center">
<h2>Rao-Blackwell üìñ</h2>
<ul>
<li>The Rao-Blackwell theorem is <span class="orange">contructive strategy</span> for improving estimators that emphasizes the pivotal role of <span class="orange">sufficiency</span> in finding UMVU estimators.</li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (Rao-Blackwell, <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>, Theorem 7.3.17)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}</span> and <span class="math inline">\tilde{\theta}(\bm{Y})</span> be an <span class="orange">unbiased</span> estimator of <span class="math inline">\theta</span>. Moreover, let <span class="math inline">S = s(\bm{Y})</span> be a <span class="blue">sufficient statistic</span> for <span class="math inline">\theta</span> and <span class="math inline">\hat{\theta} = \mathbb{E}_\theta(\tilde{\theta}(\bm{Y}) \mid S)</span>. Then <span class="math inline">\hat{\theta}</span> is an estimator such that <span class="math inline">\mathbb{E}_\theta(\hat{\theta}) = \theta</span> and <span class="math display">
\text{var}_\theta(\hat{\theta}) \le \text{var}_\theta(\tilde{\theta}).
</span> That is, <span class="math inline">\hat{\theta}</span> is a <span class="blue">uniformly better unbiased estimator</span> of <span class="math inline">\theta</span>.</p>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li><p>As we shall see later, Rao-Blackwell holds for any <span class="blue">convex loss function</span>; see <span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 7.8, Chap. 1. Note that <span class="orange">unbiasedness</span> will not play any role.</p></li>
<li><p>This means that conditioning of a sufficient statistic <span class="orange">reduces</span> the <span class="orange">mean squared error</span> of a biased estimator <span class="math inline">\tilde{\theta}</span>, albeit the resulting <span class="math inline">\hat{\theta}</span> would also be biased.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="en-route-to-finding-unique-umvue-i" class="slide level2 center">
<h2><em>En route</em> to finding unique UMVUE I üìñ</h2>
<ul>
<li><p>In looking for UMVUE we should only consider those based on a <span class="blue">sufficient statistic</span> <span class="math inline">S</span>. However, if both <span class="math inline">\hat{\theta}</span> and <span class="math inline">\tilde{\theta}</span> are unbiased and based on <span class="math inline">S</span>, how do we know if <span class="math inline">\hat{\theta}</span> is best unbiased?</p></li>
<li><p>The next theorem is a <span class="orange">partial answer</span>, which is useful if <span class="math inline">\hat{\theta}</span> attains the <span class="blue">Cram√©r-Rao</span> lower bound.</p></li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>, Theorem 7.3.19)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}</span>. If <span class="math inline">\hat{\theta}</span> is a best unbiased estimator of <span class="math inline">\theta</span>, then <span class="math inline">\hat{\theta}</span> is <span class="blue">unique</span>.</p>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Example (Example 7.3.13 in <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be iid sample from a <span class="math inline">\text{Uniform}(0, \theta)</span>. Then the estimator <span class="math display">
\hat{\theta} = \frac{n + 1}{n} \max\{Y_1,\dots,Y_n\}
</span> is <span class="orange">unbiased</span> for <span class="math inline">\theta</span> and is based on a <span class="blue">sufficient statistic</span> <span class="math inline">S = \max\{Y_1,\dots,Y_n\}</span>. However, Cram√©r-Rao cannot be applied because the regularity conditions are not met. Is <span class="math inline">\hat{\theta}</span> UMVUE?</p>
</div>
</div>
</div>
</section>
<section id="en-route-to-finding-unique-umvue-ii" class="slide level2 center">
<h2><em>En route</em> to finding unique UMVUE II üìñ</h2>
<ul>
<li>Suppose we wish to improve on an unbiased estimator <span class="math inline">\hat{\theta}</span>. Then, we could consider <span class="math inline">U = U(\bm{Y})</span> such that <span class="math inline">\mathbb{E}_\theta(U) = 0</span>, i.e.&nbsp;<span class="math inline">U</span> is an <span class="blue">unbiased estimator or 0</span>, and let <span class="math display">
\tilde{\theta} = \hat{\theta} + a U, \qquad a \in \mathbb{R}.
</span> Clearly, <span class="math inline">\tilde{\theta}</span> is also <span class="orange">unbiased</span> and its <span class="orange">variance</span> is <span class="math display">
\text{var}_\theta(\tilde{\theta}) = \text{var}_\theta(\hat{\theta}) + 2 a \text{cov}_\theta(\hat{\theta}, U) + a^2\text{var}_\theta(U).
</span></li>
<li>If <span class="math inline">\text{cov}_\theta(\hat{\theta}, U) &lt; 0</span> for some <span class="math inline">\theta</span>, then choosing <span class="math inline">a \in (0, - 2  \text{cov}_\theta(\hat{\theta}, U) / \text{var}_\theta(U))</span> gives a <span class="blue">better estimator</span> for <span class="math inline">\theta</span>, implying that <span class="math inline">\hat{\theta}</span> is not UMVUE. This actually <span class="orange">characterizes</span> UMVU estimators.</li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>, Theorem 7.3.20)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}</span> and <span class="math inline">\hat{\theta}</span> be an unbiased estimator of <span class="math inline">\theta</span>. Then <span class="math inline">\hat{\theta}</span> is UMVUE <span class="orange">if and only if</span> <span class="math inline">\hat{\theta}</span> is <span class="blue">uncorrelated</span> with all <span class="blue">unbiased estimators of <span class="math inline">0</span></span>, that is <span class="math display">
\text{cov}_\theta(\hat{\theta}, U) = 0, \quad \text{ for all } \quad U = U(\bm{Y}) \quad \text{ such that } \quad \mathbb{E}_\theta(U) = 0.
</span></p>
</div>
</div>
</div>
</section>
<section id="completeness" class="slide level2 center">
<h2>Completeness</h2>
<ul>
<li><p>Proving that an estimator <span class="math inline">\hat{\theta}</span> is uncorrelated with all unbiased estimators of 0 is very hard, limitating the practical usefulness of the former theorem.</p></li>
<li><p>However, if we assume <span class="math inline">S</span> is <span class="orange">complete</span>, we can finally see the light at the end of the tunnel.</p></li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>A sufficient statistic <span class="math inline">S = s(\bm{Y})</span> for a statistical model <span class="math inline">\mathcal{F} = \{f(\mathrm{d}y \mid \theta) : \theta \in \Theta\}</span> is said to be <span class="blue">complete</span> if <span class="orange">no nonconstant</span> function <span class="math inline">g(\cdot)</span> of <span class="math inline">S</span> is <span class="orange">first-order ancillary</span>, that is, <span class="math display">
\mathbb{E}_\theta(g(S)) = c \quad \text{for all } \theta \quad \text{implies} \quad g(S) = c \:\text{ a.s.}
</span> In other words, any non-trivial transformation of <span class="math inline">S</span> conveys information about <span class="math inline">\theta</span> in expectation.</p>
</div>
</div>
</div>
<ul>
<li><p>Because of Rao-Blackwell, the UMVUE <span class="math inline">\hat{\theta} = \hat{\theta}(S)</span> must be a function of a <span class="blue">sufficient</span> statistic <span class="math inline">S</span>.</p></li>
<li><p>If <span class="math inline">S</span> is <span class="orange">complete</span>, then (using <span class="math inline">c = 0</span>), there exists no estimator <span class="math inline">U = U(S)</span> such that <span class="math inline">\mathbb{E}_\theta(U(S)) = 0</span>, with the only exception of <span class="math inline">U = 0</span>, which is uncorrelated with <span class="math inline">\hat{\theta}(S)</span>.</p></li>
</ul>
</section>
<section id="lehmann-scheff√©-theorem" class="slide level2 center">
<h2>Lehmann-Scheff√© theorem</h2>
<ul>
<li>We summarise these finding into a single statement, which is arguably the most relevant result of the Rao-Blackwell saga.</li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (Lehmann-Scheff√©-Rao-Blackwell, <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>, Theorem 7.3.23)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}</span> and <span class="math inline">S</span> be a <span class="orange">complete</span> sufficient statistic for a parameter <span class="math inline">\theta</span>, and let <span class="math inline">\hat{\theta}</span> be an unbiased estimator of <span class="math inline">\theta</span> based only on <span class="math inline">S</span>. Then, <span class="math inline">\hat{\theta}</span> is <span class="blue">unique</span> best unbiased estimator (UMVUE) of <span class="math inline">\theta</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>The <span class="blue">Lehmann-Scheff√© theorem</span> is implicitly contained in the previous results. Its <span class="orange">original formulation</span> is: ‚Äú<em>unbiased estimators based on complete sufficient statistics are unique.</em>‚Äù</p></li>
<li><p>The Lehmann-Scheff√© theorem represents a <span class="blue">major achievement</span> in mathematical statistics, tying together <span class="orange">sufficiency</span>, <span class="grey">completeness</span> and <span class="blue">uniqueness</span>.</p></li>
</ul>
</section>
<section id="example-binomial-best-unbiased-estimation" class="slide level2 center">
<h2>Example: binomial best unbiased estimation üìñ</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be iid <span class="math inline">\textup{Bin}(N, p)</span> and we assume that <span class="math inline">N</span> is <span class="blue">known</span> and <span class="math inline">p</span> is <span class="orange">unknown</span>. We are interested in estimating the <span class="orange">reparametrization</span>: <span class="math display">
\psi = \mathbb{P}(Y_i = 1) = N p (1 - p)^{N-1}.
</span></p></li>
<li><p>We know that <span class="math inline">S = \sum_{i=1}^n Y_i \sim \textup{Bin}(n N, p)</span> is a <span class="grey">complete</span> and <span class="blue">sufficient</span> statistic<sup>1</sup>. However, no obvious unbiased estimator based on <span class="math inline">S</span> is immediately available.</p></li>
<li><p>Let us begin noting that <span class="math inline">\tilde{\psi} = \mathbb{I}(Y_1 = 1)</span> is an <span class="orange">unbiased</span> estimator of <span class="math inline">\psi</span>, where <span class="math inline">\mathbb{I}</span> is the <span class="blue">indicator function</span>. In fact: <span class="math inline">\mathbb{E}(\tilde{\psi}) = \mathbb{E}(\mathbb{I}(Y_1 = 1)) = \mathbb{P}(Y_1 = 1) = \psi</span>.</p></li>
<li><p>The Lehmann-Scheff√©-Rao-Blackwell theorem then implies that the unique and best unbiased estimator (UMVUE) is <span class="math display">
\hat{\psi} = \mathbb{E}(\tilde{\psi} \mid S) = N \binom{N n - N}{S-1}/ \binom{N n}{S}.
</span> which can be obtained after simple calculations.</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn14"><p>See Example 6.2.22 of <span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>. This is also follows from general result of exponential families.</p></li></ol></aside></section>
<section id="rao-blackwell-multiparameter-case" class="slide level2 center">
<h2>Rao-Blackwell, multiparameter case</h2>
<ul>
<li><p>Generalizations of Rao-Blakwell theory to the multiparameter case <span class="math inline">\Theta \subseteq \mathbb{R}^p</span> are possible.</p></li>
<li><p>If one is interested in estimating <span class="math inline">\psi = g(\theta)</span> for some <span class="blue">function</span> <span class="math inline">g: \mathbb{R}^p \to \mathbb{R}</span>, then the previously developed <span class="orange">theory applies almost directly</span>, with minor modifications to the statements.</p></li>
<li><p>Note that a special case of the above is <span class="math inline">g(\theta) = \theta_j</span>, meaning that the developed theory can be <span class="orange">separately</span> applied to <span class="blue">each coordinate</span> of <span class="math inline">\theta</span>.</p></li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (Rao-Blackwell, <span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 7.8, Chap. 1)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}^p</span>, and let <span class="math inline">\tilde{\theta}(\bm{Y})</span> be an estimator of <span class="math inline">\theta</span> with finite risk <span class="math inline">R(\theta; \tilde{\theta})</span> under a <span class="orange">strictly convex loss</span> function. Moreover, let <span class="math inline">S = s(\bm{Y})</span> be a <span class="blue">sufficient statistic</span> for <span class="math inline">\theta</span>, and set <span class="math inline">\hat{\theta} = \mathbb{E}_\theta(\tilde{\theta}(\bm{Y}) \mid S)</span>. Then, <span class="math display">
R(\theta; \hat{\theta}) \le R(\theta; \tilde{\theta}),
</span> unless <span class="math inline">\tilde{\theta} = \hat{\theta}</span> with probability 1.</p>
</div>
</div>
</div>
</section></section>
<section>
<section id="alternative-notions-of-optimality" class="title-slide slide level1 center">
<h1>Alternative notions of optimality</h1>

</section>
<section id="unbiased-estimating-equations-i" class="slide level2 center">
<h2>Unbiased estimating equations I</h2>
<ul>
<li>A <span class="blue">Z-estimator</span> is the <span class="orange">solution</span> over <span class="math inline">\Theta</span> of a system of equations function <span class="math inline">Q(\theta) = \bm{0}</span> of the type: <span class="math display">
Q(\theta) = \sum_{i=1}^n q(\theta; Y_i) = \bm{0},
</span> where <span class="math inline">q(\theta) = q(\theta; y)</span> are known vector-valued maps. These are called <span class="blue">estimating equations</span>.</li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>The estimating equations <span class="math inline">Q(\theta) = \sum_{i=1}^n q(\theta; Y_i)</span> are <span class="orange">unbiased</span> if they satisfy <span class="math display">
\mathbb{E}_\theta(Q(\theta)) = \bm{0}, \qquad \text{ for all } \qquad \theta \in \Theta.
</span></p>
</div>
</div>
</div>
<ul>
<li>Under iid sampling, the <span class="orange">score function</span> can be written as <span class="math inline">\ell^*(\theta) = \sum_{i=1}^n \frac{\partial}{\partial \theta}\log{f(y_i; \theta)}</span> and therefore is a Z-estimator. Moreover, under regularity conditions, it is <span class="orange">unbiased</span>: <span class="math inline">\mathbb{E}_\theta(\ell^*(\theta)) = \bm{0}</span>.</li>
</ul>
</section>
<section id="unbiased-estimating-equations-ii" class="slide level2 center">
<h2>Unbiased estimating equations II</h2>
<ul>
<li><p>Remarkably, the unbiasedness of <span class="math inline">Q(\theta)</span>, combined with a few regularity conditions, is often enough to prove <span class="orange">consistency</span> of the resulting estimator <span class="math inline">\hat{\theta}</span> as <span class="math inline">n\rightarrow \infty</span>. <sup>1</sup></p></li>
<li><p>Unbiasedness of <span class="math inline">Q(\theta)</span> does not imply that the solution <span class="math inline">\hat{\theta}</span> is an unbiased estimator of <span class="math inline">\theta</span>, unless <span class="math inline">Q(\theta)</span> is a <span class="blue">linear function</span>.</p></li>
<li><p>The unbiasedness of <span class="math inline">Q(\theta)</span> holds for any <span class="orange">reparametrization</span> <span class="math inline">\psi = \psi(\theta)</span>. Moreover, Z-estimators, by construction, satisfy <span class="blue">equivariance</span>, meaning that <span class="math inline">\hat{\psi} = \psi(\hat{\theta})</span>.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Having defined the class of unbiased estimating functions, the question naturally arises which of them we should use.</p>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn15"><p>Refer to <span class="citation" data-cites="Davison2003">Davison (<a href="#/references" role="doc-biblioref" onclick="">2003</a>)</span>, Section 7.2, for an intuitive argument and <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Chap. 5 for a rigorous proof.</p></li></ol></aside></section>
<section id="asymptotic-behavior-of-unbiased-estimating-equations" class="slide level2 center">
<h2>Asymptotic behavior of unbiased estimating equations</h2>
<ul>
<li><p>Guidance on the choice of <span class="math inline">Q(\theta)</span> can be found by investigating its <span class="blue">asymptotic behavior</span>. We provide an <span class="orange">informal argument</span> for <span class="math inline">\theta \in \Theta \subseteq \mathbb{R}</span>.</p></li>
<li><p>Under <span class="blue">iid sampling</span> and further <span class="orange">regularity conditions</span>, implying that <span class="math inline">\mathbb{E}_\theta(q(\theta; Y_i)) = 0</span>, a Taylor series expansion of <span class="math inline">Q(\theta)</span> gives <span class="math display">
0 = Q(\hat{\theta}) \approx \sum_{i=1}^n q(\theta; Y_i) + (\hat{\theta}- \theta) \sum_{i=1}^n\frac{\partial}{\partial \theta}q(\theta; Y_i).
</span></p></li>
<li><p>Thus, re-arranging, the following approximations hold <span class="orange">for large <span class="math inline">n</span></span>: <span class="math display">
\hat{\theta} - \theta \approx \frac{\sum_{i=1}^n q(\theta; Y_i)}{- \sum_{i=1}^n \frac{\partial}{\partial \theta}q(\theta; Y_i)} \approx \frac{Q(\theta)}{\mathbb{E}_\theta\left(- \frac{\partial}{\partial \theta}Q(\theta)\right)} .
</span></p></li>
<li><p>This suggests Z-estimators are <span class="blue">asymptotically unbiased</span> and the <span class="orange">asymptotic variance</span> of <span class="math inline">\hat{\theta}</span> is <span class="math display">
\text{var}(\hat{\theta}) \approx \frac{\text{var}(Q(\theta))}{\mathbb{E}_\theta\left(- \frac{\partial}{\partial \theta}Q(\theta)\right)^2} =  n^{-1}\frac{\text{var}(q(\theta))}{\mathbb{E}_\theta\left(-\frac{\partial}{\partial \theta}q(\theta)\right)^2}.
</span></p></li>
</ul>
</section>
<section id="godambe-information" class="slide level2 center">
<h2>Godambe information</h2>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Let <span class="math inline">\bm{Y}</span> be a sample from a statistical model with parameter <span class="math inline">\theta \in \Theta \subseteq \mathbb{R}</span>. Let <span class="math inline">Q(\theta)</span> be an <span class="orange">unbiased estimating equation</span>. We define the <span class="blue">sensitivity</span> as <span class="math display">
H(\theta) := \mathbb{E}_\theta\left(-\frac{\partial}{\partial \theta}Q(\theta; \bm{Y})\right),
</span> and the <span class="grey">variability</span> as <span class="math display">
J(\theta) := \text{var}_\theta(Q(\theta; \bm{Y})).
</span> Then, the <span class="blue">Godambe information</span> is defined as <span class="math display">
V(\theta) := \frac{H(\theta)^2}{J(\theta)}.
</span></p>
</div>
</div>
</div>
<ul>
<li>An estimating equation <span class="math inline">Q(\theta)</span> which has <span class="math inline">H(\theta) = J(\theta)</span> is called <span class="blue">information unbiased</span>.</li>
</ul>
</section>
<section id="godambe-efficiency" class="slide level2 center">
<h2>Godambe efficiency</h2>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Let <span class="math inline">Q(\theta)</span> and <span class="math inline">\tilde{Q}(\theta)</span> be two <span class="orange">estimating equations</span> with Godambe information <span class="math inline">V(\theta)</span> and <span class="math inline">\tilde{V}(\theta)</span>. Then <span class="math inline">Q(\theta)</span> is <span class="blue">uniformly more efficient</span> than <span class="math inline">\tilde{Q}(\theta)</span> if <span class="math display">
V(\theta) \ge \tilde{V}(\theta) \qquad\text{ for all } \qquad \theta \in \Theta \subseteq \mathbb{R}.
</span></p>
</div>
</div>
</div>
<ul>
<li><p>This criterion is appropriate because the <span class="orange">inverse</span> of the <span class="blue">Godambe information</span> <span class="math inline">V(\theta)^{-1}</span>, under regularity conditions, coincides with the <span class="orange">asymptotic variance</span> of <span class="math inline">\hat{\theta}</span>.</p></li>
<li><p>Moreover, although the <span class="blue">variance</span> <span class="math inline">J(\theta)</span> is a natural basis for comparing estimating functions, <span class="math inline">\tilde{Q}(\theta) = a Q(\theta; \bm{Y})</span> is also unbiased with variance <span class="math inline">\tilde{J}(\theta) = a^2 J(\theta)</span>.</p></li>
<li><p>Hence, a fair comparison is possible only after removing this <span class="orange">arbitrary scaling</span>. Indeed, Godambe information is <span class="blue">invariant</span> to scaling of <span class="math inline">Q(\theta)</span>.</p></li>
</ul>
</section>
<section id="godambe-information-of-the-score-function" class="slide level2 center">
<h2>Godambe information of the score function</h2>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<ul>
<li><p>Let <span class="math inline">\bm{Y}</span> be a sample from a statistical model with parameter <span class="math inline">\theta \in \Theta \subseteq \mathbb{R}</span> and with <span class="blue">score function</span> <span class="math inline">\ell^*(\theta)</span>.</p></li>
<li><p>If the first Bartlett identity holds, the score function <span class="math inline">\ell^*(\theta)</span> is an <span class="orange">unbiased estimating equation</span>.</p></li>
<li><p>Moreover, if the second Bartlett identity holds, <span class="math inline">\ell^*(\theta)</span> is <span class="blue">information unbiased</span>, that is <span class="math display">
H(\theta) = \mathbb{E}_\theta\left(-\frac{\partial}{\partial \theta}\ell^*(\theta)\right)= \text{var}_\theta(\ell^*(\theta)) = J(\theta).
</span> This implies that <span class="math display">
V(\theta) =  I(\theta),
</span> that is, the <span class="blue">Godambe information</span> of <span class="math inline">\ell^*(\theta)</span> coincides with the usual <span class="orange">Fisher information</span>.</p></li>
</ul>
</div>
</div>
</div>
<ul>
<li>Hence, Godambe information is a generalization of Fisher information.</li>
</ul>
</section>
<section id="godambe-efficiency-1" class="slide level2 center">
<h2>Godambe efficiency</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Godambe1960">Godambe (<a href="#/references" role="doc-biblioref" onclick="">1960</a>)</span>)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a sample from a joint probability measure <span class="math inline">f(\bm{y} \mid \theta)\nu(\mathrm{d}\bm{y})</span> and let <span class="math inline">\Theta \subseteq \mathbb{R}</span>. Moreover, let <span class="math inline">Q(\theta)</span> be an unbiased estimating equation with <span class="blue">Godambe information</span> <span class="math inline">V(\theta)</span>. Then under <span class="orange">regularity conditions</span> <span class="blue">C.1</span> and <span class="blue">C.2</span>: <span class="math display">
\frac{1}{V(\theta)} \ge \frac{1}{I(\theta)}.
</span></p>
</div>
</div>
</div>
<ul>
<li><p>This result is the equivalent of the Cram√©r-Rao theorem for unbiased estimating equations.</p></li>
<li><p>It implies that the <span class="blue">score functions</span> are <span class="orange">optimal</span> (Godambe efficient) among unbiased estimating equations. However, Z-estimators may have appealing <span class="grey">robustness</span> properties.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Godambe information generalizes to the vector case <span class="math inline">\theta \in \Theta \subseteq \mathbb{R}^p</span> and is defined as <span class="math inline">V(\theta) = H(\theta) J(\theta)^{-1}H(\theta)</span>, sometimes called <span class="orange">sandwich</span> matrix. Optimality results generalize as well.</p>
</div>
</div>
</div>
</section>
<section id="linear-estimating-equations-i" class="slide level2 center">
<h2>Linear estimating equations I</h2>
<ul>
<li><p>Let <span class="math inline">Y_1, \dots, Y_n</span> be <span class="blue">independent</span> random variables with <span class="orange">mean</span> <span class="math inline">\mathbb{E}(Y_i) = \mu_i(\theta)</span> and <span class="orange">variance</span> <span class="math inline">\text{var}(Y_i) = V_i(\mu)</span>, depending on a scalar parameter <span class="math inline">\theta \in \Theta \subseteq \mathbb{R}</span>.</p></li>
<li><p>Suppose the unbiased estimating equation <span class="math inline">Q(\theta)</span> has a <span class="blue">linear form</span>: <span class="math display">
Q(\theta) = \sum_{i=1}^n q(\theta; Y_i) = \sum_{i=1}^n w_i(\theta)(Y_i - \mu_i(\theta)),
</span> for some set of positive <span class="orange">weights</span> <span class="math inline">w_i(\theta)</span>. Can we find the <span class="blue">optimal</span> set of weights, according to the <span class="blue">Godambe information</span>?</p></li>
<li><p>The <span class="blue">sensitivity</span> <span class="math inline">H(\theta)</span> and the <span class="orange">variability</span> <span class="math inline">J(\theta)</span> of <span class="math inline">Q(\theta)</span> are readily available: <span class="math display">
H(\theta) = \sum_{i=1}^n w_i(\theta)\mu_i^*(\theta), \qquad J(\theta) = \sum_{i=1}^n w_i^2(\theta) V_i(\theta).
</span> Therefore, the optimal weights are those that <span class="orange">maximize</span> the <span class="blue">Godambe information</span>: <span class="math display">
V(\theta) = \frac{\left(\sum_{i=1}^n w_i(\theta)\mu_i(\theta)\right)^2}{\sum_{i=1}^n w_i^2(\theta) V_i(\theta)}.
</span></p></li>
</ul>
</section>
<section id="linear-estimating-equations-ii" class="slide level2 center">
<h2>Linear estimating equations II</h2>
<ul>
<li>Using Lagrange multipliers, it can be shown<sup>1</sup> that the <span class="orange">optimal weights</span> are <span class="math display">
w_i(\theta) \propto \frac{\mu_i^*(\theta)}{V_i(\theta)}, \qquad \mu_i^*(\theta) = \frac{\partial}{\partial \theta}\mu(\theta), \qquad i=1,\dots,n,
</span> which means the following unbiased <span class="orange">linear</span> estimating equation is <span class="blue">Godambe efficient</span>: <span class="math display">
Q(\theta) = \sum_{i=1}^n \frac{\mu_i^*(\theta)}{V_i(\theta)}(Y_i - \mu_i(\theta)).
</span></li>
<li>This optimality property holds for a special class of <span class="blue">linear</span> unbiased estimating equations but does <span class="orange">not</span> make <span class="orange">assumptions</span> of the distribution of <span class="math inline">Y_i</span> other than <span class="math inline">\mu_i(\theta)</span> and <span class="math inline">V_i(\theta)</span>.</li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be independent random variables such that <span class="math inline">\mu_i(\theta) = \lambda e_i</span> and <span class="math inline">V_i(\theta) = \lambda e_i</span>, where <span class="math inline">e_i</span> are <span class="orange">known constants</span> e.g.&nbsp;representing exposure. Then the optimal weights are <span class="math inline">w_i(\theta) = 1</span> and <span class="math inline">\hat{\theta} = \bar{Y}/ \bar{e}</span>. Note the <span class="math inline">Y_i</span> is <span class="blue">not</span> necessarily <span class="blue">Poisson</span>.</p>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn16"><p>See <span class="citation" data-cites="Davison2003">Davison (<a href="#/references" role="doc-biblioref" onclick="">2003</a>)</span>, Section 7.2.2, for a proof.</p></li></ol></aside></section>
<section id="blue-estimators-i" class="slide level2 center">
<h2>BLUE estimators I</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (Gauss-Markov, <span class="citation" data-cites="Agresti2015">Agresti (<a href="#/references" role="doc-biblioref" onclick="">2015</a>)</span>, Section 2.7.1)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\bm{Y} \in \mathbb{R}^n</span> be a random vector satisfying <span class="math inline">\mathbb{E}(\bm{Y}) = \bm{X}\beta</span> and <span class="math inline">\text{var}(\bm{Y}) = \sigma^2 I_p</span>, where <span class="math inline">\bm{X}</span> is an <span class="math inline">n \times p</span> known matrix with <span class="orange">full rank</span>, <span class="math inline">\beta \in \mathbb{R}^p</span> is an unknown vector, and <span class="math inline">\sigma^2 &gt; 0</span> is an unknown parameter. Then the <span class="blue">best linear unbiased estimator</span> (BLUE) of <span class="math inline">\beta</span> is <span class="math display">
\hat{\beta} = (\bm{X}^T\bm{X})^{-1}\bm{X}^T\bm{Y}.
</span> meaning that <span class="math inline">\hat{\beta}</span> is <span class="orange">unbiased</span> and has the <span class="blue">minimum variance</span> among all unbiased linear estimators of <span class="math inline">\beta</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>The Gauss-Markov theorem does not make specific assumptions on the distribution of <span class="math inline">\bm{Y}</span>, only on the <span class="orange">mean</span> and <span class="orange">variance</span>.</p></li>
<li><p>If we strengthen the assumptions to <span class="math inline">\bm{Y} \sim \textup{N}_p(\bm{X}\beta, \sigma^2 I_p)</span>, then <span class="math inline">\hat{\beta}</span> is the <span class="blue">UMVUE</span> of <span class="math inline">\beta</span> among all estimators, including non-linear ones; see <span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Chap. 3, Sec. 4.</p></li>
<li><p>As a special case of Gauss-Markov, if <span class="math inline">Y_i</span> are iid with mean <span class="math inline">\mu</span> and variance <span class="math inline">\sigma</span>, then <span class="math inline">\bar{Y}</span> is BLUE.</p></li>
</ul>
</section>
<section id="blue-estimators-ii" class="slide level2 center">
<h2>BLUE estimators II</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (Aitken, <span class="citation" data-cites="Agresti2015">Agresti (<a href="#/references" role="doc-biblioref" onclick="">2015</a>)</span>, Section 2.7.1)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\bm{Y} \in \mathbb{R}^n</span> be random vector satisfying <span class="math inline">\mathbb{E}(\bm{Y}) = \bm{X}\beta</span> and <span class="math inline">\text{var}(\bm{Y}) = \Sigma</span>, where <span class="math inline">\bm{X}</span> is <span class="math inline">n \times p</span> known matrix with <span class="orange">full rank</span>, <span class="math inline">\beta \in \mathbb{R}^p</span> an unknown vector, and <span class="math inline">\Sigma</span> an <span class="orange">known</span> covariance matrix. Then the <span class="blue">best linear unbiased estimator</span> (BLUE) of <span class="math inline">\beta</span> is <span class="math display">
\hat{\beta} = (\bm{X}^T\Sigma \bm{X})^{-1}\bm{X}^T\Sigma^{-1}\bm{Y}.
</span> corresponding to the <span class="orange">generalized least squares</span> estimator.</p>
</div>
</div>
</div>
<ul>
<li><p>This interesting <span class="blue">generalization</span> of Gauss-Markov is often not applicable in practice, because the covariance matrix <span class="math inline">\Sigma</span> is typically <span class="orange">unknown</span>.</p></li>
<li><p>When <span class="math inline">\Sigma = \text{diag}(\sigma_1^2,\dots,\sigma_n^2)</span> is <span class="orange">diagonal</span>, i.e.&nbsp;in presence of heteroschedasticity, the Aitken estimator reduces to the <span class="blue">weighted least squares</span> estimator.</p></li>
<li><p>Moreover, if <span class="math inline">Y_i</span> are independent random variables with mean <span class="math inline">\mu</span> and variance <span class="math inline">\sigma^2_i</span>, then the <span class="orange">weighted mean</span> <span class="math inline">\hat{\mu} = \sum_{i=1}^n w_i Y_i / \sum_{j=1}^n w_j</span> is BLUE, where <span class="math inline">w_i = (1/\sigma_i^2)</span>.</p></li>
</ul>
</section>
<section id="blue-estimators-and-unbiased-estimating-equations-i" class="slide level2 center">
<h2>BLUE estimators and unbiased estimating equations I</h2>
<ul>
<li><p>We discuss here <span class="orange">connections</span> between the <span class="blue">BLUE estimators</span> and the <span class="orange">unbiased estimating equations</span>, aimed at providing a <span class="orange">unified view</span> of these concepts.</p></li>
<li><p>Under the same assumptions of Gauss-Markov theorem, let us consider: <span class="math display">
Q(\beta) = \bm{A}^T(\bm{Y} - \bm{X}\beta),
</span> for some <span class="math inline">n \times p</span> matrix <span class="math inline">\bm{A}</span> having full rank. This is a <span class="orange">linear unbiased</span> estimating equation, and the <span class="blue">optimal</span> choice of <span class="math inline">\bm{A}</span> maximizes the <span class="orange">Godambe information</span>.</p></li>
<li><p>Solving this estimating equation we obtain to a linear unbiased estimator, which is <span class="math display">
\hat{\beta} = (\bm{A}^T \bm{X})^{-1}\bm{A}^T \bm{Y}, \qquad \mathbb{E}(\hat{\beta}) = (\bm{A}^T \bm{X})^{-1}\bm{A}^T \bm{X}\beta = \beta.
</span></p></li>
<li><p>The <span class="blue">sensitivity</span> and <span class="orange">variability</span> matrices of <span class="math inline">Q(\beta)</span> are <span class="math display">
J(\beta) = \text{var}(Q(\beta)) = \sigma^2 \bm{A}^T \bm{A}, \qquad H(\beta) = \mathbb{E}\left(-\frac{\partial}{\partial \beta}Q(\beta)\right) = (\bm{A}^T \bm{X})^T.
</span> Consequently, the <span class="blue">Godambe information</span> is <span class="math inline">V(\beta) =  \sigma^{-2} (\bm{A}^T \bm{X})^T(\bm{A}^T \bm{A})^{-1}(\bm{A}^T \bm{X})^T</span>.</p></li>
</ul>
</section>
<section id="blue-estimators-and-unbiased-estimating-equations-ii" class="slide level2 center">
<h2>BLUE estimators and unbiased estimating equations II</h2>
<ul>
<li><p>The <span class="orange">optimal</span> choice of <span class="math inline">\bm{A}</span> equivalently minimizes the inverse of the <span class="blue">Godambe information</span>, which after a few algebraic manipulation is equal to <span class="math display">
V(\beta)^{-1} =  \sigma^2 \left[(\bm{A}^T \bm{X})^{-1}\bm{A}^T\right] \left[(\bm{A}^T \bm{X})^{-1}\bm{A}^T\right]^T.
</span></p></li>
<li><p>The key remark is the following: a direct calculation shows that the variance of <span class="math inline">\hat{\beta}</span> is <span class="math display">
\text{var}(\beta) = \sigma^2 \left[(\bm{A}^T \bm{X})^{-1}\bm{A}^T\right] \left[(\bm{A}^T \bm{X})^{-1}\bm{A}^T\right]^T = V(\beta)^{-1},
</span> that is, the <span class="orange">variance</span> of <span class="math inline">\hat{\beta}</span> coincides with the inverse of the <span class="blue">Godambe information</span>. This is a consequence of the linearity of <span class="math inline">Q(\beta)</span>, otherwise the property holds only asymptotically.</p></li>
<li><p>Thus, the same proof of Gauss-Markov theorem can be used to show that the <span class="blue">BLUE estimator</span> is <span class="orange">Godambe efficient</span> and the optimal matrix is <span class="math inline">\bm{A} = \bm{X}</span>, giving <span class="math display">
\hat{\beta} = (\bm{X}^T\bm{X})^{-1}\bm{X}^T\bm{Y}, \qquad V(\beta) = \frac{1}{\sigma^2}\bm{X}^T\bm{X}.
</span></p></li>
<li><p>Moreover, if <span class="math inline">\bm{Y} \sim \textup{N}_p(\bm{X}\beta, \sigma^2 I_p)</span>, then <span class="math inline">V(\beta)</span> also coincides with the <span class="blue">Fisher information</span> <span class="math inline">I(\beta)</span>.</p></li>
</ul>
</section></section>
<section>
<section id="asymptotic-evaluations" class="title-slide slide level1 center">
<h1>Asymptotic evaluations</h1>

</section>
<section id="asymptotic-evaluations-preliminaries" class="slide level2 center">
<h2>Asymptotic evaluations: preliminaries</h2>
<ul>
<li><p>Asymptotic evaluations of estimators are taught in basic courses of inferential statistics. We focus on two main properties: <span class="blue">consistency</span> and <span class="orange">asymptotic normality</span>.</p></li>
<li><p>An estimator <span class="math inline">\hat{\theta}_n</span> is <span class="orange">consistent</span> if it converges <span class="blue">in probability</span> to the true value <span class="math inline">\theta_0</span> as the sample size increases, i.e., <span class="math inline">\hat{\theta}_n \overset{p}{\longrightarrow} \theta_0</span> as <span class="math inline">n\rightarrow \infty</span>. Classical <span class="blue">sufficient conditions</span> are given below.</p></li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>, Theorem 10.1.3)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}</span> and <span class="math inline">\hat{\theta}_n</span> be a sequence of estimators such that the <span class="orange">asymptotic bias</span> and <span class="blue">variance</span> are zero, that is for every <span class="math inline">\theta \in \Theta</span> <span class="math display">
\lim_{n\to\infty}\text{bias}_\theta(\hat{\theta}_n)=0, \qquad \lim_{n\to\infty}\text{var}_\theta(\hat{\theta}_n)=0.
</span> Then <span class="math inline">\hat{\theta}_n</span> is a <span class="blue">consistent estimator</span> of <span class="math inline">\theta_0</span>.</p>
</div>
</div>
</div>
<ul>
<li>Checking this condition case-by-case is difficult. Instead, we seek <span class="blue">general sufficient conditions</span> to establish the consistency of broad estimator classes, including <span class="orange">maximum likelihood</span>.</li>
</ul>
</section>
<section id="asymptotic-evaluations-preliminaries-1" class="slide level2 center">
<h2>Asymptotic evaluations: preliminaries</h2>
<ul>
<li><p>The <span class="orange">asymptotic normality</span> of an estimator <span class="math inline">\hat{\theta}_n</span> is a stronger property than consistency, implying that the estimator is <span class="blue">normally distributed</span> around the true value <span class="math inline">\theta_0</span> for large <span class="math inline">n</span>.</p></li>
<li><p>Let <span class="math inline">\Theta \subseteq \mathbb{R}</span> and let <span class="math inline">\hat{\theta}_n</span> be a sequence of estimators. Under ‚Äúregularity conditions‚Äù: <span class="math display">
\sqrt{n}(\hat{\theta}_n - \theta_0) \overset{\text{d}}{\longrightarrow} \text{N}(0, v(\theta_0)^{-1}), \qquad n \rightarrow \infty,
</span> where <span class="math inline">v(\theta_0)^{-1}</span> is the so-called <span class="blue">asymptotic variance</span>.</p></li>
<li><p>If <span class="math inline">\hat{\theta}_n</span> is the <span class="orange">maximum likelihood</span>, then under regularity conditions <span class="math inline">n v(\theta)</span> equals the <span class="orange">Fisher information</span> <span class="math inline">I(\theta) = n i(\theta)</span> and the <span class="blue">asymptotic variance</span> is <span class="math inline">i(\theta_0)^{-1}</span>.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>In regular problems, the maximum likelihood estimator <span class="math inline">\hat{\theta}_n</span> is <span class="orange">asymptotically efficient</span>, that is, for <span class="math inline">n</span> large enough, its variance attains the Cram√©r-Rao lower bound. Informally, <span class="math display">
\hat{\theta}_n \:\dot{\sim}\: \text{N}(\theta_0, I(\theta_0)^{-1}).
</span></p>
</div>
</div>
</div>
<ul>
<li><span class="orange">Remark</span>: there exist infinitely many asymptotically efficient estimators.</li>
</ul>
</section>
<section id="example-poisson-with-unknown-mean-1" class="slide level2 center">
<h2>Example: Poisson with unknown mean</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be a iid random sample from a <span class="orange">Poisson</span> distribution of mean parameter <span class="math inline">\lambda &gt; 0</span>. The maximum likelihood estimator <span class="math inline">\hat{\lambda}_n</span> is the sample mean <span class="math display">
\hat{\lambda}_n = \bar{Y}.
</span></p></li>
<li><p>One could invoke the strong <span class="blue">law of large numbers</span> to show that <span class="math inline">\hat{\lambda}_n \overset{\text{a.s.}}{\longrightarrow} \lambda</span>. Alternatively: <span class="math display">
\mathbb{E}_\lambda(\hat{\lambda}) = \lambda, \qquad \text{var}_\lambda(\hat{\lambda}_n) = \frac{\lambda}{n} = I(\lambda)^{-1},
</span> which implies <span class="math inline">\text{bias}_\lambda(\hat{\lambda}_n)=0</span> and <span class="math inline">\lim_{n\to\infty}\text{var}_\lambda(\hat{\lambda}_n)=0</span>, from which <span class="orange">consistency</span> follows.</p></li>
<li><p>Moreover, as a direct application of the <span class="orange">central limit theorem</span>, we also obtain that <span class="math display">
\sqrt{n}(\hat{\lambda}_n - \lambda) \overset{\text{d}}{\longrightarrow} \text{N}(0, \lambda), \qquad i(\lambda) = \frac{1}{\lambda}.
</span></p></li>
<li><p>In order to construct confidence intervals, one typically estimate the asymptotic variance <span class="math inline">i(\lambda)^{-1}</span> with a consistent estimator <span class="math inline">i(\hat{\lambda}_n)^{-1} = \hat{\lambda}_n</span>. Then <span class="blue">Slutsky theorem</span> ensures that <span class="math display">
\sqrt{n}\:i(\hat{\lambda}_n)^{1/2}(\hat{\lambda}_n - \lambda)\overset{\text{d}}{\longrightarrow} \text{N}(0, 1).
</span></p></li>
</ul>
</section>
<section id="the-classical-regularity-conditions" class="slide level2 center">
<h2>The classical ‚Äúregularity conditions‚Äù</h2>
<div class="callout callout-warning no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>(<strong>A1</strong>) We observe an <span class="orange">iid</span> sample <span class="math inline">Y_1,\dots,Y_n</span> from a density <span class="math inline">f(y ; \theta_0)</span> with true value <span class="math inline">\theta_0 \in \Theta \subseteq \mathbb{R}^p</span>.</p>
<p>(<strong>A2</strong>) The model is <span class="blue">identifiable</span>, that is, the densities <span class="math inline">f(\cdot ; \theta)</span> and <span class="math inline">f(\cdot ; \theta')</span> are different for <span class="math inline">\theta \neq \theta'</span>.</p>
<p>(<strong>A3</strong>) The distributions <span class="math inline">f(y ; \theta)</span> have <span class="orange">common support</span>.</p>
<p>(<strong>A4</strong>) The parameter space <span class="math inline">\Theta</span> contains an <span class="orange">open set</span> of which <span class="math inline">\theta_0</span> is an <span class="blue">interior point</span>.</p>
</div>
</div>
</div>
<p>We will sometimes need the additional conditions:</p>
<div class="callout callout-warning no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>(<strong>A5</strong>) There is a neighbourhood <span class="math inline">\mathcal{N}</span> of the true value <span class="math inline">\theta_0</span> within which the first <span class="orange">three derivatives</span> of <span class="math inline">\ell(\theta)</span> exist a.s., and there exist functions <span class="math inline">m_{rst}(y)</span> such that <span class="math inline">|\partial^3f(y;\theta)/\partial\theta_r \partial\theta _s \partial \theta_t| \le m_{rst}(y)</span> and <span class="math inline">\mathbb{E}_\theta(M_{rst}(\bm{Y})) &lt; \infty</span> for <span class="math inline">r,s,t = 1,\dots,p</span> and <span class="math inline">\theta \in \mathcal{N}</span>.</p>
<p>(<strong>A6</strong>) The <span class="blue">Fisher information matrix</span> is finite and <span class="orange">positive definite</span>, and <span class="math display">
\mathbb{E}_\theta\left[\frac{\partial}{\partial\theta_r}\ell(\theta)\right] = 0, \qquad [I(\theta)]_{rs} = -\mathbb{E}_\theta\left[\frac{\partial^2}{\partial \theta_r \partial \theta_s}\ell(\theta)\right] = \mathbb{E}_\theta\left[\frac{\partial\ell(\theta)}{\partial \theta_r}\frac{\partial\ell(\theta)}{\partial \theta_s}\right],
</span> for <span class="math inline">r,s = 1,\dots,p</span>, that this, the <span class="orange">first</span> and <span class="blue">second Bartlett identities</span>.</p>
</div>
</div>
</div>
</section>
<section id="wald-inequality" class="slide level2 center">
<h2>Wald inequality üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (Wald inequality, <span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 3.2, Chap. 6)</strong></p>
</div>
<div class="callout-content">
<p>Under assumptions <span class="blue">(A1)-(A3)</span>, by the strong law of large numbers: <span class="math display">
\frac{1}{n}\ell(\theta; \bm{Y}) - \frac{1}{n}\ell(\theta_0; \bm{Y}) = \frac{1}{n}\sum_{i=1}^n\log{\frac{f(Y_i; \theta)}{f(Y_i; \theta_0)}} \overset{\text{a.s.}}{\longrightarrow} - \text{KL}(f(\cdot; \theta_0) \mid f(\cdot; \theta)), \qquad n\rightarrow \infty,
</span> where <span class="math inline">\text{KL}</span> is the <span class="blue">Kullback-Leibler divergence</span>, which is <span class="orange">strictly positive</span> for <span class="math inline">\theta \neq \theta_0</span>. Thus: <span class="math display">
\ell(\theta; \bm{Y}) - \ell(\theta_0; \bm{Y}) \overset{\text{a.s.}}{\longrightarrow} - \infty.
</span> Moreover, by the properties of the <span class="math inline">\text{KL}</span>, or using Jensen‚Äôs inequality, we deduce: <span class="math display">
\mathbb{E}_{\theta_0}\left(\ell(\theta; \bm{Y})\right) &lt; \mathbb{E}_{\theta_0}\left(\ell(\theta_0; \bm{Y})\right), \qquad \theta \neq \theta_0,
</span> which is commonly known as <span class="orange">Wald inequality</span>.</p>
</div>
</div>
</div>
</section>
<section id="consistency-for-the-mle" class="slide level2 center">
<h2>Consistency for the MLE</h2>
<ul>
<li><p>Wald inequality is the main workhorse for proving <span class="blue">consistency</span> of the <span class="orange">maximum likelihood</span>.</p></li>
<li><p>Broadly speaking, <span class="blue">on average</span>, the likelihood is <span class="orange">maximized</span> at the true value <span class="math inline">\theta_0</span>, and this holds almost surely for large <span class="math inline">n</span>, suggesting that <span class="math inline">\hat{\theta}_n \rightarrow \theta_0</span> almost surely as <span class="math inline">n\rightarrow \infty</span>.</p></li>
<li><p>We may be tempted to conclude that conditions <span class="blue">(A1)-(A3)</span> are enough to prove consistency. Unfortunately, there are <span class="orange">complications</span> on general spaces <span class="math inline">\Theta</span>. An exception is given below:</p></li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Cor. 3.5, Chap. 6)</strong></p>
</div>
<div class="callout-content">
<p>Under assumptions <span class="blue">(A1)-(A3)</span> and if <span class="math inline">\Theta = (\theta_0,\theta_1,\dots,\theta_k)</span> is <span class="orange">finite</span>, then <span class="math inline">\hat{\theta}_n</span> exists, is unique and is a <span class="blue">consistent estimator</span> of <span class="math inline">\theta_0</span>.</p>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p><span class="grey">Proof</span>. Let <span class="math inline">A_{j,n} = \{\ell(\theta_0) &gt; \ell(\theta_j)\}</span> for <span class="math inline">j=1,\dots,k</span>. It holds <span class="math inline">\mathbb{P}(A_{j,n}) \rightarrow 1</span> as <span class="math inline">n\rightarrow \infty</span>. Hence: <span class="math display">
\mathbb{P}(\ell(\theta_0) &gt; \ell(\theta_j) \text { for all } j=1,\dots,k) = \mathbb{P}(\cap_{j=1}^k A_{j,n}) \ge 1 - \sum_{j=1}^k\mathbb{P}(A_{j,n}^C)\rightarrow 1, \quad n\rightarrow \infty.
</span></p>
</div>
</div>
</div>
</section>
<section id="what-could-go-wrong" class="slide level2 center">
<h2>What could go wrong?</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid sample from the following univariate density<sup>1</sup> <span class="math display">
f(y; \theta) = \frac{1}{2}\phi(y; 0, 1) + \frac{1}{2}\phi(y; \theta, e^{-2/\theta^2}),  \qquad \theta \in \mathbb{R},
</span> where <span class="math inline">\phi(x; \mu, \sigma^2)</span> is the <span class="orange">normal density</span>. The density <span class="math inline">f(y; \theta)</span> satisfies conditions <span class="blue">(A1)-(A4)</span>. Moreover <span class="math inline">\ell(\theta)</span> is <span class="blue">differentiable</span>.</p></li>
<li><p>However, the log-likelihood present <span class="blue">spykes</span> in correspondence of the observed data and the maximum likelihood concentrates around <span class="math inline">0</span> rather than <span class="math inline">\theta_0</span>, i.e <span class="math inline">\hat{\theta}_n</span> is <span class="orange">inconsistent</span>.</p></li>
<li><p>Indeed, there are <span class="blue">multiple roots</span> of the score equation <span class="math inline">\ell^*(\theta)</span>, corresponding to the spykes. The ‚Äúcorrect‚Äù solution close <span class="math inline">\theta_0</span> is among them, but is not identified by the data even for large <span class="math inline">n</span>.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Note this example does not contradict Wald inequality, because the spykes occur on a <span class="orange">set of measure zero</span>. Indeed for any fixed <span class="math inline">\theta</span> the probability of observing <span class="math inline">Y_i = \theta</span> is zero.</p>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn17"><p>This example is taken from a <a href="https://radfordneal.wordpress.com/2008/08/09/inconsistent-maximum-likelihood-estimation-an-ordinary-example/">blogpost</a> of Radford Neal.</p></li></ol></aside></section>
<section id="what-could-go-wrong-1" class="slide level2 center">
<h2>What could go wrong?</h2>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-17-1.png" class="quarto-figure quarto-figure-center r-stretch" width="1600"><ul>
<li>These are <span class="blue">simulated data</span> when the true value is <span class="math inline">\theta_0 = 0.6</span>. We plot the <span class="orange">log-density</span> <span class="math inline">\log{f(y;\theta_0)}</span> and the <span class="blue">log-likelihood</span> <span class="math inline">\ell(\theta)</span> for <span class="math inline">n=10,30,100</span>.</li>
</ul>
</section>
<section id="what-else-could-go-wrong" class="slide level2 center">
<h2>What else could go wrong?</h2>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-18-1.png" width="2000" class="r-stretch"><ul>
<li>The picture depict <span class="math inline">- \text{KL}(f(\cdot; \theta_0) \mid f(\cdot; \theta))</span> in another <span class="orange">problematic</span> situation. The true value is <span class="math inline">\theta_0 = \pi/2</span>, but the presence of the asymptote may cause <span class="math inline">\hat{\theta}_n</span> to <span class="orange">diverge</span>.</li>
</ul>
</section>
<section id="consistency-for-the-mle-1" class="slide level2 center">
<h2>Consistency for the MLE üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Th. 5.1, Chap. 6)</strong></p>
</div>
<div class="callout-content">
<p>Under assumptions <span class="blue">(A1)-(A6)</span>, with probability tending to <span class="math inline">1</span> as <span class="math inline">n\rightarrow \infty</span>, the equation <span class="math inline">\ell^*(\theta) = \bm{0}</span> has at least one root <span class="math inline">\hat{\theta}_n</span>, and there exists a sequence of roots <span class="math inline">\hat{\theta}_n</span> such that <span class="math inline">\hat{\theta}_n \overset{p}{\longrightarrow} \theta_0</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>This standard result of the literature requires several regularity conditions and yet it delivers <span class="orange">less</span> than <span class="orange">what it seems</span>.<sup>1</sup></p></li>
<li><p>The claim is that a <span class="blue">clairvoyant statistician</span>, with knowlegde of <span class="math inline">\theta_0</span>, could choose a consistent sequence of roots. In reality, it may be impossibile to choose the right solution.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Let us further require that, with probability tending to 1 as <span class="math inline">n\to \infty</span>, there is a <span class="blue">unique solution</span> to the <span class="orange">score equation</span>. In that case <span class="math inline">\hat{\theta}_n</span> is <span class="orange">consistent</span> and is also the <span class="blue">global maximizer</span> of <span class="math inline">\ell(\theta)</span>.</p>
</div>
</div>
</div>
<aside><ol class="aside-footnotes"><li id="fn18"><p>See also <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 5.42, for slightly less stringent conditions and a careful discussion about the issue of multiple roots.</p></li></ol></aside></section>
<section id="asymptotic-normality-of-the-mle" class="slide level2 center">
<h2>Asymptotic normality of the MLE üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Th. 5.1, Chap. 6)</strong></p>
</div>
<div class="callout-content">
<p>Under assumptions <span class="blue">(A1)-(A6)</span>, suppose the maximum likelihood estimator <span class="math inline">\hat{\theta}_n</span> exists and is <span class="orange">consistent</span> for the true value <span class="math inline">\theta_0</span>. Then <span class="math display">
\sqrt{n}(\hat{\theta}_n - \theta_0) \overset{\text{d}}{\longrightarrow} \text{N}(0, i(\theta_0)^{-1}), \quad i(\theta) = -\int\left(\frac{\partial^2}{\partial \theta \partial \theta^T}\log{f(y \mid \theta)}\right)f(y \mid \theta)\mathrm{d}y,
</span> where <span class="math inline">n i(\theta)</span> is the <span class="blue">Fisher information matrix</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>Informally, we say that the maximum likelihood estimator is <span class="orange">asymptotically efficient</span> because, roughly speaking, <span class="math inline">\text{var}_\theta(\hat{\theta}_n) \approx I(\theta)^{-1}</span>, the latter being the <span class="blue">Cram√©r-Rao lower bound</span>.</p></li>
<li><p>Rigorously, the above theorem does not establish the convergence of <span class="math inline">\mathbb{E}_\theta(\hat{\theta}_n)</span> and <span class="math inline">\text{var}_\theta(\hat{\theta}_n)</span>, nor have we introduced an asymptotic version of the Cram√©r-Rao bound.</p></li>
<li><p>Nevertheless, the statement that maximum likelihood estimators are <span class="blue">asymptotically efficient</span> is <span class="orange">correct</span>, as rigorously discussed in Chapter 8 of <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>.</p></li>
</ul>
</section>
<section id="observed-vs-fisher-information" class="slide level2 center">
<h2>Observed vs Fisher information</h2>
<ul>
<li>For the <span class="blue">practical</span> construction of <span class="orange">confidence intervals</span>, or simply to empirically assess the variance of an estimator, we need to consider a consistent estimator of <span class="math inline">I(\theta) = n i(\theta)</span>.</li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>The negative <span class="orange">Hessian matrix</span> of the log-likelihood is called <span class="blue">observed information</span> and equals: <span class="math display">
\mathcal{I}(\theta) := - \frac{\partial^2}{\partial \theta \partial \theta^T} \ell(\theta; \bm{Y}).
</span> If the second Bartlett identity holds, the <span class="orange">Fisher information</span> is <span class="math inline">I(\theta) = \mathbb{E}_\theta(\mathcal{I}(\theta))</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>There are two natural candidates for estimating <span class="math inline">I(\theta_0) = n i(\theta_0)</span>, namely <span class="math inline">I(\hat{\theta}_n)</span> and <span class="math inline">\mathcal{I}(\hat{\theta}_n)</span>. These two quantities may coincide, but in general, this is not guaranteed.</p></li>
<li><p>Following Fisher‚Äôs original work, <span class="citation" data-cites="Efron1978">Efron and Hinkley (<a href="#/references" role="doc-biblioref" onclick="">1978</a>)</span> suggested using <span class="math inline">\mathcal{I}(\hat{\theta}_n)</span> because it approximates the <span class="blue">conditional variance</span> of <span class="math inline">\hat{\theta}_n</span> given an appropriate <span class="orange">ancillary statistic</span>.</p></li>
<li><p>Moreover, <span class="math inline">\mathcal{I}(\hat{\theta}_n)</span> can be computed numerically via differentiation, whereas <span class="math inline">I(\hat{\theta}_n)</span> requires analytical derivations.</p></li>
</ul>
</section>
<section id="consistency-for-m-estimators-i" class="slide level2 center">
<h2>Consistency for M-estimators I</h2>
<ul>
<li><p>We now discuss a broader and modern theory for <span class="orange">consistency</span>. Let <span class="math inline">M_n(\theta) = \sum_{i=1}^n m(\theta; Y_i)</span> be an <span class="blue">M-estimator</span> and recall that the <span class="orange">maximum likelihood</span> is a special instance, with <span class="math display">
M_n(\theta) = \sum_{i=1}^n \ell(\theta;Y_i),
</span></p></li>
<li><p>In order to simplify the subsequent exposition, it is convenient to consider <span class="math display">
M_n(\theta) = \textcolor{red}{\frac{1}{n}}\sum_{i=1}^n [\ell(\theta;Y_i) \textcolor{red}{- \ell(\theta_0; Y_i)}] = \frac{1}{n}\sum_{i=1}^n\log{\frac{f(Y_i; \theta)}{f(Y_i; \theta_0)}},
</span> where the red terms are ininfluential because the maximizer <span class="math inline">\hat{\theta}_n</span> of <span class="math inline">M_n(\theta)</span> is the same.</p></li>
<li><p>Under conditions <span class="blue">(A1)-(A3)</span> the law of large numbers guarantees that <span class="math inline">M_n(\theta) \overset{\textup{p}}{\longrightarrow} M(\theta)</span> <span class="orange">pointwise</span> for every <span class="math inline">\theta</span>, where <span class="math inline">M(\theta) = - \text{KL}(f(\cdot; \theta_0) \mid f(\cdot; \theta))</span>. However, this was <span class="orange">not enough</span>.</p></li>
<li><p>On the other hand, we will see that <span class="math inline">\hat{\theta}_n</span> does not need to maximize <span class="math inline">M_n(\theta)</span>. Indeed, it is sufficient that is <span class="blue">nearly maximizes</span> it, in the sense that <span class="math inline">M_n(\hat{\theta}_n) \ge \sup_{\theta \in \Theta}M(\theta) - o_p(1)</span>.</p></li>
</ul>
</section>
<section id="consistency-for-m-estimators-ii" class="slide level2 center">
<h2>Consistency for M-estimators II üìñ</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 5.7)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\theta \subseteq \mathbb{R}^p</span>, <span class="math inline">M_n(\theta)</span> be random functions and <span class="math inline">M(\theta)</span> be a function of <span class="math inline">\theta</span> such that for every <span class="math inline">\epsilon &gt; 0</span> <span class="math display">
\begin{aligned}
\sup_{\theta \in \Theta} \left|M_n(\theta) - M(\theta)\right| \overset{\textup{p}}{\longrightarrow} 0, \qquad \text{(Uniform convergence)} \\
\sup_{\theta : ||\theta- \theta_0||_2 \ge \epsilon} M(\theta) &lt; M(\theta_0). \qquad \text{(Strong identifiability)}
\end{aligned}
</span> Then any sequence of estimators <span class="math inline">\hat{\theta}_n</span> with <span class="math inline">M_n(\hat{\theta}_n) \ge M_n(\theta_0) - o_p(1)</span> <span class="blue">converges in probability</span> to <span class="math inline">\theta_0</span> as <span class="math inline">n\rightarrow \infty</span>.</p>
</div>
</div>
</div>
<ul>
<li><p>The <span class="orange">uniform convergence</span> assumption strengthen the pointwise convergence typically ensured by the law of large numbers, that is, <span class="math inline">m(\theta)</span> should be <span class="blue">Glivenko-Cantelli</span>.</p></li>
<li><p>This holds if <span class="math inline">\Theta</span> is <span class="blue">compact</span>, <span class="math inline">m(\theta)</span> is continuous and dominated by an integrable function.</p></li>
<li><p>The strong identifiability condition, also called <span class="orange">well separability</span> ensures that only point close to <span class="math inline">\theta_0</span> are close to the maximum value <span class="math inline">M(\theta_0)</span>, strengthening Wald inequality.</p></li>
</ul>
</section>
<section id="consistency-for-z-estimators" class="slide level2 center">
<h2>Consistency for Z-estimators üìñ</h2>
<ul>
<li><p>The former theorem can be also expressed in terms of Z-estimators <span class="math inline">Q_n(\theta)</span>, that is, on a set of <span class="orange">estimating equations</span>. An example is the score function <span class="math display">
Q_n(\theta) = \textcolor{red}{\frac{1}{n}}\sum_{i=1}^n \ell^*(\theta; Y_i).
</span></p></li>
<li><p>We require <span class="math inline">\hat{\theta}_n</span> to <span class="blue">nearly solve</span> <span class="math inline">Q_n(\theta) = \bm{0}</span> and that <span class="math inline">\lim_{n\to\infty} Q_n(\theta_0) = \bm{0}</span>. Intuitively, this comes from the <span class="blue">LLN</span> in <span class="orange">unbiased estimating equations</span>, in which case <span class="math inline">\mathbb{E}_{\theta_0}(Q_n(\theta_0)) = \bm{0}</span>.</p></li>
</ul>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 5.9)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\theta \subseteq \mathbb{R}^p</span>, <span class="math inline">Q_n(\theta)</span> be random vector-valued functions and <span class="math inline">Q(\theta)</span> be a vector-valued function of <span class="math inline">\theta</span> such that for every <span class="math inline">\epsilon &gt; 0</span> <span class="math display">
\sup_{\theta \in \Theta} \left ||Q_n(\theta) - Q(\theta)\right||_2 \overset{\textup{p}}{\longrightarrow} 0, \qquad\inf_{\theta : ||\theta- \theta_0||_2 \ge \epsilon} ||Q(\theta)||_2 &gt; ||Q(\theta_0)||_2 = 0.
</span> Then any sequence of estimators <span class="math inline">\hat{\theta}_n</span> such that <span class="math inline">Q_n(\hat{\theta}_n) = o_p(1)</span> <span class="blue">converges in probability</span> to <span class="math inline">\theta_0</span>.</p>
</div>
</div>
</div>
</section>
<section id="asymptotic-normality-of-m-estimators-i" class="slide level2 center">
<h2>Asymptotic normality of M-estimators I</h2>
<div class="callout callout-warning no-icon callout-titled callout-style-simple">
<div class="callout-body">
<div class="callout-title">
<p><strong>Theorem (<span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 5.21)</strong></p>
</div>
<div class="callout-content">
<p>Let <span class="math inline">\Theta \subseteq \mathbb{R}^p</span> and <span class="math inline">M_n(\theta)</span> be an M-estimator whose vector-valued <span class="blue">derivative</span> is <span class="math inline">Q_n(\theta)</span>, so that <span class="math display">
M_n(\theta) = \sum_{i=1}^n m(\theta; Y_i), \qquad Q_n(\theta) = \sum_{i=1}^nq(\theta;Y_i).
</span> Let <span class="math inline">\hat{\theta}_n</span> be a sequence of <span class="orange">consistent</span> estimators such that <span class="math inline">Q_n(\hat{\theta}_n) = 0</span>. Under assumptions <span class="blue">(A1)-(A2)</span> and further <span class="blue">mild regularity conditions</span> <span class="math display">
\sqrt{n}(\hat{\theta}_n - \theta_0) \overset{\text{d}}{\longrightarrow} \text{N}(0, v(\theta_0)^{-1}), \qquad v(\theta) = h(\theta)j(\theta)^{-1}h(\theta),
</span> where <span class="math inline">V(\theta) = n v(\theta)</span> is the <span class="orange">Godambe information matrix</span> and <span class="math display">
h(\theta) = \mathbb{E}_\theta\left(- \frac{\partial}{\partial \theta}q(\theta)\right), \qquad j(\theta) = \mathbb{E}_\theta\left(q(\theta)q(\theta)^T\right).
</span></p>
</div>
</div>
</div>
</section>
<section id="asymptotic-normality-of-m-estimators-ii" class="slide level2 center">
<h2>Asymptotic normality of M-estimators II</h2>
<ul>
<li><p>The previous theorem is very powerful as it applies to the broad class of M-estimators. Moreover, its statement has been substantially <span class="orange">simplified</span> compared to <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>.</p></li>
<li><p>The actual statement does not even require <span class="math inline">Y_1,\dots,Y_n</span> to be independent or identically distributed.</p></li>
<li><p>Moreover, the <span class="blue">regularity conditions</span> are much weaker than <span class="blue">(A1)-(A6)</span> and essentially ensure that the involved quantities are well-defined. <span class="orange">However</span>, note that <span class="math inline">\hat{\theta}_n</span> must be <span class="orange">consistent</span>.</p></li>
<li><p>An alternative proof relying on more <span class="orange">classical conditions</span>, e.g.&nbsp;based on bounding third derivatives as in <span class="blue">(A1)-(A6)</span>, is given in <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorem 5.41.</p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>In regular problems, an M-estimator <span class="math inline">\hat{\theta}_n</span> is <span class="orange">consistent</span> and <span class="blue">asymptotically normal</span>. Moreover, for <span class="math inline">n</span> large enough, its variance is the inverse of the <span class="blue">Godambe information</span>. Informally, <span class="math display">
\hat{\theta}_n \:\dot{\sim}\: \text{N}(\theta_0, V(\theta_0)^{-1}).
</span></p>
</div>
</div>
</div>
</section>
<section id="first-order-bias-correction" class="slide level2 center">
<h2>First-order bias-correction</h2>
<ul>
<li><p>In a regular model with <span class="math inline">\Theta \subseteq \mathbb{R}^p</span> and independent samples, the <span class="orange">bias</span> of the <span class="orange">maximum likelihood estimator</span> can be <span class="orange">expanded</span> as follows: <span class="math display">
\text{bias}_\theta(\hat{\theta}_n) = \frac{b_1(\theta)}{n} + \frac{b_2(\theta)}{n^2} + \mathcal{O}(n^{-3}).
</span></p></li>
<li><p>The quantity <span class="math inline">\text{bias}_\theta(\hat{\theta}_n)</span> is often unavailable, but the <span class="blue">first-order</span> term <span class="math inline">b_1(\theta)</span> might be computable, e.g., in <span class="orange">exponential families</span> (<span class="citation" data-cites="Pace1997">Pace and Salvan (<a href="#/references" role="doc-biblioref" onclick="">1997</a>)</span>, Chap. 9).</p></li>
<li><p>The <span class="orange">jackknife</span> is a popular strategy for removing the first-order bias. Alternatively, the <span class="blue">first-order bias-corrected</span> maximum likelihood estimator is obtained via plug-in as <span class="math display">
\hat{\theta}_\text{bc} = \hat{\theta}_n - \frac{b_1(\hat{\theta}_n)}{n}.
</span></p></li>
<li><p>If <span class="math inline">\tilde{\theta}_n</span> is an estimator of <span class="math inline">\theta</span> with bias of order <span class="math inline">\mathcal{O}(n^{-2})</span>, then <span class="math display">
\text{var}_\theta(\tilde{\theta}_n) = \text{var}_\theta(\hat{\theta}_\text{bc}) + \Delta^2(\theta) + \mathcal{O}(n^{-3}),
</span> where <span class="math inline">\Delta^2(\theta) \geq 0</span>, with equality if and only if <span class="math inline">\hat{\theta}_\text{bc} = \tilde{\theta}_n</span>. In this case, <span class="math inline">\hat{\theta}_\text{bc}</span> is said to be <span class="orange">second-order efficient</span>; see <span class="citation" data-cites="Efron1975b">Efron (<a href="#/references" role="doc-biblioref" onclick="">1975</a>)</span>.</p></li>
</ul>
</section>
<section id="bias-reduction-using-firths-correction-i" class="slide level2 center">
<h2>Bias reduction using Firth‚Äôs correction I</h2>
<ul>
<li><p>The jackknife and <span class="math inline">\hat{\theta}_\text{bs}</span> are ‚Äúcorrective‚Äù rather than ‚Äúpreventive‚Äù. That is, the maximum likelihood <span class="math inline">\hat{\theta}</span> is first calculated, then corrected. A practical requirement is the <span class="orange">existence</span> of <span class="math inline">\hat{\theta}</span>.</p></li>
<li><p>Motivated by this, <span class="citation" data-cites="Firth1993">Firth (<a href="#/references" role="doc-biblioref" onclick="">1993</a>)</span> proposed a <span class="blue">modified score equation</span>. The idea is that the <span class="orange">bias</span> in <span class="math inline">\hat{\theta}</span> can be <span class="orange">reduced</span> by introducing a <span class="blue">small bias</span> into the <span class="blue">score function</span>.</p></li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>In a regular model with <span class="math inline">\Theta \subseteq \mathbb{R}^p</span>, let <span class="math inline">\ell^*(\theta)</span> be the score function, <span class="math inline">I(\theta)</span> the Fisher information matrix and <span class="math inline">b(\theta)</span> the <span class="orange">bias</span> of the maximum likelihood <span class="math inline">\hat{\theta}_n</span>. <span class="citation" data-cites="Firth1993">Firth (<a href="#/references" role="doc-biblioref" onclick="">1993</a>)</span> estimating equation is <span class="math display">
Q(\theta) = \ell^*(\theta) + A(\theta),
</span> where <span class="math inline">A(\theta) = A(\theta; \bm{Y})</span> is any vector such that <span class="math display">
\mathbb{E}_\theta(A(\theta)) = - I(\theta)\frac{b_1(\theta)}{n} + \mathcal{O}(n^{-1/2}).
</span> Clearly, a natural candidate for <span class="math inline">A(\theta; \bm{Y})</span> is indeed <span class="math inline">A(\theta) = - I(\theta)b_1(\theta)/n</span>.</p>
</div>
</div>
</div>
</section>
<section id="bias-reduction-using-firths-correction-ii" class="slide level2 center">
<h2>Bias reduction using Firth‚Äôs correction II</h2>

<img data-src="img/firth.png" class="quarto-figure quarto-figure-center r-stretch" style="width:6in"></section>
<section id="bias-reduction-using-firths-correction-iii" class="slide level2 center">
<h2>Bias reduction using Firth‚Äôs correction III üìñ</h2>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid sample from a Poisson with parameter <span class="math inline">\lambda</span> and consider the reparametrization <span class="math inline">\psi = 1/\lambda</span>. The score and the Fisher information are <span class="math display">
\ell^*(\psi) = \frac{n}{\psi^2} - \frac{\bar{y}}{n \psi}, \qquad I(\psi) = \frac{n}{\psi^3}.
</span> The <span class="orange">maximum likelihood</span> is <span class="math inline">\hat{\psi} = 1/\bar{y}</span>, with <span class="blue">first-order bias</span> <span class="math inline">b_1(\psi)/n = \psi^2/n</span>. Thus <span class="math display">
Q(\psi) = \ell^*(\psi) - I(\psi)b_1(\psi)/n \quad \implies \quad \hat{\psi}_\text{Firth} = \frac{1}{\bar{y} + 1/n}.
</span></p>
</div>
</div>
</div>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an iid sample from a Bernoulli with parameter <span class="math inline">p</span> and consider the reparametrization <span class="math inline">\beta = \log{p/(1-p)}</span>. Application of <span class="citation" data-cites="Firth1993">Firth (<a href="#/references" role="doc-biblioref" onclick="">1993</a>)</span> method gives <span class="math display">
\hat{\beta}_\text{Firth} = \log\left(\frac{n_1 + 1/2}{n - n_1 + 1/2}\right), \quad \text{whereas}\quad \hat{\beta} = \log\left(\frac{n_1}{n - n_1}\right),
</span> which is a well-know <span class="orange">bias-reducing</span> correction of the empirical logit.</p>
</div>
</div>
</div>
</section></section>
<section>
<section id="robustness" class="title-slide slide level1 center">
<h1>Robustness</h1>

</section>
<section id="robustness-preliminaries" class="slide level2 center">
<h2>Robustness: preliminaries</h2>
<ul>
<li><p>Thus far, we have assumed that <span class="math inline">\mathcal{F} = \{f(\cdot;\theta) : \theta \in \Theta\}</span> is <span class="orange">correctly specified</span>, that is, there exists a <span class="math inline">\theta_0</span> that generates the data <span class="math inline">(Y_1,\dots,Y_n) \sim f(\cdot;\theta_0)</span> and <span class="math inline">f(\cdot; \theta_0) \in \mathcal{F}</span>.</p></li>
<li><p>Under this <span class="blue">assumption</span>, we have derived estimators that are <span class="orange">optimal</span> in some sense. However, if the underlying model is not correct, everything breaks down.</p></li>
<li><p>The term ‚Äú<span class="orange">robustness</span>‚Äù is intentionally vague, but let us say that any statistical procedure:</p>
<ol type="a">
<li>Should have nearly optimal efficiency if the model is correctly specified</li>
<li>Small deviations from the model assumptions should impact the model only slightly</li>
<li>Somewhat larger deviations from the model should not cause a catastrophe</li>
</ol></li>
<li><p>We also distinguish among two kinds of robustness:</p>
<ol type="i">
<li>robustness with respect to <span class="blue">contamination</span> of the data (i.e.&nbsp;<span class="math inline">y_i = 10^{32}</span> is an <span class="orange">outlier</span>)</li>
<li>robustness with respect to <span class="orange">model misspecification</span>, that is, we specify a class of models <span class="math inline">\mathcal{F}</span> but in reality <span class="math inline">(Y_1,\dots,Y_n) \sim f_0(\cdot)</span> and <span class="math inline">f_0(\cdot) \notin \mathcal{F}</span>.</li>
</ol></li>
<li><p>Case i. is sometimes called <span class="orange">resistence</span> and relies on the notion of <span class="blue">influence functions</span>. For instance, the median is resistent, the mean is not.</p></li>
</ul>
</section>
<section id="example-huber-estimators-i" class="slide level2 center">
<h2>Example: Huber estimators I üìñ</h2>
<ul>
<li><p>Recall that a Huber estimator <span class="math inline">\hat{\theta}_n</span> for the <span class="orange">mean</span> <span class="math inline">\theta_0</span> is defined as the solution of <span class="math display">
Q(\theta) = \sum_{i=1}^n q(Y_i - \theta)= 0, \qquad q(y) = \begin{cases} -k \quad &amp;\text{ if }\: y \le -k\\
y \quad &amp;\text{ if  }\: |y| \le k \\
k \quad &amp;\text{ if }\: y \ge k\end{cases}.
</span></p></li>
<li><p>We assume <span class="math inline">Y_i \overset{\textup{iid}}{\sim} f_0</span> where <span class="math inline">f_0(y)</span> is a <span class="orange">continuous</span> and <span class="blue">symmetric</span> density around <span class="math inline">\theta_0</span>. Hence, there exists a density <span class="math inline">\tilde{f}_0</span> symmetric around <span class="math inline">0</span> such that <span class="math inline">\tilde{f}_0(y - \theta_0) = f_0(y)</span>.</p></li>
<li><p>First of all, provided <span class="math inline">f_0</span> is symmetric, the estimating equation <span class="math inline">Q(\theta)</span> is <span class="orange">unbiased</span> <span class="math display">
\mathbb{E}_0\{Q(\theta)\} = n \mathbb{E}_0\{q(Y_1 - \theta_0)\} = 0.</span> Broadly speaking, this means that Huber estimator <span class="math inline">\hat{\theta}_n</span> is <span class="orange">consistent</span> for <span class="math inline">\theta_0</span>. Moreover <span class="math display">
\sqrt{n}(\hat{\theta}_n - \theta_0) \overset{\text{d}}{\longrightarrow} \text{N}(0, v^{-1}(\theta_0)),\quad v(\theta)^{-1} = j(\theta)/h(\theta)^2.
</span></p></li>
<li><p>Huber estimator is <span class="orange">robust</span> but <span class="blue">less efficient</span> than the maximum likelihood. For instance, if <span class="math inline">f_0</span> is a Gaussian with mean <span class="math inline">\theta_0</span> and variance <span class="math inline">\sigma^2</span>, then <span class="math inline">\bar{Y}</span> has asymptotic variance <span class="math inline">\sigma^2</span> and <span class="math inline">\sigma^2 \le v(\theta_0)^{-1}</span>.</p></li>
</ul>
</section>
<section id="example-huber-estimators-ii" class="slide level2 center">
<h2>Example: Huber estimators II üìñ</h2>
<ul>
<li>Let <span class="math inline">Z \sim \tilde{f}_0</span>, and note such density <span class="orange">does not depend</span> on <span class="math inline">\theta_0</span>. After some calculations, we find <span class="math display">
j(\theta) = \mathbb{E}_0\{q(Y_1 - \theta)^2\}= \mathbb{E}\{Z^2 I(|Z|&lt; k)\} + 2 k^2 \mathbb{P}(Z &gt; k),
</span> and <span class="math display">
h(\theta) = \mathbb{E}_0\left(-\frac{\partial}{\partial\theta}q(Y_1 - \theta)\right) =  \mathbb{P}(|Z| \le k).
</span></li>
<li>Remarkably, the asymptotic variance does not depend on <span class="math inline">\theta_0</span> therefore its relative efficiency compared to the <span class="orange">normal model</span> is also <span class="blue">constant</span> over <span class="math inline">\theta_0</span>.</li>
</ul>
<ul>
<li>Below we show the <span class="blue">asymptotic relative efficiency</span> (ARE) of the Huber estimator compared to <span class="math inline">\bar{Y}</span> for different values of <span class="math inline">k</span>, assuming <span class="math inline">f_0</span> is Gaussian with <span class="math inline">\sigma^2 = 1</span> and arbitrary <span class="math inline">\theta_0</span></li>
</ul>
<table class="caption-top">
<colgroup>
<col style="width: 31%">
<col style="width: 19%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"><span class="math inline">k</span></th>
<th style="text-align: right;">0 (Median)</th>
<th style="text-align: right;">0.5</th>
<th style="text-align: right;">1</th>
<th style="text-align: right;">1.5</th>
<th style="text-align: right;">2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\text{ARE} = \sigma^2/v(\theta_0)^{-1} = v(\theta_0)</span></td>
<td style="text-align: right;">0.637</td>
<td style="text-align: right;">0.792</td>
<td style="text-align: right;">0.903</td>
<td style="text-align: right;">0.964</td>
<td style="text-align: right;">0.99</td>
</tr>
</tbody>
</table>
<ul>
<li>The ARE does not depend on <span class="math inline">\sigma^2</span> if we use <span class="math inline">k = \sigma \tilde{k}</span>. This is the default of the <code>huber</code> function of the <code>MASS</code> R package with <span class="math inline">\tilde{k} = 1.5</span>, where <span class="math inline">\sigma</span> is robustly estimated using the MAD.</li>
</ul>
</section>
<section id="example-omitted-variable-in-linear-regression" class="slide level2 center">
<h2>Example: omitted variable in linear regression üìñ</h2>
<ul>
<li><p>Let <span class="math inline">y_1,\dots,y_n</span> be realizations from the model <span class="math inline">Y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \epsilon_i</span> for <span class="math inline">i=1,\dots,n</span>, where <span class="math inline">x_i</span> and <span class="math inline">z_i</span> are linearly independent <span class="blue">covariates</span> and <span class="math inline">\epsilon_i \overset{\textup{iid}}{\sim} \text{N}(0, \sigma^2)</span> is the <span class="orange">error term</span>.</p></li>
<li><p>If we do not include <span class="math inline">z_i</span> in our model, the class <span class="math inline">\mathcal{F}</span> is <span class="orange">misspecified</span>. The <span class="orange">maximum likelihood</span> estimate of <span class="math inline">\beta_2</span> under the misspecified <span class="math inline">\mathcal{F}</span> is: <span class="math display">
\hat{\beta}_2 = \frac{1}{\sum_{j=1}^n (x_j - \bar{x})^2}\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y}).
</span></p></li>
<li><p>Thus, the estimator <span class="math inline">\hat{\beta}_2</span>, <span class="blue">under the true model</span> <span class="math inline">f_0</span>, is distributed as a Gaussian with mean <span class="math display">
\mathbb{E}_0(\hat{\beta}_2) = \beta_2 + \beta_3 \frac{1}{\sum_{j=1}^n (x_j - \bar{x})^2}\sum_{i=1}^n (x_i - \bar{x})(z_i - \bar{z}),
</span> and variance <span class="math inline">\sigma^2 / \sum_{j=1}^n (x_j - \bar{x})^2</span>.</p></li>
<li><p>In other words, <span class="math inline">\hat{\beta}_2</span> is <span class="orange">biased</span> and <span class="orange">inconsistent</span> unless <span class="math inline">x</span> and <span class="math inline">z</span> are <span class="blue">uncorrelated</span> or, obviously, if the model is correctly specified, that is if <span class="math inline">\beta_3 = 0</span>.</p></li>
</ul>
</section>
<section id="maximum-likelihood-under-a-misspecified-model" class="slide level2 center">
<h2>Maximum likelihood under a misspecified model üìñ</h2>
<ul>
<li><p>Let <span class="math inline">f_0(\cdot)</span> denote the true probability model, and let <span class="math inline">\mathcal{F} = \{f(\cdot;\theta) : \theta \in \Theta\}</span> be an <span class="orange">incorrectly specified</span> statistical model, such that <span class="math inline">f_0 \notin \mathcal{F}</span>.</p></li>
<li><p>Suppose <span class="math inline">Y_1, \dots, Y_n</span> are <span class="blue">iid</span> under <span class="math inline">f_0</span>, and define the log-likelihood as <span class="math inline">\ell(\theta) = \sum_{i=1}^n \log{f(y_i;\theta)}</span>.</p></li>
<li><p>Let <span class="math inline">\mathbb{E}_0(\cdot)</span> denote expectation under the true model <span class="math inline">f_0</span>. If the problem is <span class="blue">sufficiently regular</span>, the <span class="orange">maximum likelihood</span> estimator <span class="math inline">\hat{\theta}_n</span> <span class="orange">converges</span> in probability to some value <span class="math inline">\theta_0</span> such that <span class="math display">
\mathbb{E}_0\{\ell(\theta)\} &lt; \mathbb{E}_0\{\ell(\theta_0)\}, \quad \text{for all } \theta \in \Theta, \quad \theta \neq \theta_0,
</span> as shown in <span class="citation" data-cites="Huber1967">Huber (<a href="#/references" role="doc-biblioref" onclick="">1967</a>)</span>. That is, <span class="math inline">\hat{\theta}_n</span> converges to a value satisfying <span class="orange">Wald‚Äôs inequality</span>.</p></li>
<li><p>An alternative formulation of this result is the following: <span class="math display">
\mathrm{KL}(f(\cdot; \theta_0) \mid f_0) &lt; \mathrm{KL}(f(\cdot; \theta) \mid f_0), \quad \text{for all } \theta \in \Theta, \quad \theta \neq \theta_0.
</span></p></li>
</ul>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>In other words, the <span class="orange">maximum likelihood</span> converges to <span class="math inline">\theta_0</span>, which represents the parameter value that makes <span class="math inline">f(\cdot;\theta)</span> <span class="blue">as close as possible</span> to the true <span class="math inline">f_0</span>, albeit <span class="math inline">\mathrm{KL}(f(\cdot; \theta_0) \mid f_0) &gt; 0</span>.</p>
<p>The maximum likelihood makes our predictions ‚Äúthe best they can be‚Äù given the chosen model.</p>
</div>
</div>
</div>
</section>
<section id="example-misspecified-exponential-model-i" class="slide level2 center">
<h2>Example: misspecified exponential model I</h2>
<ul>
<li><p>Let <span class="math inline">\mathcal{F} = \{\mu^{-1}e^{-y/\mu} : \mu \in \mathbb{R}^+ \}</span> and suppose the data <span class="math inline">Y_1,\dots,Y_n</span> are iid from an <span class="orange">exponential</span> with mean <span class="math inline">\mu_0</span>. Then <span class="math inline">\bar{Y}</span> is a <span class="blue">consistent</span> and <span class="orange">efficient</span> estimator for <span class="math inline">\mu_0</span>.</p></li>
<li><p>However, <span class="math inline">\bar{Y}</span> is a <span class="orange">robust</span> estimator, in the sense that if instead <span class="math inline">Y_i \overset{\textup{iid}}{\sim} f_0(\cdot)</span> with <span class="math inline">f_0(\cdot) \notin \mathcal{F}</span>, then <span class="math inline">\bar{Y}</span> remains <span class="blue">consistent</span> for the mean <span class="math inline">\mu_0</span> under minimal assumptions on <span class="math inline">f_0</span> (i.e.&nbsp;<span class="math inline">\mu_0</span> must exist).</p></li>
<li><p>On the other hand, the central limit theorem shows that the asymptotic distribution is <span class="math display">
\sqrt{n}(\bar{Y} - \mu) \overset{\textup{d}}{\longrightarrow} \textup{N}(0, \sigma^2).
</span> where <span class="math inline">\sigma^2</span> is the variance of <span class="math inline">Y_i</span> under <span class="math inline">f_0(\cdot)</span>, provided <span class="math inline">\sigma^2 &lt; \infty</span>.</p></li>
<li><p>Thus, <span class="blue">confidence intervals</span> are robust if <span class="math inline">\sigma^2</span> is estimated in a <span class="orange">robust</span> way, e.g.&nbsp;using the <span class="blue">sample variance</span>, but <span class="orange">not</span> if we use the usual <span class="math inline">\hat{\sigma} = i(\hat{\mu})^{-1} = \bar{Y}^2</span> implied by the exponential specification.</p></li>
<li><p>This example can be read under the lenses of estimating equations. The score function <span class="math display">
\ell^*(\mu) = \sum_{i=1}^n(Y_i - \mu)
</span> is an <span class="blue">unbiased estimating equation</span> under <span class="math inline">f_0(\cdot)</span> for a broad class of models beyond <span class="math inline">\mathcal{F}</span>.</p></li>
</ul>
</section>
<section id="robustness-and-unbiased-estimating-equations" class="slide level2 center">
<h2>Robustness and unbiased estimating equations</h2>
<div class="callout callout-tip no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>An essential requirement is that estimands must have the <span class="blue">same interpretation</span> under all the potential models. In the former exponential example <span class="math inline">\mu_0</span> represents the mean of <span class="math inline">f_0</span>.</p>
<p>Formally, this means we can write the parameter <span class="math inline">\theta_0</span> as a <span class="orange">functional of interest</span> <span class="math inline">T(\cdot)</span> of <span class="math inline">f_0</span>: <span class="math display">
\theta_0 = T(f_0).
</span> For example, we might have <span class="math inline">\theta_0 = \int_\mathcal{Y} \bm{y} f_0(\bm{y}) \nu(\mathrm{d}\bm{y})</span>, that is, the mean of <span class="math inline">f_0</span>.</p>
<p>On the other hand, for instance the parameters <span class="math inline">\alpha</span> and <span class="math inline">\beta</span> of a Gamma distribution are not robust to interpretation, because they are meaningless for models other than the Gamma.</p>
</div>
</div>
</div>
<ul>
<li><p>More broadly, if the <span class="orange">score function</span> <span class="math inline">\ell^*(\theta) = \sum_{i=1}^n \ell^*(\theta; Y_i)</span> is <span class="blue">unbiased</span> under <span class="math inline">f_0(\cdot)</span>, the estimator is <span class="blue">consistent</span> under mild conditions.</p></li>
<li><p>Moreover, even if the maximum likelihood <span class="math inline">\hat{\theta}_n</span> is consistent, the <span class="blue">asymptotic variance</span> is not anymore the one induced by the Fisher information: <span class="orange">adjustments</span> are needed.</p></li>
</ul>
</section>
<section id="misspecified-likelihoods-are-m-estimators" class="slide level2 center">
<h2>Misspecified likelihoods are M-estimators</h2>
<ul>
<li><p>The <span class="blue">theory</span> of <span class="blue">M- and Z-estimators</span> can be directly applied to investigate the asymptotic behavior the maximum likelihood estimator <span class="orange">under model misspecification</span>.</p></li>
<li><p>If <span class="math inline">\mathcal{F}</span> is misspecified then the maximizer of the log-likelihood <span class="math inline">\ell(\theta) = \sum_{i=1}^n \log{f(y_i;\theta)}</span> should be regarded as an <span class="orange">M-estimator</span> while the score function <span class="math inline">\ell^*(\theta)</span> is a <span class="blue">Z-estimator</span>.</p></li>
<li><p><span class="orange">Consistency</span> and <span class="blue">asymptotic normality</span> of the maximum likelihood estimator <span class="math inline">\hat{\theta}_n</span> for misspecified models hold under the assumptions in <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, Theorems 5.7, 5.9, 5.21.</p></li>
<li><p>Note that under misspecification, <span class="blue">Bartlett identity</span> does not hold anymore. However, under the assumptions of Theorem 5.21 of <span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>, the maximum likelihood is such that <span class="math display">
\sqrt{n}(\hat{\theta}_n - \theta_0) \overset{\text{d}}{\longrightarrow} \text{N}(0, v(\theta_0)^{-1}), \qquad v(\theta) = h(\theta)j(\theta)^{-1}h(\theta),
</span> where <span class="math inline">V(\theta) = n v(\theta)</span> is the <span class="orange">Godambe information matrix</span> and <span class="math display">
h(\theta) = \mathbb{E}_0\left(- \frac{\partial}{\partial \theta}\ell^*(\theta)\right), \qquad j(\theta) = \mathbb{E}_0\left(\ell^*(\theta)\ell^*(\theta)^T\right).
</span> where expectations are taken over <span class="math inline">f_0</span> and not the misspecified <span class="math inline">f(\cdot; \theta)</span>, so that <span class="math inline">h(\theta) \neq j(\theta)</span>.</p></li>
</ul>
</section>
<section id="sandwich-estimators" class="slide level2 center">
<h2>Sandwich estimators</h2>
<ul>
<li><p>In order to compute <span class="orange">confidence intervals</span> and test hypotheses, we need to estimate the <span class="blue">asymptotic variance</span> of the maximum likelihood estimator <span class="math inline">\hat{\theta}_n</span> under model misspecification.</p></li>
<li><p>Informally, recall that for <span class="math inline">n</span> large enough and under regularity conditions, we have <span class="math display">
\text{var}_0(\hat{\theta}_n) \approx V(\theta_0)^{-1}.
</span></p></li>
<li><p>If the model is correctly specified, then typical <span class="orange">estimators</span> of the <span class="orange">variance</span> of <span class="math inline">\hat{\theta}_n</span> are <span class="math inline">\mathcal{I}(\hat{\theta}_n)</span> and <span class="math inline">I(\hat{\theta}_n)</span>. Unfortunately, we cannot use <span class="math inline">V(\hat{\theta}_n)</span> because it depends on <span class="math inline">f_0</span>, which is unknown!</p></li>
</ul>
<div class="callout callout-note no-icon callout-style-simple">
<div class="callout-body">
<div class="callout-content">
<p>The <span class="blue">sandwich estimator</span> is a popular choice for estimating the <span class="orange">asymptotic variance</span> of <span class="math inline">\hat{\theta}_n</span> under model misspecification. The sandwich estimator for <span class="math inline">V(\theta)</span> is <span class="math display">
\hat{V}(\hat{\theta}_n) = \mathcal{I}(\hat{\theta}_n)\left(\sum_{i=1}^n\ell^*(\hat{\theta}_n; y_i)\ell^*(\hat{\theta}_n; y_i)^T\right)^{-1}\mathcal{I}(\hat{\theta}_n),
</span> recalling that <span class="math inline">\mathcal{I}(\theta) = - \partial/\partial \theta  \:\ell^*(\theta; \bm{y})</span> is the <span class="blue">observed information</span> matrix. If the model is correctly specified then <span class="math inline">\hat{V}(\hat{\theta}_n) = \mathcal{I}(\hat{\theta}_n) + o_p(1)</span>.</p>
</div>
</div>
</div>
</section>
<section id="example-misspecified-exponential-model-ii" class="slide level2 center">
<h2>Example: misspecified exponential model II üìñ</h2>
<ul>
<li><p>Let us consider again <span class="math inline">Y_i \overset{\textup{iid}}{\sim} f_0(\cdot)</span> with <span class="math inline">f_0(\cdot) \notin \mathcal{F}</span>, where <span class="math inline">\mathcal{F}</span> is a <span class="orange">misspecified exponential</span> model.</p></li>
<li><p>The score function is <span class="orange">unbiased</span> for <span class="math inline">\mu</span> under <span class="math inline">f_0</span>. The score and the observed observation matrix are, respectively <span class="math display">
\ell^*(\mu) = \sum_{i=1}^n \left(-\frac{1}{\mu} + \frac{y_i}{\mu^2}\right) = - \frac{n}{\mu} + \frac{n \bar{y}}{\mu^2}, \qquad \mathcal{I}(\mu) = -\frac{\partial}{\partial \mu}\ell^*(\mu) = -\frac{n}{\mu^2} + \frac{2 n \bar{y}}{\mu^3}.
</span></p></li>
<li><p>The inverse of the observed information matrix, evaluated at <span class="math inline">\hat{\mu} = \bar{y}</span>, is an estimate of the asymptotic variance <span class="orange">assuming</span> the model is <span class="blue">correctly specified</span>: <span class="math display">
\text{var}_\theta(\hat{\mu}) \approx \mathcal{I}(\hat{\mu})^{-1} = \frac{\bar{y}^2}{n}.
</span></p></li>
<li><p>If the model is <span class="orange">misspecified</span>, then we can use the <span class="orange">sandwich estimator</span>: <span class="math display">
\text{var}_0(\hat{\mu}) \approx \mathcal{I}(\hat{\mu})^{-2} \sum_{i=1}^n\ell^*(\hat{\mu}; y_i)^2 = \frac{\bar{y}^4}{n^2} \sum_{i=1}^n\frac{1}{\bar{y}^4}(y_i - \bar{y})^2 = \frac{1}{n}\left(\frac{1}{n}\sum_{i=1}^n (y_i - \bar{y})^2\right),
</span> which is the <span class="math inline">n^{-1}</span> times the usual method of moments estimator for the variance.</p></li>
</ul>
</section>
<section id="example-correlated-observations" class="slide level2 center">
<h2>Example: correlated observations</h2>
<ul>
<li><p>Let <span class="math inline">y_1,\dots,y_n</span> be realizations of <span class="orange">dependent</span> random variables from the density <span class="math inline">f(\bm{y};\theta)</span> with <span class="math inline">\Theta \subseteq \mathbb{R}^p</span>. Moreover, let <span class="math inline">f(y_i;\theta)</span> be the <span class="blue">marginal density</span> of <span class="math inline">y_i</span>.</p></li>
<li><p>If the data are dependent, the log-likelihood <span class="math inline">\ell_c(\theta) = \sum_{i=1}^n \log{f(y_i;\theta)}</span> is <span class="orange">misspecified</span>, because it assumes independence. Indeed, <span class="math inline">\ell_c(\theta)</span> is an instance of <span class="blue">composite likelihood</span>.</p></li>
<li><p>Nonetheless, under mild regularity conditions, the <span class="grey">misspecified score function</span> is <span class="orange">unbiased</span> under the true model <span class="math inline">f(\bm{y};\theta)</span>, thanks to the <span class="blue">linearity</span> of the expectation operator: <span class="math display">
\ell^*_c(\theta) = \sum_{i=1}^n \frac{\partial}{\partial \theta}\log{f(y_i;\theta)} \implies \mathbb{E}_0\{\ell^*_c(\theta)\} = \bm{0}.
</span></p></li>
<li><p>Unbiasedness of <span class="math inline">\ell^*_c(\theta)</span> does not guarantee consistency nor asymptotic normality, but both are recovered under mild assumptions on the dependence structure, relying on <span class="blue">ergodic</span> theorems or <span class="orange">martingales</span>. Remarkably, a Godambe-like asymptotic variance is obtained at the limit<sup>1</sup>.</p></li>
</ul>
<aside><ol class="aside-footnotes"><li id="fn19"><p>Refer to Section 7.2.3 in <span class="citation" data-cites="Davison2003">Davison (<a href="#/references" role="doc-biblioref" onclick="">2003</a>)</span> for a discussion on general estimating equations with dependent data and sufficient conditions for consistency and asymptotic normality.</p></li></ol></aside></section>
<section id="example-the-probability-of-observing-a-zero" class="slide level2 center">
<h2>Example: the probability of observing a zero üìñ</h2>
<ul>
<li><p>Let <span class="math inline">Y_1,\dots,Y_n</span> be an <span class="blue">iid</span> sample from a <span class="orange">discrete</span> distribution with pdf <span class="math inline">f_0</span>. We are interested in estimating the following functional <span class="math display">
\psi_0 = \mathbb{P}(Y_i = 0) = f_0(0),
</span></p></li>
<li><p>Under a Poisson model <span class="math inline">\mathcal{F}</span> with mean <span class="math inline">\lambda</span>, <span class="math inline">\psi</span> is reparametrization: <span class="math inline">\psi = e^{-\lambda}</span>. Two estimators are: <span class="math display">
\hat{\psi}_\text{ML} = e^{-\bar{y}} \quad (\text{maximum likelihood}), \qquad \hat{\psi} = \left(\frac{n-1}{n}\right)^{n\bar{y}}, \quad (\text{UMVU}).
</span></p></li>
<li><p>Both estimators are <span class="orange">not robust</span> for <span class="math inline">\psi_0</span> under model misspecification, unless under <span class="math inline">\psi_0</span> we have <span class="math inline">\psi_0 = e^{-\mu_0}</span>. Indeed, the score equation is <span class="orange">biased</span>, being equal to <span class="math display">
\ell^*(\psi) = \frac{n}{\psi}\left(1 - \frac{\bar{y}}{-\log{\psi}}\right) \implies \mathbb{E}_0\{\ell^*(\psi_0)\} = \frac{n}{\psi_0}\left(1 - \frac{\mu_0}{-\log{\psi_0}}\right).
</span></p></li>
<li><p>A <span class="orange">robust alternative</span> is given by the <span class="blue">empirical proportion</span> of zero: <span class="math display">
\hat{\psi}_\text{MM} = \frac{1}{n}\sum_{i=1}^n \mathbb{I}(y_i = 0).
</span></p></li>
</ul>
</section>
<section id="example-linear-models-with-misspecified-variance-i" class="slide level2 center">
<h2>Example: linear models with misspecified variance I üìñ</h2>
<ul>
<li><p>Let <span class="math inline">Y_i = \bm{x}_i^T\beta + \epsilon_i</span>, where the <span class="orange">errors</span> <span class="math inline">\epsilon_i</span> are random variables distributed according to <span class="math inline">f_0</span>, whereas <span class="math inline">\bm{x}_i</span> are <span class="blue">known covariates</span> and <span class="math inline">\beta \in \mathbb{R}^p</span> is a <span class="orange">parameter</span> of interest.</p></li>
<li><p>If we further assume that <span class="math inline">\epsilon_i \overset{\textup{iid}}{\sim} \text{N}(0, \sigma^2)</span>, then the <span class="orange">maximum likelihood estimator</span> <span class="math inline">\hat{\beta} = (\bm{X}^T\bm{X})^{-1}\bm{X}^T\bm{y}</span> is the <span class="blue">least squares estimator</span>. Moreover, the <span class="blue">score function</span> is <span class="math display">
\ell^*(\beta) = \frac{1}{\sigma^2}\sum_{i=1}^n \bm{x}_i(y_i - \bm{x}_i^T\beta) = \frac{1}{\sigma^2}\bm{X}^T(\bm{y} - \bm{X}\beta),
</span> whereas the Fisher/observed <span class="orange">information matrix</span> is <span class="math display">
I(\beta) = \mathcal{I}(\beta) = \frac{1}{\sigma^2}\sum_{i=1}^n \bm{x}_i\bm{x}_i^T = \frac{1}{\sigma^2}\bm{X}^T\bm{X} \implies \text{var}_\beta(\hat{\beta}) = \sigma^2 (\bm{X}^T\bm{X})^{-1}.
</span></p></li>
<li><p>Provided that <span class="math inline">\mathbb{E}_0(Y_i) = \bm{x}_i^T\beta</span>, that is, as long as the <span class="blue">linearity assumption</span> holds under <span class="math inline">f_0</span>, then the OLS estimator is <span class="orange">robust</span> and <span class="blue">unbiased</span> even when <span class="math inline">\epsilon_i</span> are not Gaussian or <span class="orange">not iid</span>.</p></li>
<li><p>If the iid Gaussian model is <span class="orange">misspecified</span>, e.g.&nbsp;because <span class="math inline">\text{var}_0(\epsilon_i) = \sigma^2_i</span> (heteroskedasticity), then the OLS estimator is still a good choice but its variance should be adjusted.</p></li>
</ul>
</section>
<section id="example-linear-models-with-misspecified-variance-ii" class="slide level2 center">
<h2>Example: linear models with misspecified variance II üìñ</h2>
<ul>
<li><p>The <span class="blue">variance</span> of <span class="math inline">\hat{\beta}</span> under a general model <span class="math inline">f_0</span> in which the random vector <span class="math inline">(\epsilon_1,\dots,\epsilon_n)</span> has zero mean and <span class="math inline">\text{var}_0(\bm{\epsilon}) = \bm{\Sigma}</span>, is explicity available <span class="math display">
\text{var}_0(\hat{\beta}) =  (\bm{X}^T\bm{X})^{-1} \bm{X}^T \bm{\Sigma}\bm{X} (\bm{X}^T\bm{X})^{-1}.
</span> This coincides with the inverse <span class="blue">Godambe information</span> of the <span class="orange">estimating equation</span> <span class="math inline">\ell^*(\beta)</span>: <span class="math display">
\text{var}_0(\hat{\beta}) = I(\beta)^{-1} \mathbb{E}_0\left\{\frac{1}{\sigma^4}\bm{X}^T(\bm{Y} - \bm{X}\beta)(\bm{Y} - \bm{X}\beta)\bm{X}\right\} I(\beta)^{-1}
</span></p></li>
<li><p>In practice, the matrix <span class="math inline">\bm{\Sigma}</span> is unknown. Thus, we rely on the <span class="blue">sandwich estimator</span>: <span class="math display">
\begin{aligned}
\hat{V}(\hat{\beta})^{-1} &amp;= I(\hat{\beta})^{-1} \left\{\frac{1}{\sigma^4}\sum_{i=1}^n \bm{x}_i(y_i - \bm{x}_i^T\hat{\beta})(y_i - \bm{x}_i^T\hat{\beta})\bm{x}_i^T\right\} I(\hat{\beta})^{-1} \\
&amp;= (\bm{X}^T\bm{X})^{-1} \bm{X}^T \bm{R}^2 \bm{X} (\bm{X}^T\bm{X})^{-1},
\end{aligned}
</span> where <span class="math inline">\bm{R}^2 = \text{diag}(r_1^2,\dots,r_n^2)</span> and <span class="math inline">r_i = y_i - \bm{x}_i^T\hat{\beta}</span> are the <span class="orange">residuals</span>.</p></li>
<li><p>This <span class="orange">robust</span> estimator is known as the <span class="blue">White‚Äôs correction</span> after <span class="citation" data-cites="White1980">White (<a href="#/references" role="doc-biblioref" onclick="">1980</a>)</span>, who also proved it is consistent if <span class="math inline">\bm{\Sigma} = \text{diag}(\sigma_1^2,\dots,\sigma_n^2)</span> and under technical conditions on <span class="math inline">\bm{X}</span>.</p></li>
</ul>
</section>
<section id="example-linear-models-with-misspecified-variance-iii" class="slide level2 center">
<h2>Example: linear models with misspecified variance III</h2>

<img data-src="un_A_files/figure-revealjs/unnamed-chunk-21-1.png" width="2400" class="r-stretch"><ul>
<li>In this example, we fit a linear model (in the parameters!) so that <span class="math inline">\bm{Y} = \bm{X}\beta + \epsilon</span> using <span class="blue">least squares</span>, with <span class="math inline">p = 12</span>. The residuals clearly show <span class="orange">heteroskedasticity</span>.</li>
</ul>
</section>
<section id="example-linear-models-with-misspecified-variance-iv" class="slide level2 center">
<h2>Example: linear models with misspecified variance IV</h2>
<ul>
<li>The <span class="blue">standard</span> estimator is <span class="math inline">\hat{\sigma}^2 (\bm{X}^T\bm{X})^{-1}</span>. Below we show the first <span class="math inline">4 \times 4</span> entries</li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span class="math inline">\beta_1</span></th>
<th style="text-align: right;"><span class="math inline">\beta_2</span></th>
<th style="text-align: right;"><span class="math inline">\beta_3</span></th>
<th style="text-align: right;"><span class="math inline">\beta_4</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\beta_1</span></td>
<td style="text-align: right;"><strong>113.11</strong></td>
<td style="text-align: right;">-47.95</td>
<td style="text-align: right;">17.70</td>
<td style="text-align: right;">-12.81</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\beta_2</span></td>
<td style="text-align: right;">-47.95</td>
<td style="text-align: right;"><strong>170.53</strong></td>
<td style="text-align: right;">-73.32</td>
<td style="text-align: right;">54.10</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\beta_3</span></td>
<td style="text-align: right;">17.70</td>
<td style="text-align: right;">-73.32</td>
<td style="text-align: right;"><strong>87.43</strong></td>
<td style="text-align: right;">-69.35</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\beta_4</span></td>
<td style="text-align: right;">-12.81</td>
<td style="text-align: right;">54.10</td>
<td style="text-align: right;">-69.35</td>
<td style="text-align: right;"><strong>217.58</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>The <span class="orange">sandwhich (White)</span> estimator is instead <span class="math inline">(\bm{X}^T\bm{X})^{-1} \bm{X}^T \bm{R}^2 \bm{X} (\bm{X}^T\bm{X})^{-1}</span>:</li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span class="math inline">\beta_1</span></th>
<th style="text-align: right;"><span class="math inline">\beta_2</span></th>
<th style="text-align: right;"><span class="math inline">\beta_3</span></th>
<th style="text-align: right;"><span class="math inline">\beta_4</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\beta_1</span></td>
<td style="text-align: right;"><strong>2.82</strong></td>
<td style="text-align: right;">-9.73</td>
<td style="text-align: right;">9.45</td>
<td style="text-align: right;">-8.80</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\beta_2</span></td>
<td style="text-align: right;">-9.73</td>
<td style="text-align: right;"><strong>42.79</strong></td>
<td style="text-align: right;">-43.71</td>
<td style="text-align: right;">40.57</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\beta_3</span></td>
<td style="text-align: right;">9.45</td>
<td style="text-align: right;">-43.71</td>
<td style="text-align: right;"><strong>72.01</strong></td>
<td style="text-align: right;">-67.22</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\beta_4</span></td>
<td style="text-align: right;">-8.80</td>
<td style="text-align: right;">40.57</td>
<td style="text-align: right;">-67.22</td>
<td style="text-align: right;"><strong>288.72</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>We used the <code>sandwich</code> R package, that implements several sandwich variants.</li>
</ul>
</section></section>
<section>
<section id="references-and-study-material" class="title-slide slide level1 center">
<h1>References and study material</h1>

</section>
<section id="main-references" class="slide level2 center">
<h2>Main references</h2>
<ul>
<li><span class="citation" data-cites="Davison2003">Davison (<a href="#/references" role="doc-biblioref" onclick="">2003</a>)</span>
<ul>
<li><span class="orange">Chapter 4</span> (<em>Likelihood</em>)</li>
<li><span class="orange">Chapter 7</span> (<em>Estimation and Hypothesis Testing</em>)</li>
<li><span class="orange">Chapter 8</span> (<em>Linear Regression Model</em>)</li>
</ul></li>
<li><span class="citation" data-cites="Casella2002">Casella and Berger (<a href="#/references" role="doc-biblioref" onclick="">2002</a>)</span>
<ul>
<li><span class="blue">Chapter 7</span> (<em>Point estimation</em>)</li>
<li><span class="blue">Chapter 10</span> (<em>Asymptotic evaluations</em>)</li>
</ul></li>
<li><span class="citation" data-cites="Pace1997">Pace and Salvan (<a href="#/references" role="doc-biblioref" onclick="">1997</a>)</span>
<ul>
<li><span class="grey">Chapter 2</span> (<em>Data and model reduction</em>)</li>
<li><span class="grey">Chapter 3</span> (<em>Survey of basic concepts and techniques</em>)</li>
</ul></li>
</ul>
</section>
<section id="additional-references" class="slide level2 center">
<h2>Additional references</h2>
<ul>
<li><span class="citation" data-cites="Lehmann1998">Lehmann and Casella (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>
<ul>
<li><span class="orange">Chapter 1</span> (<em>Preparations</em>)</li>
<li><span class="orange">Chapter 2</span> (<em>Unbiasedness</em>)</li>
<li><span class="orange">Chapter 4</span> (<em>Average risk optimality</em>)</li>
<li><span class="orange">Chapter 5</span> (<em>Minimax and admissibility</em>)</li>
<li><span class="orange">Chapter 5</span> (<em>Minimax and admissibility</em>)</li>
<li><span class="orange">Chapter 6</span> (<em>Asymptotic optimality</em>)</li>
</ul></li>
<li><span class="citation" data-cites="Robert1994">Robert (<a href="#/references" role="doc-biblioref" onclick="">1994</a>)</span>
<ul>
<li><span class="orange">Chapter 2</span> (<em>Decision-theoretic foundations</em>)</li>
</ul></li>
<li><span class="citation" data-cites="vandervaart1998">van der Vaart (<a href="#/references" role="doc-biblioref" onclick="">1998</a>)</span>
<ul>
<li><span class="blue">Chapter 4</span> (<em>Moment estimators</em>)</li>
<li><span class="blue">Chapter 5</span> (<em>M- and Z-Estimators</em>)</li>
</ul></li>
</ul>
</section>
<section id="references" class="slide level2 unnumbered smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Agresti2015" class="csl-entry" role="listitem">
Agresti, A. (2015), <em><span class="nocase">Foundations of Linear and Generalized Linear Models</span></em>, Wiley.
</div>
<div id="ref-Casella2002" class="csl-entry" role="listitem">
Casella, G., and Berger, R. L. (2002), <em><span>Statistical Inference</span></em>, Duxbury.
</div>
<div id="ref-Davison2003" class="csl-entry" role="listitem">
Davison, A. C. (2003), <em><span>Statistical Models</span></em>, Cambridge University Press.
</div>
<div id="ref-Diaconis1979" class="csl-entry" role="listitem">
Diaconis, P., and Ylvisaker, D. (1979), <span>‚Äú<span class="nocase">Conjugate prior for exponential families</span>,‚Äù</span> <em>The Annals of Statistics</em>, 7, 269‚Äì292.
</div>
<div id="ref-Efron1975b" class="csl-entry" role="listitem">
Efron, B. (1975), <span>‚Äú<span class="nocase">Defining the curvature of a statistical problem (with applications to second order efficiency)</span>,‚Äù</span> <em>The Annals of Statistics</em>, 3, 1189‚Äì1242.
</div>
<div id="ref-Efron2010" class="csl-entry" role="listitem">
Efron, B. (2010), <em><span class="nocase">Large Scale Inference: Empirical Bayes Methods for Estimation, Testing, and Prediction</span></em>, Institute of mathematical statistics monographs, Leiden: Cambridge University Press.
</div>
<div id="ref-Efron2016" class="csl-entry" role="listitem">
Efron, B., and Hastie, T. (2016), <em><span>Computer Age Statistical Inference</span></em>, Cambridge University Press.
</div>
<div id="ref-Efron1978" class="csl-entry" role="listitem">
Efron, B., and Hinkley, D. V. (1978), <span>‚ÄúAssessing the accuracy of the maximum likelihood estimator: Observed vs fisher information,‚Äù</span> <em>Biometrika</em>, 65, 457‚Äì482.
</div>
<div id="ref-Efron1975" class="csl-entry" role="listitem">
Efron, B., and Morris, C. (1975), <span>‚Äú<span class="nocase">Data analysis using Stein‚Äôs estimator and its generalizations</span>,‚Äù</span> <em>Journal of the American Statistical Association</em>, 70, 311‚Äì319.
</div>
<div id="ref-Firth1993" class="csl-entry" role="listitem">
Firth, D. (1993), <span>‚ÄúBias reduction of maximum likelihood estimates,‚Äù</span> <em>Biometrika</em>, 80, 27‚Äì38.
</div>
<div id="ref-Godambe1960" class="csl-entry" role="listitem">
Godambe, V. P. (1960), <span>‚Äú<span class="nocase">An optimum property of regular maximum likelihood estimation</span>,‚Äù</span> <em>Annals of Mathematical Statistics</em>, 31, 1208‚Äì1211.
</div>
<div id="ref-Huber1967" class="csl-entry" role="listitem">
Huber, P. J. (1967), <span>‚ÄúThe behavior of maximum likelihood estimates under nonstandard conditions,‚Äù</span> in <em>Proceedings of the fifth berkeley symposium on mathematical statistics and probability</em>.
</div>
<div id="ref-James1961" class="csl-entry" role="listitem">
James, W., and Stein, C. (1961), <span>‚ÄúEstimation with quadratic loss,‚Äù</span> in <em>Proc. Fourth berkeley symposium</em>, <span>University of California Press</span>, pp. 361‚Äì380.
</div>
<div id="ref-Lehmann1998" class="csl-entry" role="listitem">
Lehmann, E. L., and Casella, G. (1998), <em><span class="nocase">Theory of Point Estimation, Second Edition</span></em>, Springer.
</div>
<div id="ref-Pace1997" class="csl-entry" role="listitem">
Pace, L., and Salvan, A. (1997), <em><span class="nocase">Principles of statistical inference from a Neo-Fisherian perspective</span></em>, Advanced series on statistical science and applied probability, World Scientific.
</div>
<div id="ref-Robert1994" class="csl-entry" role="listitem">
Robert, C. P. (1994), <em><span class="nocase">The Bayesian Choice: from decision-theoretic foundations to computational implementation</span></em>, Springer.
</div>
<div id="ref-Stein1956" class="csl-entry" role="listitem">
Stein, C. (1956), <span>‚ÄúInadmissibility of the usual estimator of the mean of a multivariate normal distribution,‚Äù</span> in <em><span>Proc. Third Berkeley Symposium</span></em>, <span>University of California Press</span>, pp. 197‚Äì206.
</div>
<div id="ref-vandervaart1998" class="csl-entry" role="listitem">
van der Vaart, A. W. (1998), <em><span>Asymptotic Statistics</span></em>, Cambridge University Press.
</div>
<div id="ref-White1980" class="csl-entry" role="listitem">
White, H. (1980), <span>‚Äú<span class="nocase">A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity</span>,‚Äù</span> <em>Econometrica</em>, 4, 817‚Äì838.
</div>
</div>
<div class="quarto-auto-generated-content">
<p><img src="img/logoB.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://tommasorigon.github.io/InferentialStat">Home page</a></p>
</div>
</div>
</section></section>

    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="un_A_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="un_A_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="un_A_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="un_A_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="un_A_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="un_A_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="un_A_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="un_A_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="un_A_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>