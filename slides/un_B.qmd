---
title: "Generalized Linear Models"
subtitle: "Statistics III - CdL SSE"
author: "[Tommaso Rigon]{.orange}"
institute: "_Universit√† degli Studi di Milano-Bicocca_"
page-layout: full
bibliography: ../biblio.bib
citeproc: true
csl: https://www.zotero.org/styles/journal-of-the-american-statistical-association
reference-location: margin
execute:
  cache: false
filters: 
  - remove-pause.lua
format:
  revealjs:
    auto-stretch: true
    center: true
    html-math-method: katex
    transition: none
    output-file: un_B_slides.html
    slide-number: true
    callout-appearance: minimal
    code-line-numbers: true
    theme: [default, ../template.css] # alternative themes (subset): default, night, dark
    embed-resources: false
    echo: false
    fig-dpi: 250
    # incremental: true  # Remove comment if you like incremental bullet points
    logo: img/logoB.png
    footer: "[Home page](https://tommasorigon.github.io/StatIII)"
  html:
    html-math-method: katex
    echo: false
    callout-appearance: minimal
    theme: [simplex, ../template.css]
    toc: true
    toc-title: Table of contents
    embed-resources: false
    smooth-scroll: true
    fig-dpi: 250
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

## [Homepage](../index.html)

```{r}
#| warning: false
#| echo: false
#| include: false
#| message: false
#| purl: false
rm(list = ls())
knitr::purl("un_B.qmd", output = "../code/un_B.R", documentation = 0)
styler:::style_file("../code/un_B.R")

library(ggplot2)
library(ggthemes)
library(MLGdata)
```

::: columns
::: {.column width="30%"}
![](img/gaussian.png)
:::

::: {.column width="70%"}
- This unit will cover the following [topics]{.orange}:
    - Exponential dispersion families
    - Likelihood, inference and testing
    - Iteratively Re-weighted Least Squares (IRLS)
    - Deviance, model checking, and residuals
    - Model selection
    
- GLMs are regression models with a linear predictor in which the response variable is distributed according to an [exponential dispersion family]{.blue}.

- This  Unit covers the [theoretical backbone]{.orange} of GLMs.
:::
:::

:::callout-tip
The content of this Unit is covered in [Chapter 2]{.orange} of @Salvan2020. Alternatively, see [Chapter 4]{.blue} of @Agresti2015 or [Chapter 6]{.grey} of @Azzalini2008.
:::

# Introduction

## Preliminaries

- GLMs are a class of [regression models]{.blue} where we describe a [response]{.orange} random variable $Y_i$ as a function of a vector of [covariates]{.grey} $\bm{x}_i \in \mathbb{R}^p$.  

- The random variables $Y_i$ are not restricted to be Gaussian. For example, we may have  
  - $Y_i \in \{0,1\}$, often called [binary regression]{.blue}  
  - $Y_i \in \{0,1,\dots\}$, often called [count regression]{.orange}  
  - $Y_i \in (0,\infty)$ or $Y_i \in (-\infty,\infty)$  

- Gaussian linear models form a special case of GLMs, arising when  $Y_i \in (-\infty,\infty)$

. . .

- The [response random variables]{.orange} are collected in the random vector $\bm{Y} = (Y_1,\dots,Y_n)^T$, whose [observed realization]{.blue} is $\bm{y} = (y_1,\dots,y_n)^T$.

- The [design matrix]{.blue} $\bm{X}$ is a $n \times p$ matrix, comprising the covariate's values. The $j$th variable (column) is denoted with $\tilde{\bm{x}}_j$, whereas the $i$th observation (row) is $\bm{x}_i$.

## `Beetles` data, from Bliss (1935) 

- The `Beetles` dataset originates from Bliss (1935). It records the number of adult flour beetles that died after a 5-hour exposure to gaseous carbon disulphide.

```{r}
data("Beetles")
colnames(Beetles) <- c("n", "deaths", "logdose")
knitr::kable(Beetles)
```

- We aim to predict the proportion of `deaths` as a function of the `logdose`.

- Modelling death proportions directly with [linear models]{.orange} is [inappropriate]{.orange}. While a [variable transformation]{.blue} offers a more [principled]{.blue} approach, it has important [drawbacks]{.orange}.

## `Beetles` data, a dose-response plot

```{r}
#| fig-width: 7.8
#| fig-height: 4.55
#| fig-align: center
ggplot(data = Beetles, aes(x = logdose, y = deaths/n)) +
  geom_point() +
  theme_light() +
  theme(legend.position = "right") +
  scale_color_tableau(palette = "Color Blind") +
  xlab("log-dose") +
  ylab("Proportion of deaths")
```

- There is a clear [positive]{.orange} and [non-linear]{.blue} pattern between the [proportion of deaths]{.orange} as a function of the logdose. The response variable take values in $[0, 1]$. 

## An attempt at modelling the `Beetles` data

- Let $Y_i$ the number of dead beetles out of $m_i$, and let $x_i$ be the log-dose. By definition, the random variables $Y_i \in \{0, 1, \dots, m_i\}$ for $i=1,\dots,8$. 

- It is reasonable to model each $Y_i$ as [independent binomial]{.blue} random variables, counting the number of deaths out of $m_i$ individuals. In other words:
$$
Y_i \overset{\text{ind}}{\sim} \text{Binomial}(m_i, \pi_i), \qquad i=1,\dots,8,
$$
where $\pi_i$ is the [probability]{.orange} of dying at a given dose $x_i$, and we know that
$$
\mathbb{E}\left(\frac{Y_i}{m_i}\right) = \mu_i = \pi_i.
$$

- A modelling possibility, called [logistic regression]{.blue}, prescribes the following:
$$
g(\pi_i) = \log\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_1 + \beta_2 x_i \quad \Longrightarrow \quad \pi_i = g^{-1}(\beta_1 + \beta_2 x_i) = \frac{\exp(\beta_1 + \beta_2 x_i)}{1 + \exp(\beta_1 + \beta_2 x_i)}.
$$
for some parameters $\beta_1,\beta_2 \in \mathbb{R}$. [Note]{.orange} that $\pi_i \in (0, 1)$ by construction. 

## `Beetles` data, fitted model

```{r}
#| fig-width: 7.8
#| fig-height: 4.55
#| fig-align: center

fit_Beetles <- glm(cbind(deaths, n - deaths) ~ logdose, family = "binomial", data = Beetles)

ggplot(data = Beetles, aes(x = logdose, y = deaths/n)) +
  geom_point() +
  geom_function(fun = function(x) plogis(coef(fit_Beetles)[1] + coef(fit_Beetles)[2] * x), linetype = "dashed") +
  theme_light() +
  xlab("log-dose") +
  ylab("Proportion of deaths")
```

- The [maximum likelihood]{.orange} estimates are $\hat{\beta}_1 = -60.72$ and $\hat{\beta}_2 = 34.3$. This gives the [predictive curve]{.blue} $\hat{\pi}(x) = g^{-1}(\hat{\beta}_1 + \hat{\beta}_2x)$, an estimate for the mean proportion $\mathbb{E}(Y_i/m_i)$. 


## Alternative modelling approaches I üìñ

- Let $Z_i = Y_i/m_i$ be the proportion of deaths. A direct application of linear models means:
$$
Z_i = \beta_1 + \beta_2 x_i + \epsilon_i.
$$
This is [not]{.orange} a [good approach]{.orange}. In the first place, while $Z_i \in [0, 1]$ the prediction $\beta_1 + \beta_2 x_i$ would be [unrestricted]{.orange}. This means we could get "1.3" or "-2" as estimated proportion.

- Secondly, the [additive structure]{.blue} $Z_i = \beta_1 + \beta_2 x_i + \epsilon_i$ cannot hold for iid errors $\epsilon_i$, because $Y_i$, and hence $Z_i$, are [discrete]{.orange}. The errors would be [heteroskedastic]{.orange}. 

. . .

- A better alternative would be considering a variable transformation of $Z_i$, obtaining
$$
\text{logit}(\tilde{Z}_i) = \log\left(\frac{Y_i + 0.5}{m_i - Y_i + 0.5}\right) = \beta_1 + \beta_2 x_i + \epsilon_i, \qquad \tilde{Z}_i = \frac{Y_i + 0.5}{m_i +1}.
$$
The [arbitrary]{.orange} correction term is necessary because otherwise the logit would be undefined. 

- The predictions are $\hat{\pi}_i = g^{-1}[\mathbb{E}\{g(\tilde{Z}_i)\}] = g^{-1}(\hat{\beta}_1 + \hat{\beta}_2 x_i)$, in which $\hat{\beta}_1$ and $\hat{\beta_2}$ are estimated using OLS. The [interpretation]{.blue} of $\hat{\beta}$ is less clear, as they refer to the mean of $g(\tilde{Z}_i)$.

- Inference is also problematic because of [heteroskedastic]{.orange} errors. Finally, this approach is [not compatible]{.orange} with the very reasonable assumption $Y_i \sim \text{Binomial}(m_i, \pi_i)$. 


## Alternative modelling approaches II

```{r}
#| fig-width: 7.8
#| fig-height: 4.55
#| fig-align: center

fit_Beetles_lm <- lm(I(deaths / n) ~ logdose, data = Beetles)
fit_Beetles_logit <- lm(qlogis((deaths + 0.5) / (n + 1)) ~ logdose, data = Beetles)

ggplot(data = Beetles, aes(x = logdose, y = deaths/n)) +
  xlim(c(1.65, 1.92)) + 
  geom_point() +
  geom_function(fun = function(x) plogis(coef(fit_Beetles)[1] + coef(fit_Beetles)[2] * x), linetype = "dashed") + geom_function(fun = function(x) coef(fit_Beetles_lm)[1] + coef(fit_Beetles_lm)[2] * x, linetype = "dashed", col = "darkorange") + geom_function(fun = function(x) plogis(coef(fit_Beetles_logit)[1] + coef(fit_Beetles_logit)[2] * x), linetype = "dashed", col = "darkblue") +
  theme_light() +
  xlab("log-dose") +
  ylab("Proportion of deaths")
```

- The black line is the predicted curve of a [logistic regression GLM]{.grey}. The orange line is the predictived curve of a [linear model]{.orange}. The blue line is the predictive curve of a [linear model]{.blue} after an [empirical logit variable transformation]{.blue}.

## `Aids` data

- Number of AIDS `deaths` in Australia in a sequence of three-months periods between 1983 and 1986.

:::{.smaller}
```{r}
data(Aids)
colnames(Aids) <- c("deaths", "period")
rownames(Aids) <- paste(1983:1986, rep(1:4, each = 4), sep = "-")[-c(15:16)]
knitr::kable(t(Aids[1:7, ]))
knitr::kable(t(Aids[8:14, ]))
```
:::

- We are interested in predicting the number of `deaths` as a function of the `period` of time.

- The response variable $Y_i \in \{0, 1, \dots\}$ is a [count]{.orange}. 

## `Aids` data, scatter plot

```{r}
#| fig-width: 7.8
#| fig-height: 4.55
#| fig-align: center
ggplot(data = Aids, aes(x = period, y = deaths)) +
  geom_point() +
  theme_light() +
  xlab("Period") +
  ylab("Deaths")
```

- There is a clear positive pattern between `period` and `deaths`. However, the growth is likely [faster]{.orange} than [linear]{.orange}. Note that the both the mean and the [variability]{.blue} of $Y_i$ grow over time. 

## An attempt at modelling the `Aids` data

## `Aids` data, fitted model

```{r}
fit_Aids <- glm(deaths ~ period, family = "poisson", data = Aids)

ggplot(data = Aids, aes(x = period, y = deaths)) +
  geom_point() +
  geom_function(fun = function(x) exp(coef(fit_Aids)[1] + coef(fit_Aids)[2] * x), linetype = "dashed") +
  theme_light() +
  xlab("Period") +
  ylab("Deaths")
```


## Alternative modelling approaches I üìñ

## Alternative modelling approaches II

## Components of a GLM

## Random component of a GLM

## Linear predictor of a GLM

## Link function of a GLM

## Advantages of GLMs versus transforming the data

# Exponential dispersion families

## Overview

- Figure 1 of @Efron2023. [Three level]{.grey} of statistical modeling. 


![](img/EF.png){width=6in fig-align="center"}


- The [prime role]{.orange} of [exponential families]{.orange} in the theory of statistical inference was first emphasized by @Fisher1934.

- Most [well-known]{.blue} [distributions]{.blue}---such as Gaussian, Poisson, Binomial, and Gamma---are instances of exponential families.


# Generalized Linear Models

## References {.unnumbered}

::: {#refs}
:::
