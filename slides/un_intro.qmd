---
title: "Introduction"
subtitle: "Statistics III - CdL SSE"
author: "[Tommaso Rigon]{.orange}"
institute: "_Università degli Studi di Milano-Bicocca_"
page-layout: full
bibliography: ../biblio.bib
citeproc: true
csl: https://www.zotero.org/styles/journal-of-the-american-statistical-association
reference-location: margin
execute:
  cache: false
filters: 
  - remove-pause.lua
format:
  revealjs:
    auto-stretch: true
    center: true
    html-math-method: katex
    transition: none
    output-file: un_intro_slides.html
    slide-number: true
    callout-appearance: minimal
    code-line-numbers: true
    theme: [default, ../template.css] # alternative themes (subset): default, night, dark
    embed-resources: false
    echo: false
    fig-dpi: 250
    # incremental: true  # Remove comment if you like incremental bullet points
    logo: img/logoB.png
    footer: "[Home page](https://tommasorigon.github.io/StatIII)"
  html:
    html-math-method: katex
    echo: false
    callout-appearance: minimal
    theme: [simplex, ../template.css]
    toc: true
    toc-title: Table of contents
    embed-resources: false
    smooth-scroll: true
    fig-dpi: 250
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

## [Homepage](../index.html)

::: columns
::: {.column width="35%"}
![](img/cox.jpg){width=3in}

::: {style="font-size: 80%;"}
*"I would like to think of myself as a scientist, who happens largely to specialise in the use of statistics."*

[Sir David Cox](https://royalsocietypublishing.org/doi/10.1098/rsbm.2023.0052#:~:text=David%20described%20himself%20as%20a,of%20his%20interest%20in%20applications.){.grey} (1924-2022)
:::
:::

::: {.column width="65%"}
- _Statistica III_ is a monographic course on [Generalized Linear Models]{.blue} (GLMs), a broadly applicable [regression]{.orange} technique.

- This is a [B.Sc.-level]{.orange} course, but there are some prerequisites: it is assumed that you have already been exposed to:

  - [Simple linear regression]{.blue}, from [_Statistica I_](https://tommasorigon.github.io/StatI/);
  - [Inferential statistics]{.orange}, from _Statistica II_;
  - [Linear models]{.grey}, from _Analisi Statistica Multivariata_ and _Econometria_;
  - [R software]{.grey}, from [_Analisi Statistica Multivariata_](https://tommasorigon.github.io/introR/).
  
- In _Statistica III_ we extend linear models within a unified and elegant framework. 

- Regression is such an important topic that the [tour]{.orange} will [continue]{.orange} at the [M.Sc. at CLAMSES]{.blue}. In [Data Mining](https://tommasorigon.github.io/datamining/) I will cover penalized methods and nonparametric regression.

- Indeed, GLMs can be arguably regarded one of the most influential statistical ideas of the XX century.
:::
:::

## Statistics of the 20th century 

![](img/Davison1.png){width=7in fig-align=center}

- [Biometrika]{.orange} is among the most prestigious journals in Statistics. Past editors include Karl Pearson, Sir David Cox, and Anthony Davison.

## Early ideas

- Classical linear models and least squares began with the work of [Gauss]{.orange} and [Legendre]{.blue} who applied the method to astronomical data. 

- Their idea, in modern terms, was to [predict the mean]{.blue} of a normal, or Gaussian, distribution as a function of a [covariate]{.orange}: 
$$
\mathbb{E}(Y_i) = \beta_1 + \beta_2 x_i, \qquad i=1,\dots,n.
$$

. . .

- As early as Fisher (1922), a more advanced non-linear model was introduced, designed to handle [proportion data]{.blue} of the form $S_i / m$.

- Through some modeling and calculus, Fisher derived a [binomial]{.blue} model for $S_i$, with
$$
\mathbb{E}(S_i/m) = \pi_i 
= 1 - \exp\{-\exp(\beta_1 + \beta_2 x_i)\}, 
\qquad i = 1, \dots, n.
$$
where $\pi_i \in (0, 1)$ is the [probability of success]{.orange} of a binomial distribution. 

- The corresponding inverse relationship is known as the [complementary log-log]{.orange} link function: 
$$
\beta_1 + \beta_2 x_i = \log\{-\log(1-\pi_i)\}.
$$

## Early ideas II

- In the [probit model]{.blue}, developed by Bliss (1935), a [Binomial]{.blue} model for $S_i$ is specified with
$$
\mathbb{E}(S_i/m) = \pi_i = \Phi(\beta_1 + \beta_2 x_i),\qquad i = 1, \dots, n.
$$
where $\Phi(x)$ is the cumulative distribution function of a Gaussian distribution. 

. . .

- Dyke and Patterson (1952) also considered the case of modelling proportions, but specified
$$
\mathbb{E}(S_i/m) = \pi_i = \frac{\exp(\beta_1 + \beta_2 x_i)}{1 + \exp(\beta_1 + \beta_2 x_i)}, \qquad i = 1, \dots, n.
$$

- The corresponding inverse relationship is known as the [logit]{.orange} link function: 
$$
\beta_1 + \beta_2 x_i = \text{logit}(\pi_i) = \log\left(\frac{\pi_i}{1 - \pi_i}\right).
$$
In fact, this approach is currently known as [logistic regression]{.blue}. 

. . .

- See Chapter 1 of @McCullagh1989 for a more exhaustive [historical]{.blue} account, including early ideas about the [Poisson]{.orange} distribution, the multinomial, and more. 

## Generalized linear models 

![](img/Davison7.png){width=6.5in fig-align=center}

![](img/Davison7_5.png){width=6.5in fig-align=center}

- The [pivotal paper]{.orange} by @Nelder1972 unified all these approaches. 

## Quasi likelihoods

![](img/Davison8.png){width=6.5in fig-align=center}

## The content of this course

- [General theory]{.blue}

  - Linear models and misspecification	
  - Generalized Linear Models

- [Notable models]{.orange}

  - Binary and binomial regression
  - Poisson regression

- [Advanced topics]{.grey}

  - Contingency tables and log-linear models
  - Quasi likelihoods

. . .

- Unfortunately, due to time constraints, we will [not]{.orange} cover:
  - Multinomial response models;
  - Models with correlated responses (random effects);
  - Nonparametric regression.

- These topics will be covered e.g. in [Statistica Multivariata]{.blue} and [Data Mining](https://tommasorigon.github.io/datamining/) at CLAMSES. 

## Textbooks

We will use several textbooks throughout this course — some more specialized than others. They are listed in order of importance: 

1. The book by @Salvan2020, [in Italian]{.blue}, is the [main textbook]{.orange}. Most of the material covered in these slides can be found there. I will also try to follow its notation as closely as possible.  

. . .

2. The book by @Azzalini2008, [in Italian]{.blue}, is more concise but very enjoyable to read. I highly recommend browsing through it.  

. . .

3. The book by @Agresti2015, [in English]{.orange}, is comprehensive and extremely well-written. It was the one I consulted most while preparing this course. Its only "drawback" is that it is in English.  

. . .

4. The book by @McCullagh1989, [in English]{.orange}, is an [advanced and authoritative textbook]{.orange}   intended for experienced statisticians (at least at the M.Sc. level). Feel free to explore it out of curiosity, but it is not a main reference.


## Exam

- The written exam has two parts, held on the same day:  
  - [Theory and exercises]{.orange}: questions to assess understanding of concepts  
    and the ability to correctly set up a statistical model.  
  - [Data set analysis]{.blue}: applied analysis of a dataset using R.  

- The [overall mark]{.grey} is the average of the two parts.  
  - You must pass both parts (each $\geq 18$).  

- The [oral exam]{.orange} is optional:  
  - Can be requested by the student or the teacher  
  - Final mark = average of written and oral marks  

- The exam is [closed-book and closed-notes]{.orange}, except for the [R scripts]{.blue} provided at the beginning of the test.


## References {.unnumbered}

::: {#refs}
:::
