---
title: "Soluzione esame del 27 Gennaio 2026"
subtitle: "Statistics III - CdL SSE"
author: "[Tommaso Rigon]{.orange}"
institute: "_Università degli Studi di Milano-Bicocca_"
page-layout: full
lang: it
bibliography: ../biblio.bib
citeproc: true
csl: https://www.zotero.org/styles/journal-of-the-american-statistical-association
reference-location: margin
execute:
  cache: false
format:
  html:
    html-math-method: katex
    echo: true
    callout-appearance: minimal
    theme: [simplex, ../template.css]
    embed-resources: false
    code-line-numbers: true
    smooth-scroll: true
    code-fold: false
    code-summary: "Show the code"
    fig-dpi: 150
    highlight-style: github
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

# [Homepage](../index.html)

## Parte I: analisi dei dati

```{r}
library(faraway)
data(anaesthetic)
head(anaesthetic, 4)
```

```{r}
# Punto (a)
anaesthetic$breath[anaesthetic$breath == 0] <- 0.25
```

Questo passaggio era necessario per lo svolgimento delle domande successive, ma non conferiva di per sè alcun punteggio.

<!-- (a) Alcuni valori di `breath` sono esattamente pari a `0` minuti, che è un errore di arrotondamento. Si sostituisca a tali valori il numero `0.25`. -->

<!-- (b) Si ottengano dei boxplot per la variabile `breath` per ciascuno dei quattro gruppi di pazienti (senza riportarli); si commentino i risultati. Si riportino inoltre le medie e le deviazioni standard di ciascun gruppo. -->

```{r}
#| fig-show: hide

# Punto (b)
boxplot(anaesthetic$breath ~ anaesthetic$tgrp) # Boxplot (non mostrato nel seguente output)
tapply(anaesthetic$breath, anaesthetic$tgrp, mean) # Media di ciascun gruppo
tapply(anaesthetic$breath, anaesthetic$tgrp, sd) # Deviazione standard di ciascun gruppo
```

Sulla base dei boxplot e delle statistiche descrittive calcolate, le differenze di efficacia (`breath`) tra i diversi metodi di anestesia non appaiono particolarmente marcate. Per confermare questa valutazione preliminare, è tuttavia necessario ricorrere a un test statistico formale.

```{r}
# Punto (c)
m_lin <- lm(breath ~ tgrp, data = anaesthetic)
```

Si tratta di un modello *ANOVA*, un concetto che è stato trattato nel corso Analisi Statistica Multivariata. La risposta alla gran parte delle domande del punto (c) si poteva ottenere leggendo con attenzione il comando `summary`.

```{r}
#| eval: false
summary(m_lin)
```

Anzitutto, desumiamo che l'equazione che esprime la risposta media in funzione della variabile `tgrp` è la seguente
$$
\hat{E}(Y_i) = \hat{\beta}_1 + \hat{\beta}_2 d_{i,B} + \hat{\beta}_3 d_{i, C} + \hat{\beta}_4 d_{i, D} = 5.4  - 2.15 \, d_{i,B} -2.34 \, d_{i, C} -1.04\, d_{i, D},\qquad i=1,\dots,80.
$$
dove $d_{i, B}, d_{i, C}$ e $d_{i, D}$ sono delle variabili *dummy* che identificano l'appartenenza dell'i-esima unità ai gruppo `B`, `C`, `D` della variabile `tgrp`; il primo gruppo (`A`) è preso come categoria di riferimento. Di conseguenza, il valore $\hat{\beta}_1$ rappresenta la media del gruppo `A`, mentre i rimanenti coefficienti rappresentano la **differenza** tra la media del gruppo considerato e la media del gruppo `A`. 

Alla luce di quanto discusso in precedenza, risultava quindi evidente che le previsioni per ciascuno dei quattro gruppi coincidessero con le rispettive medie di gruppo. Non era pertanto necessario eseguire ulteriori comandi, poiché tali medie erano già state calcolate. In effetti, il comando `predict` restituiva proprio i valori delle medie.
```{r}
predict(m_lin, newdata = data.frame(tgrp = c("A", "B", "C", "D")))
```

Veniva infine richiesto di confrontare il modello stimato con il modello nullo, ossia di verificare l’ipotesi nulla  
$$H_0: \beta_2 = \beta_3 = \beta_4 = 0,$$ 
contro l’alternativa $H_1$, secondo cui almeno uno dei coefficienti è diverso da zero. In questo contesto, tale sistema di ipotesi **equivale a verificare se le medie dei gruppi siano uguali tra loro** oppure no. Tradotto nel linguaggio del problema, si tratta di accertare, mediante un test statistico formale, se in media esistano differenze di efficacia tra le quattro differenti anestesie. Anche in questo caso, la risposta si otteneva tramite il `summary`, da cui si deduce in particolare che:

    F-statistic: 1.774 on 3 and 76 DF,  p-value: 0.1592

In altri termini, la statistica test F è pari a $1.774$ avente gradi di libertà pari a $q = 3$ (numero di parametri vincolati) e $n - p = 76$. Il *p-value* è pari a $0.1592$, pertanto non c'è sufficiente evidenza contro l'ipotesi nulla. In altre parole, concludiamo che in media i trattamente anestetici sono indistinguibili tra loro e che eventuali differenze empiriche sono da attribuire all'effetto del caso.  In alternativa, si potevano usare i seguenti comandi:
```{r}
m_lin0 <- lm(breath ~ 1, data = anaesthetic)
anova(m_lin0, m_lin)
```
che producono gli stessi identici risultati, con qualche dettaglio aggiuntivo. 

```{r}
#| fig-show: hide
# Punto (d)
par(mfrow = c(2, 2))
plot(m_lin, which = 1:4)
```

I grafici diagnostici non destano particolari preoccupazioni. Si osservano lievi differenze di variabilità tra i gruppi, ma, considerato il numero limitato di osservazioni, questa moderata eteroschedasticità è verosimilmente attribuibile all’effetto del caso.

Il grafico diagnostico *Q–Q plot* è quello che presenta le maggiori criticità: si evidenzia infatti uno scostamento piuttosto marcato dalla distribuzione normale. Ciò non risulta particolarmente sorprendente, innanzitutto perché la variabile risposta assume esclusivamente valori positivi e, di conseguenza, la distribuzione dei residui non può essere di tipo gaussiano. Tuttavia, come discusso a lezione, deviazioni dalla normalità non sempre hanno un impatto rilevante sulle conclusioni inferenziali; questo è proprio il caso in esame (si vedano i punti successivi).

In generale, le previsioni di un modello lineare possono assumere valori negativi, circostanza problematica quando la variabile risposta è limitata a valori positivi. Si osservi tuttavia che, in questo esempio specifico, le previsioni coincidono con le medie aritmetiche dei singoli gruppi; di conseguenza, esse non possono assumere valori negativi, come conseguenza della proprietà di internalità della media aritmetica.

Come già osservato, il modello lineare `m_lin` risulta complessivamente soddisfacente, pur essendo formalmente mal specificato. Un’alternativa naturale, che tiene conto del fatto che la variabile risposta assume valori positivi, è rappresentata da un modello Gamma. Come si vedrà, tale scelta risulta appropriata ma non modifica le conclusioni inferenziali raggiunte.

```{r}
# Punto (e)
m_gamma <- glm(breath ~ tgrp, data = anaesthetic, family = "Gamma")
```

La risposta alla gran parte delle domande del punto (e) si poteva ottenere leggendo con attenzione il comando `summary`. In alternativa, si potevano calcolare i coefficienti 
```{r}
coef(m_gamma)
```
da cui si ottiene che l'equazione che esprima la risposta media in funzione della variabile `tgrp` è
$$
\hat{\mathbb{E}}(Y_i) = \frac{1}{\hat{\beta}_1 + \hat{\beta}_2 d_{i,B} + \hat{\beta}_3 d_{i, C} + \hat{\beta}_4 d_{i, D}} = \frac{1}{0.185  + 0.123 \, d_{i,B} + 0.141 \, d_{i, C} + 0.044\, d_{i, D}}, \qquad i=1,\dots,80.
$$

:::callout-warning
L'interpretazione dei coefficienti stimati in un modello gamma con legame canonico ha causato molte difficoltà. La media della variabile aleatoria $Y_A$, cioè una generica variabile risposta appartenente al gruppo `A`, è pari a
$$
\hat{\mathbb{E}}(Y_A) = \frac{1}{\hat{\beta}_1} = \frac{1}{0.185} = 5.40.
$$
In altre parole, $\hat{\beta}_1$ rappresenta il reciproco della media del gruppo `A`. Inoltre, prendendo come esempio il gruppo `B`, si noti che la media di $Y_B$ è pari a
$$
\hat{\mathbb{E}}(Y_B) = \frac{1}{\hat{\beta}_1 + \hat{\beta}_2} = \frac{1}{0.185 + 0.123} = 3.25.
$$
Pertanto, i valori $\hat{\beta_2}, \hat{\beta}_3$ e $\hat{\beta}_4$ corrispondono alla differenza tra il reciproco delle media del gruppo di riferimento ed il reciproco della media del gruppo `A`. Per esempio, si ha che
$$
\hat{\beta}_2 = \frac{1}{\mathbb{E}(Y_B)} - \frac{1}{\mathbb{E}(Y_A)}.
$$
Di consequenza, valori positivi di $\hat{\beta}_2$ implicano che $\hat{\mathbb{E}}(Y_A) > \hat{\mathbb{E}}(Y_B)$; la disuguaglianza è invertita in caso di valori negativi di $\hat{\beta}_2$. 
:::

```{r}
# Punto (e.iii)
predict(m_gamma, newdata = data.frame(tgrp = c("A", "B", "C", "D")), type = "response")
```

Le previsioni del modello gamma sono pari, ancora una volta, alle medie campionarie di ciascun gruppo. [Non è un caso](https://tommasorigon.github.io/StatIII/exe/exe_B_F.pdf), come visto negli esercizi teorici. Di conseguenza, le previsioni di questo modello sono identiche a quelle del modello lineare.

```{r}
# Punto (e.iv)
m_gamma0 <- glm(breath ~ 1, data = anaesthetic, family = "Gamma")
anova(m_gamma0, m_gamma, test = "LRT")
```

Il sistema d'ipotesi del test log-rapporto di verosimiglianza è identico a quello del modello lineare, ossia di verificare l’ipotesi nulla  
$$H_0: \beta_2 = \beta_3 = \beta_4 = 0,$$ 
contro l’alternativa $H_1$, secondo cui almeno uno dei coefficienti è diverso da zero. Tale sistema di ipotesi **equivale a verificare se le medie dei gruppi siano uguali tra loro** oppure no.

:::callout-warning
Il default del comando `anova` non è il test `LRT` (log-rapporto di verosimiglianza), bensì il test `F`, che non abbiamo mai visto a lezione. I risultati sono corretti da un punto di vista statistico ma non sono quanto richiesto.
:::

Il *p-value*, cioè `Pr(>Chi)`, associato al test $W$ con $q = 3$ gradi di libertà (numero di vincoli, `Df`) è pari a $0.1511$, che è praticamente identico a quello ottenuto nel caso del modello `m_lin`. Le conclusioni qualitative sono le medesime. 

Il valore del test $W$ non è riportato tra le informazioni fornite da `anova` e va quindi calcolato "a mano". In effetti `Deviance` rappresenta al differenza tra le devianze considerate, che tuttavia va riscalata per $\hat{\phi}$ quando questo è diverso da $1$. Di conseguenza

```{r}
deviance_diff <- deviance(m_gamma0) - deviance(m_gamma)
phi_hat <- summary(m_gamma)$dispersion
W <- deviance_diff / phi_hat
round(c(deviance_diff, phi_hat, W), 4)
```

Pertanto si ottiene che la statistica test è $W = 4.2621 / 0.8042 = 5.2997$.

```{r}
#| fig-show: hide
# Punto (f)
par(mfrow = c(2, 2))
plot(m_gamma, which = 1:4)
```

I grafici diagnostici non presentano alcun tipo di problematicità e sono migliorati rispetto a quelli del modello lineare.

```{r}
#| eval: false

# Punto (g)
fit_A <- predict(m_gamma, newdata = data.frame(tgrp = c("A")), type = "response", se = TRUE)
z_test <- (fit_A$fit - 10) / fit_A$se.fit
2 * (1 - pnorm(abs(z_test)))
```
Una statistica test basata sulla deviazione standard è la seguente
$$z_\text{test} = \frac{\hat{\mu}_A - 10}{\hat{se}(\hat{\mu}_A)} = - 4.2480,
$$
Si può assumere, come per gli intervalli di confidenza, che la distribuzione di tale statistica test sia normale. Pertanto, il *p-value* associato è praticamente pari a $0$. Ci conseguenza, si rifiuta l'ipotesi nulla $H_0: \mu_A = 10$. 

```{r}
# Punto (h)

# NON BISOGNAVA FARE NULLA.
```

No, non ha senso verificare se nel modello `m_gamma` è presente sovradispersione. Il modello Gamma già prevede un parametro di dispersione, in questo caso pari a $\hat{\phi} = 0.8042$. 

<!-- (g) Si vuole testare se la media del gruppo `A`, indicata con $\mu_A$, è o meno pari a $10$. Utilizzando il modello `m_gamma`, si ottenga una statistica test opportuna e si calcoli il relativo *p-value*. Si commentino i risultati. -->

<!-- (h) Ha senso verificare se nel modello `m_gamma` è presente sovradispersione? In caso affermativo, si provi a trattarla tramite una quasi-verosimiglianza e si commentino i risultati ottenuti. -->
